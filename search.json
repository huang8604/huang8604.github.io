[{"categories":null,"content":"实用命令汇总 任务 命令 多核压缩目录 `tar -cvf - /data 多核解压文件 `pigz -dc -p 4 /backup/data.tar.gz 简写压缩命令 tar --use-compress-program=\"pigz -p 4\" -cvf data.tar.gz /data 简写解压命令 tar --use-compress-program=\"pigz -dp 4\" -xvf data.tar.gz tar -cvf - /data pigz -p 9 \u003e /backup/backup.tar.gz1. 📘 Linux 下使用 tar 与 pigz 进行多核压缩 一、概述 在 Linux 系统中， tar 是最常用的归档（打包）工具之一，用于将多个文件或目录合并为一个文件。 而 gzip 是常用的压缩工具，用于对文件内容进行压缩。 tar 与 gzip 常搭配使用形成命令： tar -czf backup.tar.gz /data1. 但这种方式的一个明显限制是： ⚠️ tar 与 gzip 均为单线程程序，只能使用一个 CPU 核心。 当系统 CPU 较多、文件较大时（如 10GB 以上），这种单线程压缩会成为性能瓶颈。 为解决这一问题，推荐使用 **pigz** （Parallel Implementation of GZip） ， 它是 gzip 的多线程版本，可以充分利用多核 CPU 进行压缩。 二、tar 与 pigz 的关系与工作方式 tar 与 pigz 实际是两个独立程序： 程序 功能 是否多线程 tar 负责打包（将多个文件合并为一个数据流） ❌ 单线程 pigz 负责压缩（将数据流压缩成 gzip 格式） ✅ 多线程 1️⃣ tar 的职责 tar 的任务是读取文件系统中的数据，然后输出一个 未压缩的数据流 。 这个过程几乎不涉及复杂计算，主要是 I/O 操作。 示例： tar -cvf - /data1. 这条命令不会生成文件，而是将归档内容输出到标准输出（stdout）。 - 表示“写到标准输出”。 2️⃣ pigz 的职责 pigz 从标准输入（stdin）接收数据流，并对其进行并行压缩。 示例： pigz -p 4 \u003e backup.tar.gz1. -p 4 表示使用 4 个线程进行压缩。 它会根据 CPU 核心数量自动划分压缩块并并行计算。 3️⃣ 二者的组合：流式管道压缩 通过 Linux 管道（ | ）机制，可以让 tar 与 pigz 同时工作： tar -cvf - /data | pigz -p 4 \u003e /backup/backup.tar.gz1. 执行时的并行流程如下： ┌────────────────────────┐ ┌────────────────────┐ │ tar: 读取文件并打包流式输出 │ ---\u003e │ pigz: 多线程压缩数据流 │ └────────────────────────┘ └────────────────────┘ (单线程) (多线程)1.2.3.4. 运行结果： tar 依然是单线程； pigz 使用 4 个 CPU 核； 管道机制保证两者边读边压缩、无须中间文件； 整体 CPU 利用率高、内存占用低、压缩速度显著提升。 三、为什么 tar 只能使用一个 CPU？ tar 是一种典型的“流式归档”工具，它顺序地遍历文件系统、读取文件并写入输出流。 这种顺序处理模式的核心特点是： 每次只处理一个文件； 不进行复杂运算； 不具备数据块划分与并发处理机制； 并发读取文件还可能破坏归档的顺序一致性。 因此： 🧠 结论： tar 的核心瓶颈不是 CPU，而是磁盘 I/O。 即使机器有 8 核、16 核， tar 自身仍然只使用 1 个核心。 四、如何使用多核进行压缩 ✅ 方案一：tar + pigz（推荐） tar -cvf - /data | pigz -p 4 \u003e /backup/backup.tar.gz1. 说明： 参数 含义 -cvf - 打包并输出到标准输出 pigz -p 4 使用 4 个线程压缩 \u003e 将压缩后的数据写入目标文件 性能特征： tar 占用约 1 核； pigz 占用 4 核； 总共利用 5 核； 压缩速度通常是单线程 gzip 的 3~5 倍。 ✅ 方案二：tar 内置调用 pigz（更简洁） 许多 Linux 发行版的 tar 已支持直接使用 pigz 替代 gzip ： tar --use-compress-program=\"pigz -p 4\" -cvf /backup/backup.tar.gz /data1. 等价于： tar -cvf - /data | pigz -p 4 \u003e /backup/backup.tar.gz1. 优点： 命令更简洁； 归档和压缩由 tar 管理； 同样支持多核。 ✅ 方案三：解压时多核解压 同样，解压时也可以利用多核： pigz -dc -p 4 /backup/backup.tar.gz | tar -xvf -1. 或者更简洁的形式： tar --use-compress-program=\"pigz -dp 4\" -xvf /backup/backup.tar.gz1. 五、性能对比示例（8 核 CPU） 工具 压缩方式 CPU使用 压缩时间(18GB文件) `tar gzip` 单线程 100% of 1 CPU `tar pigz -p 4` 多线程（4核） ~400% `tar pigz -p 8` 多线程（8核） ~800% （实际速度取决于磁盘 I/O、文件类型、压缩比等因素） 六、在生产环境中的最佳实践 场景 推荐命令 说明 4 核机器 `tar -cvf - /data pigz -p 3 \u003e /backup/data.tar.gz` 8 核机器 `tar -cvf - /data pigz -p 6 \u003e /backup/data.tar.gz` 自动检测 CPU pigz -p $(($(nproc)-1)) 自动使用除 1 外的全部 CPU 七、总结 项目 tar gzip pigz 功能 打包 压缩 多线程压缩 是否多线程 ❌ ❌ ✅ 可替代 gzip ❌ ✅ ✅ 推荐用途 打包文件 兼容老系统压缩 现代多核环境压缩 与 tar 配合方式 输出到管道 tar -czf `tar 九、结语 tar 的瓶颈是 I/O，而非 CPU； pigz 能显著提高压缩性能； tar + pigz 的组合是大文件备份的业界最佳实践； 合理控制线程数量（如 -p 3 或 -p $(nproc)-1 ）可以在性能与系统稳定性间取得最佳平衡。 ","date":"2025-10-28","objectID":"/posts/linux-%E4%B8%8B%E4%BD%BF%E7%94%A8-tar-%E4%B8%8E-pigz-%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%A0%B8%E5%8E%8B%E7%BC%A9/:0:0","tags":["clippings","blog","工具"],"title":"Linux 下使用 tar 与 pigz 进行多核压缩","uri":"/posts/linux-%E4%B8%8B%E4%BD%BF%E7%94%A8-tar-%E4%B8%8E-pigz-%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%A0%B8%E5%8E%8B%E7%BC%A9/"},{"categories":null,"content":"FH20GMS-120 [VTS][MR1]vts_generic_boot_image_test 从报错信息来看ramdisk缺少 system/bin/e2fsck，但设备上是有这个bin文件的，如下： Ramdisk（内存磁盘）是Android启动过程中的一个关键组件，它是一个临时根文件系统，在启动初期被加载到内存中，用于初始化系统并挂载真正的根文件系统。 Ramdisk的作用 初始化系统环境 ： 运行init进程，它是所有进程的父进程。 解析init.rc脚本，设置系统属性、创建设备节点、挂载文件系统等。 挂载必要的文件系统 ： 挂载system、vendor、data等分区。 设置文件系统的权限和SELinux安全上下文。 启动关键系统服务 ： 启动守护进程（如ueventd、logd等）。 准备Android运行时环境。 过渡到真正的根文件系统 ： 在Android系统中，ramdisk通常用于启动到recovery模式或作为boot镜像的一部分，在正常启动时，它会将控制权交给system分区。 Ramdisk在Android启动流程中的位置 Bootloader加载内核和ramdisk ：Bootloader将内核和ramdisk镜像加载到内存中。 内核启动 ：内核解压ramdisk并将其作为根文件系统挂载。 init进程启动 ：ramdisk中的init程序开始执行，解析init.rc文件。 执行启动脚本 ：根据init.rc中的命令，挂载系统分区、启动服务等。 切换根文件系统 ：在某些配置中，ramdisk可能会被切换为system作为根文件系统（例如在system-as-root配置中）。 Ramdisk的内容 一个典型的ramdisk包含以下内容： init ：初始化程序。 init.rc ：初始化脚本。 system/ 、 vendor/ 、 data/ 等目录的挂载点。 一些必要的工具和库（如 e2fsck 用于检查文件系统）。 安全策略文件（如SELinux策略）。 调试Ramdisk问题 当遇到ramdisk相关的问题时（如缺少文件、多余文件等），可以： 检查构建配置 ：确保构建类型（user/userdebug/eng）正确，并且没有意外包含调试文件。 检查设备配置 ：在设备Makefile中，确保只包含了必要的包和文件。 检查GKI要求 ：如果使用GKI，确保ramdisk符合通用内核映像的要求。 总结 Ramdisk是Android启动过程中的一个临时根文件系统，它负责初始化系统并挂载真正的文件系统。确保ramdisk包含正确的文件和不包含多余的文件对于系统正常启动和通过测试（如GKI测试）至关重要。 参考附件文档，可以移除e2fsck，修改如下 这个问题就是google 利用手里gms的杠杆来撬动厂家按照指挥棒来运动. 通过修改VTS的条件,让厂家必须根据VTS的要求来做 ","date":"2025-10-29","objectID":"/posts/fh20gms-120-vtsmr1vts_generic_boot_image_test-gms-confluence/:0:0","tags":["clippings","转载","blog"],"title":"FH20GMS-120    [VTS][MR1]vts_generic_boot_image_test - GMS - Confluence","uri":"/posts/fh20gms-120-vtsmr1vts_generic_boot_image_test-gms-confluence/"},{"categories":null,"content":"作为一种英语的使用工具,第一要听懂,第二要会说.第三要看懂 背单词 万丈高楼平地起,背单词.4-6级日常足够. 百词斩用起来 听 走遍美国 多听 说 AI Chart 读 写 英语规划 背单词 百词斩 – 熟悉单词 100天 -– 百词斩一轮后,使用墨墨背单词,加深记忆. -– 墨墨一轮后,继续使用墨墨背6级单词 听说 报百词斩的听说课 听走遍美国 写单词 ","date":"2025-10-23","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E8%8B%B1%E8%AF%AD%E6%89%93%E5%8D%A1/:0:0","tags":["blog"],"title":"学习英语打卡","uri":"/posts/%E5%AD%A6%E4%B9%A0%E8%8B%B1%E8%AF%AD%E6%89%93%E5%8D%A1/"},{"categories":null,"content":"有一个问题,就是配置了uwb,如果在没有uwb的机器上,会不停的启动uwb的服务. 09-29 10:19:45.885 1 1 E init : Control message: Could not find 'aidl/android.hardware.uwb.IUwb/default' for ctl.interface_start from pid: 441 (/system/bin/servicemanager) 09-29 10:19:45.942 441 29301 W libc : Unable to set property \"ctl.interface_start\" to \"aidl/android.hardware.uwb.IUwb/default\": PROP_ERROR_HANDLE_CONTROL_MESSAGE (0x20) 09-29 10:19:45.948 1725 4002 W ServiceManagerCppClient: Waited one second for android.hardware.uwb.IUwb/default (is service started? Number of threads started in the threadpool: 32. Are binder threads started and available?) 网络上的一个类似的方案: static bool HandleControlMessage(std::string_view message, const std::string\u0026 name,pid_t from_pid) { + if(\"aidl/android.hardware.biometrics.fingerprint.IFingerprint/default\" == name){ + return true; + } std::string cmdline_path = StringPrintf(\"proc/%d/cmdline\", from_pid); std::string process_cmdline; if (ReadFileToString(cmdline_path, \u0026process_cmdline)) { std::replace(process_cmdline.begin(), process_cmdline.end(), '\\0', ' '); process_cmdline = Trim(process_cmdline); } else { process_cmdline = \"unknown process\"; } } 那么进过验证,对uwb没有作用. 进过调试,如果把支持uwb 的feature删除, 确认服务是不会启动的.所以我们在pms里增加的打印堆栈 通过堆栈,我们发现是在SystemServer中 /** * Starts a miscellaneous grab bag of stuff that has yet to be refactored and organized. */ private void startOtherServices(@NonNull TimingsTraceAndSlog t) { t.traceBegin(\"startOtherServices\"); if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_UWB)) { t.traceBegin(\"UwbService\"); mSystemServiceManager.startServiceFromJar(UWB_SERVICE_CLASS, UWB_APEX_SERVICE_JAR_PATH); t.traceEnd(); } 所以我们的修改方案就是在没有uwb的机器上,如果需要获取hasSystemFeature的地方,给返回false. frameworks/base/services/core/java/com/android/server/pm/PackageManagerService.java public boolean hasSystemFeature(String name, int version) { // allow instant applications if(\"android.hardware.uwb\".equals(name)) { //Log.d(\"PackageManagerService wentao\", \"wentao hasSystemFeature uwb\" +Log.getStackTraceString(new Throwable())); //getprop ro.hw.mcu.mac String mcuMac = SystemProperties.get(\"ro.hw.mcu.mac\", \"(unknown)\"); Log.d(\"PackageManagerService\", \"mcuMac: \" + mcuMac); if(\"(unknown)\".equals(mcuMac)) { return false; }else{ return true; } } 这个判断uwb的判断条件一定要在systemserver startOtherServices 之前,不然时序不对. ","date":"2025-10-23","objectID":"/posts/%E6%80%BB%E7%BB%93-%E5%88%A4%E6%96%ADuwb%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/:0:0","tags":["blog","实战"],"title":"总结  判断uwb服务启动问题","uri":"/posts/%E6%80%BB%E7%BB%93-%E5%88%A4%E6%96%ADuwb%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"本文基于工作中自动背光笔记扩充了下，记录下自动背光算法。 基于Android 8.1, 代码可参看 http://androidxref.com/8.1.0_… Android 9加入了所谓的机器学习算法，根据用户调节时亮度和光感重新生成曲线， 自动背光时的滑动条不再是调节adjustment值，暂时不想写了。。。 Android 10简单看了下，加入了对foreground应用的微调支持，暂时不想写了。。。 一、简单说说 简单的说，其实背光调节就三大步，建曲线，采样去抖，计算亮度 1. 建曲线 Brightness 1 ^ | | | 。 | 。 | 。 + 。 min+ 。 | 0---+---+-------------------\u003e lux min 建曲线这个其实就是建立一个lux对应的brightness的曲线，这样就可以根据光感传来的lux值，计算出对应的亮度为多少。 （安卓的算法需要Brightness比lux多一个值，所以上图曲线两者的min值不对应。另外需要严格单调递增，组数看需要，上图只是个示意） 2. 采样去抖 这个就是采集一段时间内的lux值，然后根据这段时间的lux,算出这段时间的lux值。 当然考虑到抖动(如有闪电等突然变化很大，然后又恢复的情况;或者周期性的明暗明暗变化等情况），所以需要去抖， 默认安卓是要求光照稳定在0.8~1.1倍之间，并且持续一段时间（由暗到亮是4秒，由亮到暗是8s） 3. 计算亮度 安卓的算法流程 1). 开自动背光时，下拉通知条为一系数，假设为x,其区间为[-1.0, 1.0], 应用层为除以1024,浮点精度 2). 计算背光时，先计算出lux对应的亮度，假设为y,其区间为[0.0, 1.0], 考虑为用户会微调，所以然后再处理用户微调(1中的x) 3). 最终计算屏幕亮度z向下取整 4). 然后再处理z的极值区间，例如我们设置的11255, 18255 用公式表示即为 $$ \\mathbf{z = y^{3^{-x}}*255, x\\in[-1.0, 1.0], y\\in[0.0, 1.0], z\\in[min, 255]} $$ 公式中3表示为gamma3.0,后面是3的-x次方,即$3^{-x}$ 举个例子， / 出地库 光照稳定在0.8~1.1倍之间4S / | | |/ +---------+-----------------------+-------------- 10lux 5000lux 开始改变屏幕，假设屏幕亮度从55 -\u003e 255, 那么亮度调节完需要时间为((255-55)/rampRate)*16.6ms, 约3.3S (16.6ms是一个vsync时间，rampRate默认为1，可以更改进行速率调节) 二、说点代码 代码分析其实基本也是按照前面的三点来说的， 1. 建曲线配置 frameworks/base/core/res/res/values/config.xml \u003cbool name=\"config_automatic_brightness_available\"\u003efalse\u003c/bool\u003e \u003c!-- 自动背光功能是否可用开关 --\u003e \u003cinteger-array name=\"config_autoBrightnessLevels\"\u003e \u003c!-- lux 数组 --\u003e \u003c/integer-array\u003e \u003cinteger-array name=\"config_autoBrightnessLcdBacklightValues\"\u003e \u003c!-- 对应lcd brightness 数组 --\u003e \u003c/integer-array\u003e 曲线的配置为如上面的代码里，默认安卓是没有配置的，需要自己修改或者overlay, 另外还有个是否使用自动背光的开关 config_automatic_brightness_available，默认关的，需要打开。 代码里都有详细的注释和说明可看看，我这儿就没贴出来了。 config_autoBrightnessLevels为lux数组 config_autoBrightnessLcdBacklightValues为对应的lcd亮度值， 比lux数组多一个，组成和曲线需要严格单调递增。 config_autoBrightnessLevels -\u003e lux config_autoBrightnessLcdBacklightValues -\u003e brightness --\u003e brightness[0] lux[0] --\u003e brightness[1] lux[1] --\u003e brightness[2] lux[2] --\u003e brightness[3] ..... 2. 曲线初始化 曲线设置好了，就应该扔代码里跑起来，模型建起来了，这个过程是咋样的呢？ 通过搜索配置关键词( config_automatic_brightness_available config_autoBrightnessLevels config_autoBrightnessLcdBacklightValues ) 或知道其在DisplayPowerController()构造的时候初始化的。 frameworks/base/services/core/java/com/android/server/display/DisplayPowerController.java public DisplayPowerController(......) { ...... // 使能开关 mUseSoftwareAutoBrightnessConfig = resources.getBoolean( com.android.internal.R.bool.config_automatic_brightness_available); ...... if (mUseSoftwareAutoBrightnessConfig) { // 光感数组 int[] lux = resources.getIntArray( com.android.internal.R.array.config_autoBrightnessLevels); // 背光亮度数组 int[] screenBrightness = resources.getIntArray( com.android.internal.R.array.config_autoBrightnessLcdBacklightValues); // 其它一些配置 int lightSensorWarmUpTimeConfig = resources.getInteger( com.android.internal.R.integer.config_lightSensorWarmupTime); final float dozeScaleFactor = resources.getFraction( com.android.internal.R.fraction.config_screenAutoBrightnessDozeScaleFactor, 1, 1); // 创建自动背光样条 Spline screenAutoBrightnessSpline = createAutoBrightnessSpline(lux, screenBrightness); if (screenAutoBrightnessSpline == null) { // 如果lux, brightness不合要求，禁用自动背光 Slog.e(TAG, \"Error in config.xml. config_autoBrightnessLcdBacklightValues \" + \"(size \" + screenBrightness.length + \") \" + \"must be monotic and have exactly one more entry than \" + \"config_autoBrightnessLevels (size \" + lux.length + \") \" + \"which must be strictly increasing. \" + \"Auto-brightness will be disabled.\"); mUseSoftwareAutoBrightnessConfig = false; } else { ...... mAutomaticBrightnessController = new AutomaticBrightnessController(this, handler.getLooper(), sensorManager, screenAutoBrightnessSpline, ...// gamma, 最大最小值等其他配置 } } 如果打开了自动背光功能，会根据lux和brightness数组，创建样条曲线（以得到一条光滑曲线，安卓采用的是三次样条插值，有兴趣的可以搜索下学习学习）， 如果数组不满足要求，会禁用自动背光功能。 创建样条曲线成功后赋值给 AutomaticBrightnessController(),后面背光控制的主体逻辑就转到 AutomaticBrightnessController类里了。 AutomaticBrightnessController()构造就一些赋值，没啥可看的，重点看下 createAutoBrightnessSpline() private static Spline createAutoBrigh","date":"2025-08-21","objectID":"/posts/%E8%87%AA%E5%8A%A8%E8%83%8C%E5%85%89%E7%AE%97%E6%B3%95-android-8.1/:0:0","tags":["clippings","转载","blog"],"title":"自动背光算法-Android 8.1","uri":"/posts/%E8%87%AA%E5%8A%A8%E8%83%8C%E5%85%89%E7%AE%97%E6%B3%95-android-8.1/"},{"categories":null,"content":"单编模块命令：在SYSTEM/VENDOR目录下 source build/envsetup.sh lunch (选编号，也可以直接输入名称+\"-\"+user/userdebug，这个不知道可以看编译好的out/target/product下的目录名，或者直接看build_android.sh脚本里定义的 ) make module_name 一般都是在对应代码模块目录下的Android.bp就是 android_app java_library cc_library cc_binary apex等字段 Android.bp中常见的module_name: android_app APK Settings SystemUI framework-res system/app system/priv-app system_ext/app system_ext/priv-app java_libraryJar包framework-minus-apex servicessystem/frameworkcc_libraryso库libaudiomanager libbatterysystem/lib system/lib64cc_binarybinvold bugreportsystem/binapexapexcom.android.wifi com.android.vndk.currentsystem/apex adb root;adb remount;adb push xxx xxx;adb reboot 有些是 Android.mk 文件中定义的LOCAL_MODULE字段，比如： selinux make selinux_policy system/etc/selinux vendor/etc/selinux 预编译的 SELinux 政策：sepolicy_and_mapping.sha256也需要push https://source.android.google.cn/docs/security/features/selinux/build?hl=zh-cn#precompiled-policy adb settings命令： settings 命令通过 Binder IPC 与 Android 的 Settings Provider （位于 com.android.providers.settings ）交互，操作三个核心命名空间的配置数据库： system 存储设备系统级配置（如屏幕超时、亮度），路径为 /data/system/users/0/settings_system.xml 权限 ：普通应用可读，修改需 WRITE_SETTINGS 权限。 secure 存储敏感配置（如密码、默认输入法），路径为 /data/system/users/0/settings_secure.xml 权限 ：仅系统应用或特权进程可修改。 global 存储全局配置（如飞行模式、ADB 状态），路径为 /data/system/users/0/settings_global.xml 权限 ：需系统签名或 WRITE_SECURE_SETTINGS 权限。 ⚠️ 注意：不同 Android 版本可能对配置项有定制，部分命令需 Root 权限 。 基础操作 命令 用途 示例 list 列出命名空间所有键 adb shell settings list global get 获取键值 adb shell settings get system screen_brightness （返回亮度值） put 设置键值 adb shell settings put system screen_brightness 150 （设置亮度） delete 删除键值 adb shell settings delete secure test_ke reset 重置配置 adb shell settings reset global com.example.app （重置配置） 跳过开机向导：adb shell settings put global device_provisioned 1;adb shell settings put secure user_setup_complete 1 设置不检查互联网连接 adb shell settings put global captive_portal_mode 0/1 修改长亮时间：adb shell settings put system screen_off_timeout 60000 # 60 秒 开发过程中可能遇到需要临时性的关闭某个功能进行验证或测试的情况，修改代码时可以通过添加这个开关的方式动态的控制： privatevoidsetCpuPerformance(booleanenable) { booleanneedPerformance = Settings.Global.getInt(mContext.getContentResolver(), \"wifi_cpu_performance_enable\", 1) == 1; if(!needPerformance) { return; } android.os.SystemProperties.set(\"sys.cpu.performance\",enable?\"1\":\"0\"); } setprop getprop 截图和录屏命令 adb shell screencap /sdcard/screenshot.png adb shell screenrecord /sdcard/screenrecord.mp4 adb pull /sdcard/xxx Window 命令行支持直接保存截图 adb exec-out screencap -p \u003e screenshot.png bugreport命令 抓取系统日志，打包成bugreport-xxxx-xxxx.zip，包含的数据有 ： 系统属性 （ getprop 输出） 内核日志 （ dmesg 、 /proc 文件） 服务状态 （ dumpsys 输出，通过 Binder 调用服务的 dump() 方法） 日志文件 （logcat、ANR、tombstones） 硬件信息 （ lshal 输出） dumpsys 命令 dumpsys 通过 Binder IPC 与 Android 的核心组件 ServiceManager 通信，获取所有已注册系统服务的列表。每个服务（如 activity 、 window 、 power ）均实现 dump() 接口，用于返回自身状态信息 基础命令 命令 作用 示例输出内容 adb shell dumpsys -l 列出所有支持的服务（约 100+ 项） activity, window, power, battery 等 adb shell dumpsys \u003c服务名\u003e 获取特定服务的详细信息 如 dumpsys activity 输出任务栈、Broadcast 队列等 adb shell dumpsys \u003c服务名\u003e -h 查看服务的帮助文档及子命令 dumpsys activity -h 显示 a[ctivities] 、 b[roadcasts] 等子命令选 2. 高频服务详解 服务名 关键信息 实用场景 activity任务栈、Activity 生命周期、Broadcast 队列分析 ANR、排查页面跳转异常settingssettings 设置的数据，修改历史等分析用户操作行为，机器开关状态battery电量百分比、充电状态、温度监控电池健康状态window窗口焦点、Surface 状态、Display 信息调试悬浮窗、分屏异常input输入设备信息，按键事件记录分析input输入事件package应用安装信息，权限等信息分析已安装应用行为wifiwifi信息分析wifi运行情况overlay系统的overlay信息分析系统overlay配置情况 比如： 打印systemui应用的信息：adb shell dumpsys activity service com.android.systemui 查看当前页面报名：adb shell ‘dumpsys window | grep mFocus’ cmd cmd 是 Android 系统提供的一个 高级系统管理命令 ，用于直接调用设备内置的系统服务（System Services），实现对硬件、软件配置的深度控制。其核心逻辑是通过 cmd 命令的子命令（如 battery 、 wifi 等）访问 Android 的 Binder IPC 接口，与系统服务（如 BatteryService 、 WifiService ）交互 adb shell cmd \u003c服务名\u003e \u003c子命令\u003e [参数] 🔋 一、电池管理 (battery) 用于获取或模拟电池状态（ 需 Android 6.0+ ）： 命令 功能 示例 set level \u003c百分比\u003e 设置电池电量 cmd battery set level 20 (电量设为20%) set status \u003c状态码\u003e 修改充电状态（1:放电, 2:充电） cmd battery set status 2 (模拟充电) set usb \u003c0/1\u003e 禁用/启用USB充电 cmd battery set usb 0 (禁用USB充电) unplug 模拟断开充电（仅限软件层面） cmd battery","date":"2025-07-16","objectID":"/posts/%E5%BC%80%E5%8F%91%E4%B8%AD%E5%B8%B8%E7%94%A8%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E8%B0%83%E8%AF%95%E5%91%BD%E4%BB%A4/:0:0","tags":["clippings","转载","blog"],"title":"开发中常用到的一些调试命令","uri":"/posts/%E5%BC%80%E5%8F%91%E4%B8%AD%E5%B8%B8%E7%94%A8%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E8%B0%83%E8%AF%95%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":" 背光曲线 基本概念 环境光（Ambient Light） 真实环境的光照强度，单位 Lux （如白天室外约 10,000 Lux，夜间室内约 50 Lux）。 手机通过 光感传感器（sensor） 检测环境光，但 sensor 上报值 ≤ 真实环境光值（受硬件精度限制）。 Lux: 光照度单位，从光源照射到单位面积上的光通量 在背光流程中，Lux 通常指的是环境光 传感器 检测到的环境光强度。 背光（Backlight, BL） 屏幕背后的光源强度，由系统通过驱动控制，取值范围通常为 0-255 （如 0 为最低背光，255 为最高背光）。 背光是硬件参数，直接影响屏幕亮度，但需通过屏幕材质（反射系数 R）才能体现为用户感知的亮度。 手机屏幕亮度（Nit） 用户实际感知的屏幕亮度，单位 Nit （如 100 Nit 适合室内使用，500 Nit 适合户外强光）。 由背光强度和屏幕材质共同决定，公式为： Nit = R× 背光强度（BL） 其中， R 为反射系数 （由屏幕材质决定，如 OLED 和 LCD 的 R 值不同） 需求目标 功能需求 建立从 环境光（Lux） 到 手机屏幕亮度（Nit） 的映射关系（即背光曲线）。 由于屏幕材质固定（R 恒定），代码实现时需简化为： sensor 上报的 Lux→ 背光等级（BL） 简化逻辑 忽略环境光到 sensor 上报值的转换误差，认为 sensor 上报的 Lux = 环境光 Lux 。 最终代码需实现： sensor 上报 Lux → 目标屏幕亮度（Nit） → 背光等级（BL） 。 与之对应的系统给出来的配置接口： config_autoBrightnessLevels ----Lux config_autoBrightnessDisplayValuesNits ---- DisplayNit（目标屏幕亮度） config_screenBrightnessNits —\u003e Nit config_screenBrightnessBacklight —\u003e BL 解释一下这几个参数 config_screenBrightnessNits 和 config_screenBrightnessBacklight 反应的应该是屏幕材质，也就是背光和屏幕亮度的关系（L = R*E）中的 R，在硬件不变的情况下这两个参数配置好后不应该去改变，这两个参数定义的是背光等级到屏幕亮度的硬件特性。 config_autoBrightnessLevels 和 config_autoBrightnessDisplayValuesNits 。一般修改背光曲线配置的是这两个值，这两个属性定义的是环境光到屏幕亮度（背光等级）的策略。 背光曲线的创建 这里假设配置的数据都是有效的过一遍创建流程: 创建 Nit-Backlight 和 Backlight-Nit 曲线用于反应屏幕的R反射系数属性 输入 ： config_screenBrightnessNits ：屏幕亮度（Nit）的配置值。 config_screenBrightnessBacklight ：背光亮度（Backlight）的配置值。 过程 ： 根据 config_screenBrightnessNits 和 config_screenBrightnessBacklight 创建两条映射曲线： Nit-Backlight 曲线 ：将屏幕亮度（Nit）映射到背光亮度（Backlight）。 Backlight-Nit 曲线 ：将背光亮度（Backlight）映射到屏幕亮度（Nit）。 这两条曲线是互逆的，用于在 Nit 和 Backlight 之间进行转换。 输出： Nit-Backlight 曲线和 Backlight-Nit 曲线。 创建 Lux-Nit 曲线 输入 ： config_autoBrightnessDisplayValuesNit ：自动亮度调节的目标屏幕亮度（Nit）配置值。 config_autoBrightnessLevels ：自动亮度调节的环境光照度（Lux）配置值。 用户设置的（Lux，Backlight）对：用户手动调整亮度时保存的（Lux ，Backlight） 对 过程： 将 config_autoBrightnessDisplayValuesNit 映射为 Backlight ： 使用 Nit-Backlight 曲线，将 config_autoBrightnessDisplayValuesNit 中的 Nit 值映射为对应的 Backlight 值。 得到一个 Backlight 数组，与 config_autoBrightnessLevels 中的 Lux 数组一一对应。 插入用户设置的（Lux，Backlight）对 ： 将用户手动设置的（Lux，Backlight）对插入到 config_autoBrightnessLevels 和 Backlight 数组中。 插入逻辑通常是根据 Lux 值的大小进行排序，并确保 Lux 和 Backlight 的对应关系正确 在实际操作中插入数据时涉及到所有 Backlight 的调整，涉及 adjustment 自动背光调整值.。具体逻辑在源码中分析 生成 Lux-Nit 曲线 ： 使用 Backlight-Nit 曲线，将 Backlight 数组转换为 Nit 值。 最终生成 Lux-Nit 曲线，表示从环境光照度（Lux）到目标屏幕亮度（Nit）的映射关系。 输出 ： Lux-Nit 曲线。 使用 Lux-Nit 曲线进行自动亮度调节 当环境光传感器检测到当前的 Lux 值时： 根据 Lux-Nit 曲线，查找对应的 目标Nit 值。 使用 Nit-Backlight 曲线，将 Nit 值转换为 Backlight 值。（背光强度=L/R） 将 Backlight 值传递给底层硬件，调整屏幕背光亮度。 插入用户设置的（Lux，Backlight）对时 adjustment 自动背光调整值的设置及使用 在上述流程中插入用户设置的（Lux，Backlight）对时并不只是在曲线中改变点即可，而是要调整整个lux —backlight对应关系。也就是要调整整个backlight数组。这里的调整逻辑就是通过adjustment 实现 adjustment: 自动背光调整值，范围（-1,1） 具体调整逻辑： 计算gamma gamma = log [current] desired current: 当前值（通过当前已经存在的曲线由lux得到的BL） ，desired: 期望值（用户设置） 范围 0 到 1 0 最暗，1 最亮 计算adjustment adjustment =-log [maxGamma] gamma maxGamma 是一个用于描述屏幕亮度曲线的参数，它影响屏幕亮度的非线性映射.简而言之是一个配置属性 中间当 current 和 desired 是一些特殊值时 adjustment 直接设置，这也是adjustment存在的意义. current \u003c=0.1f || current\u003e = 0.9f 时 adjustment = desired-current; desired = 0 时 adjustment =-1 desired = 1 时 adjustment = 1 重新计算gamma gamma = maxGamma^(-adjustment) 计算新的背光数组 newBacklight = oldBacklight^gamma y = a^x (0\u003c a \u003c 1) x 越大 y 越小 最终映射关系, adjustment 只是一个中间值,最终用于该表Backlight的是 gamma。 desired = 0 时 adjustment =-1 ，此时 gamma = maxGamma 最大，newBacklight = oldBacklight^maxGamma 最小，符合期望 desired = 1 时 adjustment = 1 ，此时 gamma = maxGamma^-1 最小，newBacklight = oldBacklight^maxGamma 最大，符合期望 ","date":"2025-06-30","objectID":"/posts/%E8%83%8C%E5%85%89%E6%9B%B2%E7%BA%BF%E7%9A%84%E5%88%9B%E5%BB%BA/:0:0","tags":["clippings","转载","blog"],"title":"背光曲线的创建","uri":"/posts/%E8%83%8C%E5%85%89%E6%9B%B2%E7%BA%BF%E7%9A%84%E5%88%9B%E5%BB%BA/"},{"categories":null,"content":"展锐光感自动调节亮度功能，光感数据上报对应的背光亮度设置，其实其他平台像 MTK ，高通也差不多，大同小异，主要是搜索关键字：config_autoBrightnessLevels、config_screenBrightnessBacklight，就会发现只是文件路径不太一样。 通过修改sensorhub下光感原始数据上报，或者根据实际情况去调节brightness level都能实现自动调节亮度功能的 灵敏度 ，看个人喜欢。 展锐的代码路径如下： device\\sprd\\roc1\\common\\overlay\\frameworks\\base\\core\\res\\res\\values\\config.xml \u003c!-- Array of light sensor LUX values to define our levels for auto backlight brightness support. The N entries of this array define N 1 zones as follows: Zone 0: 0 \u003c= LUX \u003c array[0] Zone 1: array[0] \u003c= LUX \u003c array[1] ... Zone N: array[N - 1] \u003c= LUX \u003c array[N] Zone N + 1 array[N] \u003c= LUX \u003c infinity Must be overridden in platform specific overlays --\u003e \u003cinteger-array name=\"config_autoBrightnessLevels\"\u003e \u003citem\u003e16\u003c/item\u003e \u003citem\u003e32\u003c/item\u003e \u003citem\u003e50\u003c/item\u003e \u003citem\u003e100\u003c/item\u003e \u003citem\u003e140\u003c/item\u003e \u003citem\u003e180\u003c/item\u003e \u003citem\u003e240\u003c/item\u003e \u003citem\u003e300\u003c/item\u003e \u003citem\u003e600\u003c/item\u003e \u003citem\u003e800\u003c/item\u003e \u003citem\u003e1000\u003c/item\u003e \u003citem\u003e2000\u003c/item\u003e \u003citem\u003e3000\u003c/item\u003e \u003citem\u003e4000\u003c/item\u003e \u003citem\u003e5000\u003c/item\u003e \u003citem\u003e6000\u003c/item\u003e \u003citem\u003e8000\u003c/item\u003e \u003citem\u003e10000\u003c/item\u003e \u003citem\u003e20000\u003c/item\u003e \u003citem\u003e30000\u003c/item\u003e \u003c/integer-array\u003e \u003c!-- Array of desired screen brightness in nits corresponding to the lux values in the config_autoBrightnessLevels array. As with config_screenBrightnessMinimumNits and config_screenBrightnessMaximumNits, the display brightness is defined as the measured brightness of an all-white image. If this is defined then: - config_autoBrightnessLcdBacklightValues should not be defined - config_screenBrightnessNits must be defined - config_screenBrightnessBacklight must be defined This array should have size one greater than the size of the config_autoBrightnessLevels array. The brightness values must be non-negative and non-decreasing. This must be overridden in platform specific overlays --\u003e \u003carray name=\"config_autoBrightnessDisplayValuesNits\"\u003e \u003citem\u003e10.45935\u003c/item\u003e \u003c!-- 0-16 --\u003e \u003citem\u003e29.25559\u003c/item\u003e \u003c!-- 16-32 --\u003e \u003citem\u003e34.240692\u003c/item\u003e \u003c!-- 32-50 --\u003e \u003citem\u003e37.514347\u003c/item\u003e \u003c!-- 50-100 --\u003e \u003citem\u003e40.018696\u003c/item\u003e \u003c!-- 100-140 --\u003e \u003citem\u003e46.885098\u003c/item\u003e \u003c!-- 140-180 --\u003e \u003citem\u003e51.626434\u003c/item\u003e \u003c!-- 180-240 --\u003e \u003citem\u003e58.610405\u003c/item\u003e \u003c!-- 240-300 --\u003e \u003citem\u003e66.890915\u003c/item\u003e \u003c!-- 300-600 --\u003e \u003citem\u003e77.61644\u003c/item\u003e \u003c!-- 600-800 --\u003e \u003citem\u003e90.221886\u003c/item\u003e \u003c!-- 800-1000 --\u003e \u003citem\u003e105.80314\u003c/item\u003e \u003c!-- 1000-2000 --\u003e \u003citem\u003e126.073845\u003c/item\u003e \u003c!-- 2000-3000 --\u003e \u003citem\u003e154.16931\u003c/item\u003e \u003c!-- 3000-4000 --\u003e \u003citem\u003e191.83717\u003c/item\u003e \u003c!-- 4000-5000 --\u003e \u003citem\u003e240.74442\u003c/item\u003e \u003c!-- 5000-6000 --\u003e \u003citem\u003e294.84857\u003c/item\u003e \u003c!-- 6000-8000 --\u003e \u003citem\u003e348.05453\u003c/item\u003e \u003c!-- 8000-10000 --\u003e \u003citem\u003e394.98703\u003c/item\u003e \u003c!-- 10000-20000 --\u003e \u003citem\u003e405.2315\u003c/item\u003e \u003c!-- 20000-30000 --\u003e \u003citem\u003e410.3658\u003c/item\u003e \u003c!-- 30000+ --\u003e \u003c/array\u003e \u003c!-- An array describing the screen's backlight values corresponding to the brightness values in the config_screenBrightnessNits array. This array should be equal in size to config_screenBrightnessBacklight. --\u003e \u003cinteger-array name=\"config_screenBrightnessBacklight\"\u003e \u003citem\u003e0\u003c/item\u003e \u003citem\u003e5\u003c/item\u003e \u003citem\u003e10\u003c/item\u003e \u003citem\u003e15\u003c/item\u003e \u003citem\u003e20\u003c/item\u003e \u003citem\u003e25\u003c/item\u003e \u003citem\u003e30\u003c/item\u003e \u003citem\u003e35\u003c/item\u003e \u003citem\u003e40\u003c/item\u003e \u003citem\u003e45\u003c/item\u003e \u003citem\u003e60\u003c/item\u003e \u003citem\u003e75\u003c/item\u003e \u003citem\u003e90\u003c/item\u003e \u003citem\u003e105\u003c/item\u003e \u003citem\u003e120\u003c/item\u003e \u003citem\u003e135\u003c/item\u003e \u003citem\u003e150\u003c/item\u003e \u003citem\u003e165\u003c/item\u003e \u003citem\u003e180\u003c/item\u003e \u003citem\u003e195\u003c/item\u003e \u003citem\u003e210\u003c/item\u003e \u003citem\u003e225\u003c/item\u003e \u003citem\u003e240\u003c/item\u003e \u003citem\u003e255\u003c/item\u003e \u003c/integer-array\u003e 查看光感数据上报原始值节点： cat /sys/devices/virtual/sprd_sensorhub/sensor_hub/raw_data_als 可以跟一下代码就会发现在 kernel 下： kernel4.14\\drivers\\iio\\sprd_hub\\shub_core.c static ssize_t raw_data_als_show(struct device *dev, struct device_attribute *attr, char *buf) { struct shub_data *sensor = dev_get_drvdata(dev); u8 data[2]; u16 *ptr; int err; ptr = (u16 *)data; if (sensor-\u003emcu_mode \u003c= SHUB_OPDOWNLOAD) { dev_err(dev, \"mcu_mode == SHUB_BOOT!\\n\"); return -EINVAL; } err = shub_sipc_read(sensor, SHUB_GET_LIGHT_RAWDATA_SUBTYPE, data, sizeof(data)); if (err \u003c 0) { dev_err(dev, \"read RegMapR_GetLightRawData failed!\\n\"); return err; } return sprintf(buf, \"%d\\n\", ","date":"2025-06-30","objectID":"/posts/android%E5%85%89%E6%84%9F%E8%87%AA%E5%8A%A8%E8%B0%83%E8%8A%82%E4%BA%AE%E5%BA%A6_%E9%AB%98%E9%80%9A-%E5%85%89%E6%84%9F%E8%87%AA%E5%8A%A8%E8%B0%83%E8%8A%82%E9%85%8D%E7%BD%AE-xml-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android：光感自动调节亮度_高通 光感自动调节配置 xml-CSDN博客","uri":"/posts/android%E5%85%89%E6%84%9F%E8%87%AA%E5%8A%A8%E8%B0%83%E8%8A%82%E4%BA%AE%E5%BA%A6_%E9%AB%98%E9%80%9A-%E5%85%89%E6%84%9F%E8%87%AA%E5%8A%A8%E8%B0%83%E8%8A%82%E9%85%8D%E7%BD%AE-xml-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"REPO 编译 编译framework service make services -j16 push adb root; adb remount ; adb push out/target/product/qssi/system/framework/services.jar /system/framework/ adb root; adb remount ;adb push out/target/product/qssi/system/framework/services.jar /system/framework/; adb push out/target/product/qssi/system/framework/services.jar.bprof /system/framework/;adb push out/target/product/qssi/system/framework/services.jar.prof /system/framework/ ;adb push out/target/product/qssi/system/framework/oat/arm64/services.art /system/framework/oat/arm64/ ;adb push out/target/product/qssi/system/framework/oat/arm64/services.odex /system/framework/oat/arm64/ ; adb push out/target/product/qssi/system/framework/oat/arm64/services.vdex /system/framework/oat/arm64/ ; 编译SystemUI make SystemUI -j16 surfaceflinger make surfaceflinger -j16 只需要把 system/bin/surfaceflinger push 进去，然后 kill surfaceflinger 进程就可以生效了 编译framework下的jni cpp文件需要编译： # make libservices.core -j16 make libandroid_servers -j16 make services -j16 adb root; adb remount; adb push out/target/product/qssi/system/lib64/libandroid_servers.so /system/lib64/ ; adb push out/target/product/qssi/system/lib/libandroid_servers.so /system/lib/ ; adb push out/target/product/qssi/system/framework/services.jar /system/framework/ ; adb reboot 调试 设置电量温度 ,温度报警在BatteryService，但是低电量现在不在这里。 adb shell dumpsys battery set level 13 adb shell dumpsys battery set temp 551 2047 adb shell \"pm install-create\" 2048 adb shell \"pm install-write 2012419093 CtsSplitApp.apk /data/local/tmp/0_CtsSplitApp.apk\" 2049 adb push CtsSplitApp.apk /data/local/tmp/0_CtsSplitApp.apk 2050 adb shell \"pm install-write 2012419093 CtsSplitApp.apk /data/local/tmp/0_CtsSplitApp.apk\" 2051 adb shell \"pm install-commit 2021419093\" 2052 adb shell \"pm install-commit 2012419093\" 2053 adb shell \"pm list instrumentation\" 2054 adb shell \"pm set-app-links-user-selection\" 2055 adb shell \"pm list instrumentation\" 2056 adb shell \"pm set-app-links-user-selection\" repo forall -c \"pwd;git clean -df;git checkout -f\";repo sync -j4; ","date":"2025-01-06","objectID":"/posts/%E7%BC%96%E8%AF%91-repo-%E8%B0%83%E8%AF%95-%E5%B7%A5%E7%A8%8B%E7%9B%B8%E5%85%B3/:0:0","tags":["blog","工具"],"title":"编译 repo 调试 工程相关","uri":"/posts/%E7%BC%96%E8%AF%91-repo-%E8%B0%83%E8%AF%95-%E5%B7%A5%E7%A8%8B%E7%9B%B8%E5%85%B3/"},{"categories":null,"content":"背景： 测试步骤: 1、插入sd卡 2、观察sd卡名字 （Samsung） 3、格式化sd卡 实测结果: 格式化SDcard后 名字变成Android 预期结果: 格式化SDcard后 名字不会改变 格式化SD后，sd卡显示的名称会变化。 这个问题跟踪了一下格式化的流程： //SYSTEM/packages/apps/Settings/src/com/android/settings/deviceinfo/StorageWizardFormatConfirm.java builder.setPositiveButton( TextUtils.expandTemplate(getText(R.string.storage_menu_format_option), disk.getShortDescription()), (dialog, which) -\u003e { final Intent intent = new Intent(context, StorageWizardFormatProgress.class); intent.putExtra(EXTRA_DISK_ID, diskId); intent.putExtra(EXTRA_FORMAT_FORGET_UUID, formatForgetUuid); intent.putExtra(EXTRA_FORMAT_PRIVATE, formatPrivate); context.startActivity(intent); }); ///mnt/media/FH22/AP/SYSTEM/packages/apps/Settings/src/com/android/settings/deviceinfo/StorageWizardFormatProgress.java setHeaderText(R.string.storage_wizard_format_progress_title, getDiskShortDescription()); setBodyText(R.string.storage_wizard_format_progress_body, getDiskDescription()); setBackButtonVisibility(View.INVISIBLE); setNextButtonVisibility(View.INVISIBLE); mTask = (PartitionTask) getLastCustomNonConfigurationInstance(); if (mTask == null) { mTask = new PartitionTask(); mTask.setActivity(this); mTask.execute(); } else { mTask.setActivity(this); } @Override protected Exception doInBackground(Void... params) { final StorageWizardFormatProgress activity = mActivity; final StorageManager storage = mActivity.mStorage; try { if (activity.mFormatPrivate) { storage.partitionPrivate(activity.mDisk.getId()); publishProgress(40); final VolumeInfo privateVol = activity.findFirstVolume(TYPE_PRIVATE, 50); final CompletableFuture\u003cPersistableBundle\u003e result = new CompletableFuture\u003c\u003e(); if(null != privateVol) { storage.benchmark(privateVol.getId(), new IVoldTaskListener.Stub() { @Override public void onStatus(int status, PersistableBundle extras) { // Map benchmark 0-100% progress onto 40-80% publishProgress(40 + ((status * 40) / 100)); } @Override public void onFinished(int status, PersistableBundle extras) { result.complete(extras); } }); mPrivateBench = result.get(60, TimeUnit.SECONDS).getLong(\"run\", Long.MAX_VALUE); } // If we just adopted the device that had been providing // physical storage, then automatically move storage to the // new emulated volume. if (activity.mDisk.isDefaultPrimary() \u0026\u0026 Objects.equals(storage.getPrimaryStorageUuid(), StorageManager.UUID_PRIMARY_PHYSICAL)) { Log.d(TAG, \"Just formatted primary physical; silently moving \" + \"storage to new emulated volume\"); storage.setPrimaryStorageUuid(privateVol.getFsUuid(), new SilentObserver()); } } else { storage.partitionPublic(activity.mDisk.getId()); } return null; } catch (Exception e) { return e; } } storage.partitionPublic(activity.mDisk.getId()); ///mnt/media/FH22/AP/SYSTEM/frameworks/base/core/java/android/os/storage/StorageManager.java public void partitionPublic(String diskId) { try { mStorageManager.partitionPublic(diskId); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } ///mnt/media/FH22/AP/SYSTEM/frameworks/base/services/core/java/com/android/server/StorageManagerService.java public void partitionPublic(String diskId) { super.partitionPublic_enforcePermission(); final CountDownLatch latch = findOrCreateDiskScanLatch(diskId); try { mVold.partition(diskId, IVold.PARTITION_TYPE_PUBLIC, -1); waitForLatch(latch, \"partitionPublic\", 3 * DateUtils.MINUTE_IN_MILLIS); } catch (Exception e) { Slog.wtf(TAG, e); } } 我们根据sdka 的exfat格式，有个aidl 调用，然后会调用到exfat 的vold里面来出来format ///mnt/media/FH22/AP/SYSTEM/system/vold/fs/Exfat.cpp static const char* kMkfsPath = \"/system/bin/mkfs.exfat\"; static const char* kFsckPath = \"/system/bin/fsck.exfat\"; status_t Format(const std::string\u0026 source) { std::vector\u003cstd::string\u003e cmd; cmd.push_back(kMkfsPath); cmd.push_back(\"-n\"); cmd.push_back(\"android\"); cmd.push_back(source); int rc = ForkExecvp(cmd); if (rc == 0) { LOG(INFO) \u003c\u003c \"Format OK\"; return 0; } else { LOG(ERROR) \u003c\u003c \"Format failed (code \" \u003c\u003c rc \u003c\u003c \")\"; errno = EIO; return -1; } return 0; } cmd.push_back(\"-n\"); cmd.push_","date":"2025-01-02","objectID":"/posts/sd-%E5%8D%A1-%E5%AD%98%E5%82%A8-%E6%8C%82%E8%BD%BD%E7%9B%B8%E5%85%B3/:0:0","tags":["blog","案例分析"],"title":"SD 卡 存储 挂载相关","uri":"/posts/sd-%E5%8D%A1-%E5%AD%98%E5%82%A8-%E6%8C%82%E8%BD%BD%E7%9B%B8%E5%85%B3/"},{"categories":["生活"],"content":"FPR 内网穿透 需要内网的机器的强大的CPU 给AI识别提供助力 借用了腾讯云内网穿透来联通 腾讯云服务器运行的为服务端， 局域网内机子运行的为客户端 NAS机器称为访问端 一 下载 frp包 按推荐linux下载了 0.37或者0.38 试验下来使用稳定 wget https://github.com/fatedier/frp/releases/download/v0.38.0/frp_0.38.0_linux_amd64.tar.gz 二 服务端安装 执行tar -zxvf frp_0.38.0_linux_amd64.tar.gz解压 执行 cd frp_0.38.0_linux_amd64/进入文件夹 修改配置文件#三 服务端配置 sudo chmod 755 ./frps 赋予 启动运行 在安装好的目录内 执行./frps -c ./frps.ini前台启动命令 后期可以ctrl+c 终止程序，再执行nohup ./frps -c ./frps.ini \u0026 后台保持启动 _后期还可以设置自动运行 #TODO： 三 服务端配置 [common] bind_addr=0.0.0.0 bind_port = 7000 token=12345678 dashboard_port = 7500 dashboard_user = admin dashboard_pwd = admin123 配置说明： “bind_addr\"是服务器本地IP，不改。 “bind_port\"是frp监听端口。 “token\"是验证token建议设置上。 “dashboard_port\"是frp面板端口。 “dashboard_user\"“dashboard_pwd\"是面板的账户密码。 token 建议复杂一些，屏蔽一些扫描访问 四 访问frp控制面板 面板仅供参考，可用可不用。访问 http://服务器ip:7500 上面配置的7500端口，使用上面配置的用户名和密码 admin/admin123 五 客户端配置修改 客户端与服务端下载同样的文件 frp_0.38.0_linux_amd64.tar.gz 创建文件夹，执行tar -zxvf frp_0.38.0_linux_amd64.tar.gz解压 然后进入， 编辑客户端配置\"frpc.ini\"文件 [common] server_addr = 公网IP 腾讯服务器的地址 server_port = 7000 上面服务端配置的端口 token=1235678 相当于密码 [RDP] type = tcp local_ip = 127.0.0.1 本地回环地址 local_port = 8060 局域网客户端的端口 remote_port = 6000 服务端的端口，用于给访问端使用 说明： 客户端连接腾讯云的地址 公网IP 端口7000 token 访问端连接腾讯云的公网IP 6000 ，会frps转到 客户端的8060端口 六 客户端连接服务端 执行./frpc -c ./frpc.ini前台启动命令 连接服务端 后期可以ctrl+c 终止程序，再执行nohup ./frpc -c ./frpc.ini \u0026 后台保持启动 七 MT Photo AI 跑 ai的机器使用的ubuntu系统 安装docker 下载镜像 sudo docker pull mtphotos/mt-photos-ai 运行脚本 #API_AUTH_KEY自行设置 sudo docker run -i -p 8060:8000 -e API_AUTH_KEY=mt_photos_ai_extra_secret --name mt-photos-ai2 mtphotos/mt-photos-ai:latest 会监听 8060端口 可以使用下面命令来看看通不通 curl --location --request POST 'http://127.0.0.1:8060/check' \\ --header 'api-key: mt_photos_ai_extra_secret' 八 跑通整个链路 MT Photo 调用 公网IP:6000 端口 api-key FRPS 会去调用 客户端的 8060端口 九 是否需要开机启动 目前使用的功能是一个不常用的功能，FRPS连接没有识别来源所以计划随用隋开，不自动启动。 9.1 设置云服务器端开机自启动 执行sudo vim /etc/systemd/system/frps.service创建服务，编辑如下 [Unit] Description=frps daemon After=syslog.target network.target Wants=network.target [Service] Type=simple ExecStart=/etc/frps/frp_0.38.0_linux_amd64/frps -c /etc/frps/frp_0.38.0_linux_amd64/frps.ini # 编辑的时候一定要删除注释 这里更改为自己安装frps的绝对路径 Restart= always RestartSec=1min [Install] WantedBy=multi-user.target 开启自启动 执行如下指令 #启动frps systemctl daemon-reload systemctl start frps #设置为开机启动 systemctl enable frps 9.2 设置局域网机子frpc开机自启动 执行sudo vim /etc/systemd/system/frpc.service创建服务，编辑如下 [Unit] Description=frpc daemon After=syslog.target network.target Wants=network.target [Service] Type=simple ExecStart=/home/wentao/frps/frp_0.37.0_linux_amd64/frpc -c /home/wentao/frps/frp_0.37.0_linux_amd64/frpc.ini # 编辑的时候一定要删除注释 这里更改为自己安装frpc的绝对路径 Restart= always RestartSec=1min [Install] WantedBy=multi-user.target 开启自启动 执行如下指令 #启动frpc sudo systemctl daemon-reload sudo systemctl start frpc #设置为开机启动 sudo systemctl enable frpc 十、复杂配置 以下配置中密码和公网IP都使用XX进行了代替，复制使用时请注意修改 远程服务端frps.ini [common] # frp监听的端口，默认是7000 bind_port = 7000 # 授权码,请自定义更改 token = XXXXX # 这个token之后在客户端会用到 # frp管理后台端口，请按自己需求更改 dashboard_port = 7500 # frp管理后台用户名和密码，请改成自己的 dashboard_user = admin dashboard_pwd = XXXXX enable_prometheus = true # frp日志存放位置、日志等级及日志存储最大天数 log_file = /var/log/frps.log log_level = info log_max_days = 7 客户端的frpc.ini文件 [common] # 远程服务器ip，远程frp服务端口以及远程登录密码 server_addr = 119.XX.XX.119 server_port = 7000 token = XXXXX # 日志存放位置、日志等级及日志存储最大天数 log_file = /var/log/frpc.log log_level = info log_max_days = 7 # 将本地机的22端口映射至远程20022端口 中括号内[ssh]只作为标识，可自定义 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 8060 remote_port = 6000 # 将本机的5901端口映射至远程25901端口 [vnc] type = tcp local_ip = 127.0.0.1 local_port = 8000 remote_port = 6001 # 将本机所在局域网内的192.168.0.129机子的5901端口映射至远程55901端口 [tsj-vnc] type = tcp local_ip = 192.168.0.129 local_port = 5901 remote_port = 55901 # 代理本机所在的内网，即若用户设置代理为公网IP+端口即可访问本机所在内网，使用的是socks5代理协议，plugin_user及后面的可设置可不设，但不设的风险较大 [socks5_proxy] type = tcp remote_port = 7890 plugin = socks5 plugin = socks5 plugin_user = name plugin_passwd = password use_encryption = true use_compression = true 重启frp服务 ","date":"2024-11-06","objectID":"/posts/mt-photos/:0:0","tags":["blog","网络配置"],"title":"MT-Photos","uri":"/posts/mt-photos/"},{"categories":"学习总结","content":"【Android Framework系列】第3章 Zygote进程相关_android zygote进程-CSDN博客 1 Zygote简介 Zygote是Android中最重要的一个进程，Zygote进程和Init进程、SystemServer进程是Android最重要的三大进程。Zygote是Android系统创建新进程的核心进程，负责启动Dalvik虚拟机，加载一些必要的系统资源和系统类，启动system_server进程，随后进入等待处理app应用请求。 在Android系统中，应用程序进程都是由Zygote进程孵化出来的，而Zygote进程是由Init进程启动的。Zygote进程在启动时会创建一个Dalvik虚拟机实例，每当它孵化一个新的应用程序进程时，都会将这个Dalvik虚拟机实例复制到新的应用程序进程里面去，从而使得每一个应用程序进程都有一个独立的Dalvik虚拟机实例。 Zygote涉及的类： frameworks/base/cmds/app_process/app_main.cpp frameworks/base/core/jni/AndroidRuntime.cpp frameworks/base/core/java/com/android/internal/os/ - Zygote.java - ZygoteInit.java - ZygoteServer.java - ZygoteConnection.java 2 Zygote启动 本文基于Android10（Q）的源码做分析 2.1 init进程解析init.rc脚本 Zygote由init进程解析init.rc脚本启动的。脚本传入app_process的main方法做分割，根据字符串命令做相应逻辑。 现在机器分为32位和64位，Zygote的启动脚本init.rc也各有区别: init.zygote32.rc：zygote进程对应的执行程序是app_process(纯32bit模式) init.zygote64.rc：zygote进程对应的执行程序是app_process64(纯64bit模式) init.zygote32_64.rc：启动两个zygote进程，对应的执行程序分别是app_process32(主模式)、app_process64 init.zygote64_32.rc：启动两个zygote进程，对应的执行程序分别是app_process64(主模式)、app_process32 zygote要执行的程序便是system/bin/app_process，它的源代码在app_main.cpp。我们先来看看app_main是如何处理脚本命令： frameworks/base/cmds/app_process/app_main.cpp 165 #if defined(__LP64__) 166 static const char ABI_LIST_PROPERTY[] = \"ro.product.cpu.abilist64\"; 167 static const char ZYGOTE_NICE_NAME[] = \"zygote64\"; 168 #else 169 static const char ABI_LIST_PROPERTY[] = \"ro.product.cpu.abilist32\"; 170 static const char ZYGOTE_NICE_NAME[] = \"zygote\"; 171 #endif 172 173 int main(int argc, char* const argv[]) 174 { ...... 256 // Parse runtime arguments. Stop at first unrecognized option. 257 bool zygote = false; 258 bool startSystemServer = false; 259 bool application = false; 260 String8 niceName; 261 String8 className; 262 263 ++i; // Skip unused \"parent dir\" argument. 264 while (i \u003c argc) { 265 const char* arg = argv[i++]; 266 if (strcmp(arg, \"--zygote\") == 0) { 267 zygote = true; 268 niceName = ZYGOTE_NICE_NAME; 269 } else if (strcmp(arg, \"--start-system-server\") == 0) { 270 startSystemServer = true; 271 } else if (strcmp(arg, \"--application\") == 0) { 272 application = true; 273 } else if (strncmp(arg, \"--nice-name=\", 12) == 0) { 274 niceName.setTo(arg + 12); 275 } else if (strncmp(arg, \"--\", 2) != 0) { 276 className.setTo(arg); 277 break; 278 } else { 279 --i; 280 break; 281 } 282 } ...... 309 if (startSystemServer) { 310 args.add(String8(\"start-system-server\")); 311 } ...... 331 if (!niceName.isEmpty()) { 332 runtime.setArgv0(niceName.string(), true /* setProcName */); 333 } 334 335 if (zygote) { 336 runtime.start(\"com.android.internal.os.ZygoteInit\", args, zygote); 337 } else if (className) { 338 runtime.start(\"com.android.internal.os.RuntimeInit\", args, zygote); 339 } else { 340 fprintf(stderr, \"Error: no class name or --zygote supplied.\\n\"); 341 app_usage(); 342 LOG_ALWAYS_FATAL(\"app_process: no class name or --zygote supplied.\"); 343 } 344 } 我们拿init.zygote64.rc为例： 1 service zygote /system/bin/app_process64 -Xzygote /system/bin --zygote --start-system-server 2 class main 3 priority -20 4 user root 5 group root readproc reserved_disk 6 socket zygote stream 660 root system 7 socket usap_pool_primary stream 660 root system 8 onrestart write /sys/android_power/request_state wake 9 onrestart write /sys/power/state on 10 onrestart restart audioserver 11 onrestart restart cameraserver 12 onrestart restart media 13 onrestart restart netd 14 onrestart restart wificond 15 writepid /dev/cpuset/foreground/tasks 主要是这个脚本命令：service zygote /system/bin/app_process64 -Xzygote /system/bin --zygote --start-system-server 实际上会被分割成： service：服务标识 zygote：表示要开启的服务名字 /system/bin/app_process64：服务对应的路径 -Xzygote：作为虚拟机启动时所需要的参数,在AndroidRuntime.cpp中的 startVm() 中调用JNI_CreateJavaVM 使用到 /system/bin：代表虚拟机程序所在目录,因为 app_process 可以不和虚拟机在一个目录,所以 app_process 需要知道虚拟机所在的目录 –zygote ：指明以 ZygoteInit 类作为入口,否则需要指定需要执行的类名 –start-system-server：仅在有 –zygote 参数时可用,告知 ZygoteInit 启动完毕后孵化出的第一个进程是 SystemServer 第一个if中\"--zygote\"命中，zygote变量置为true表示要启动zygote进程，并将进程名改成了zygote或zygote64","date":"2024-11-06","objectID":"/posts/zygote%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/:0:0","tags":["blog","Framework"],"title":"Zygote进程相关","uri":"/posts/zygote%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/"},{"categories":["Android"],"content":" 根据开机的阶段，有一些优化开机速度的空间 1. bootloader阶段 这边涉及的系统的稳定性，能修改的地方不多。 最多的是去处log，对性能提升不明显，并且对后期问题的分析有比较大的影响。 或者通过属性的控制，来控制是否打印和打印的等级。 system/core/logd/LogBuffer.cpp int get_log_level() { char buf[PROPERTY_VALUE_MAX]; memset(buf, 0, PROPERTY_VALUE_MAX); property_get(\"persist.xxx.level\", buf, \"\"); return buf[0]; } ​ int loglevl = get_log_level(); int LogBuffer::log(log_id_t log_id, log_time realtime, uid_t uid, pid_t pid, pid_t tid, const char* msg, uint16_t len) { if (log_id \u003e= LOG_ID_MAX) { return -EINVAL; } // 通过属性控制log输出 if (length \u003e 0 \u0026\u0026 loglevl \u003c log_id) { return -EINVAL; } ​ } 2 kernel阶段 对于kernel 阶段的有， 对于不影响开机的modle ，可以建议延迟加载。 可以等zygote启动后，在early-boot或boot阶段去加载ko, 让zygote早点起来 比如蓝牙和wifi的ko驱动 3 Init阶段 3.1 zygote 在 late-init之后启动 # Mount filesystems and start core system services. on late-init trigger early-fs # Mount fstab in init.{$device}.rc by mount_all command. Optional parameter # '--early' can be specified to skip entries with 'latemount'. # /system and /vendor must be mounted by the end of the fs stage, # while /data is optional. trigger fs trigger post-fs # Mount fstab in init.{$device}.rc by mount_all with '--late' parameter # to only mount entries with 'latemount'. This is needed if '--early' is # specified in the previous mount_all command on the fs stage. # With /system mounted and properties form /system + /factory available, # some services can be started. trigger late-fs # Now we can mount /data. File encryption requires keymaster to decrypt # /data, which in turn can only be loaded when system properties are present. trigger post-fs-data # Load persist properties and override properties (if enabled) from /data. trigger load_persist_props_action # Should be before netd, but after apex, properties and logging is available. trigger load_bpf_programs # Now we can start zygote for devices with file based encryption # 触发zygote启动 trigger zygote-start # Remove a file to wake up anything waiting for firmware. trigger firmware_mounts_complete trigger early-boot trigger boot 3.2 并行执行uevent(enable_parallel_restorecon) vendor/ueventd.rc中加入parallel_restorecon enable parallel_restorecon enable 3.3 CPU 打开性能模式 1 开机的时候，cpu开启性能模式 on early-init write /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor performance # 查看当前频率 # cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq 2 开机后关闭,改成自动适应 on property:sys.boot_completed=1 write /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor schedutil 4 移除没有用到的模块 比如： 如CI模块 on post-fs-data insmod /vendor/lib/modules/cimax-usb.ko insmod /vendor/lib/modules/ci.ko 5 延迟vendor/etc/init下的非关键服务 放在early-boot或者boot阶段执行，加快zygote的启动 // 放在early-boot或者boot阶段执行 on boot start xxx service xxx /system/bin/xxx user root group system 6 zygote classloader懒加载， 懒加载会比直接加载更耗内存，懒加载是通过system-server发送指令给zygote做加载相关动作，在发送指令前，system-server会加载一部分自己使用的类，会和zygote中存在相同的一部分备份 service zygote /system/bin/app_process -Xzygote /system/bin --zygote --start-system-server --enable-lazy-preload zygote 添加 task_profiles ProcessCapacityHigh MaxPerformance service zygote /system/bin/app_process -Xzygote /system/bin --zygote --start-system-server --enable-lazy-preload class main priority -20 user root group root readproc reserved_disk socket zygote stream 660 root system socket usap_pool_primary stream 660 root system onrestart exec_background - system system -- /system/bin/vdc volume abort_fuse onrestart write /sys/power/state on onrestart restart audioserver onrestart restart cameraserver onrestart restart media onrestart restart netd onrestart restart wificond task_profiles ProcessCapacityHigh MaxPerformance 精简preload的classes , 比如可以去掉如下class 根据项目的时间情况 如果需要再做一些大的裁剪，可以使用frameworks\\base\\config\\generate-preloaded-classes.sh下的脚本来生成preloaded-classes // 生物识别 android.hardware.biometrics // 人脸识别 android.hardware.face // 打印服务 android.hardware.fingerprint android.print. // 部分定位相关, 还有GPS定位相关 android.hardware.location com.android.internal.location.GpsNetInitiatedHandler android.location.Gnss* // 手机通话相关 android.telephony. android.telecom. com.android","date":"2024-11-06","objectID":"/posts/%E5%BC%80%E6%9C%BA%E4%BC%98%E5%8C%96/:0:0","tags":["blog","Framework"],"title":"开机优化","uri":"/posts/%E5%BC%80%E6%9C%BA%E4%BC%98%E5%8C%96/"},{"categories":["Android"],"content":"开机流程 bootloader 引导系统 内核启动 idle 流程图 Zygote 启动 Zygote进程相关 zygote的启动是在 init 进程启动后，解析init.rc文件创建的： import /system/etc/init/hw/init.${ro.zygote}.rc #这个里面会根据平台的不同，选择32位，还是64位。 # system/core/rootdir/init.zygote64.rc service zygote /system/bin/app_process64 -Xzygote /system/bin --zygote --start-system-server --socket-name=zygote class main priority -20 user root group root readproc reserved_disk socket zygote stream 660 root system socket usap_pool_primary stream 660 root system onrestart exec_background - system system -- /system/bin/vdc volume abort_fuse onrestart write /sys/power/state on # NOTE: If the wakelock name here is changed, then also # update it in SystemSuspend.cpp onrestart write /sys/power/wake_lock zygote_kwl onrestart restart audioserver onrestart restart cameraserver onrestart restart media onrestart restart media.tuner onrestart restart netd onrestart restart wificond task_profiles ProcessCapacityHigh MaxPerformance critical window=${zygote.critical_window.minute:-off} target=zygote-fatal ","date":"2024-11-06","objectID":"/posts/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/:0:0","tags":["blog","Framework"],"title":"启动流程分析","uri":"/posts/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"},{"categories":null,"content":"git clone –recursive https://github.com/huang8604/huang8604.github.io.git 录屏传输 录屏方法 录屏原理 1 创建虚拟屏幕，把内容绘制到屏幕绑定的 surface 中 针对第三方的应用，由于缺少权限。 需要通过 MediaProjection 的方式创建 projectionManager = (MediaProjectionManager) getSystemService(MEDIA_PROJECTION_SERVICE); meidaProjection = projectionManager.getMediaProjection(resultCode,data); //创建前台通知 //mediac 创建的surface //创建虚拟屏幕 virtualDisplay = mediaProjection.createVirtualDisplay(\"name\",width,height,dpi,flag..mirro,surface,null,null); 对于系统应用，可以直接创建虚拟屏幕 virtualDisplay = ((DisplayManager)getsystemservice(DISPLAY_SERVIcE)).createvirtualDisplay(\"Mainscreen\", width, height, dpi,surface,flgs: 1 \u003c 10 | DisPlayManager.VIRTUAL_DISPLAY_FLAG PRESENTATION | DisPlayManage r.VIRTUAL_DISPLAY_FLKG_PUBLIC | DisPlayManager.VIRTUAL_DISPLAY_FLAG_OWN_CONTENT_ONLY); 2 surface 由 mediacodec 创建 3 把 surface 内容输入到 MediaCodec，然后编码 MediaFormat format = createFormate(... bit,fps,); MediaCodec codec = createMediaCodec(); SurfactControl.createDisplay(); configure(codec,format);//codec.configure(format) Surface surface = codec.createInputSurface(); setDisplaySurface(display,surface,...) codec.start(); try{ //开启循环 alive = encode(codec,fd); code.stop(); } finally{ destoryDisplay(diaplay); codec.release(); surface.release(); } private boolean encode(MediaCodec codec, FileDescriptor fd) throws IOException { boolean eof = false; MediaCodec.BufferInfo bufferInfo = new MediaCodec.BufferInfo(); while (!consumeRotationChange() \u0026\u0026 !eof) { int outputBufferId = codec.dequeueOutputBuffer(bufferInfo, -1); eof = (bufferInfo.flags \u0026 MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0; try { if (consumeRotationChange()) { // must restart encoding with new size break; } if (outputBufferId \u003e= 0) { ByteBuffer codecBuffer = codec.getOutputBuffer(outputBufferId); if (sendFrameMeta) {//写入文件头 writeFrameMeta(fd, bufferInfo, codecBuffer.remaining()); } //写入帧数据 IO.writeFully(fd, codecBuffer); } } finally { if (outputBufferId \u003e= 0) { codec.releaseOutputBuffer(outputBufferId, false); } } } return !eof; } private static void setDisplaySurface(IBinder display, Surface surface, int orientation, Rect deviceRect, Rect displayRect, int layerStack) { SurfaceControl.openTransaction(); try { SurfaceControl.setDisplaySurface(display, surface); SurfaceControl.setDisplayProjection(display, orientation, deviceRect, displayRect); SurfaceControl.setDisplayLayerStack(display, layerStack); } finally { SurfaceControl.closeTransaction(); } } private static MediaCodec (Codec codec, String encoderName) throws IOException, ConfigurationException { if (encoderName != null) { Ln.d(\"Creating encoder by name: '\" + encoderName + \"'\"); try { return MediaCodec.createByCodecName(encoderName); } catch (IllegalArgumentException e) { Ln.e(\"Video encoder '\" + encoderName + \"' for \" + codec.getName() + \" not found\\n\" + LogUtils.buildVideoEncoderListMessage()); throw new ConfigurationException(\"Unknown encoder: \" + encoderName); } catch (IOException e) { Ln.e(\"Could not create video encoder '\" + encoderName + \"' for \" + codec.getName() + \"\\n\" + LogUtils.buildVideoEncoderListMessage()); throw e; } } try { MediaCodec mediaCodec = MediaCodec.createEncoderByType(codec.getMimeType()); Ln.d(\"Using video encoder: '\" + mediaCodec.getName() + \"'\"); return mediaCodec; } catch (IOException | IllegalArgumentException e) { Ln.e(\"Could not create default video encoder for \" + codec.getName() + \"\\n\" + LogUtils.buildVideoEncoderListMessage()); throw e; } } 录屏保存为文件 String rootDir = Applistion.getInstance().getExternalCacheDir()+\"...\"; File file = new File(path+\"test.h264\"); FileOutputStream fileOutputStream = null; fileOutputStream = new FileOutputStream(file); fileOutputStream.write(data); fileOutstream.flush(); fileOutStream.close(); fileOutStream = null; file = null; 录屏数据编码传输 服务端 ServerSocket mServer = null; Socket mSocket = null ; void init() { new Thread (new Runnable(){ @Override public void run(){ while(true){ try{ if(mServer == null){ //新建服务socket 服务 mServer = new ServerSocker(6666); mSocket = mServer.acce","date":"2024-11-06","objectID":"/posts/%E6%8A%95%E5%B1%8F%E8%AE%B0%E5%BD%95/:0:0","tags":["blog"],"title":"投屏记录","uri":"/posts/%E6%8A%95%E5%B1%8F%E8%AE%B0%E5%BD%95/"},{"categories":["生活"],"content":"1 . 在github上配置静态页面 参考下面地址： GitHub - CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers 2. 安装HUGO 参考网上资料，安装HUGO，GO。 3. git clone 配置页面 4. obsidia 安装 hugo publish 插件 5. 使用 使用过程比较丝滑的，只要在文档属性里面添加blog属性。 插件回自动生成字段。并且拷贝到 HUGO 目录下去。 然后在HUGO 的目录下，git提交。 github page 会自动生成网页 比如这一篇就是这样 ⚠️upload failed, check dev console ","date":"2024-11-06","objectID":"/posts/%E7%BD%91%E7%BB%9C%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%96%B9%E6%A1%88/:0:0","tags":["blog","网络配置"],"title":"网络博客配置方案","uri":"/posts/%E7%BD%91%E7%BB%9C%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"1 . 在github上配置静态页面 参考下面地址： GitHub - CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers 2. 安装HUGO 参考网上资料，安装HUGO，GO。 3. git clone 配置页面 4. obsidia 安装 hugo publish 插件 5. 使用 使用过程比较丝滑的，只要在文档属性里面添加blog属性。 插件回自动生成字段。并且拷贝到 HUGO 目录下去。 然后在HUGO 的目录下，git提交。 github page 会自动生成网页 比如这一篇就是这样 ⚠️upload failed, check dev console ","date":"2024-11-06","objectID":"/posts/%E7%BD%91%E7%BB%9C%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%96%B9%E6%A1%88/:0:0","tags":["blog","算法研究"],"title":"网络博客配置方案","uri":"/posts/%E7%BD%91%E7%BB%9C%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"【问题描述】 客户需求,要求日文可以在平假字和汉字之间切换. 【分析过程】 刚开始拿到问题的是,查找了日文字库的支持格式,发现日本字库就是包括了平假字和汉字,是这两个的一个集合.不存在两个 字库的方式. 【解决方法】 日文包括了平假字和汉字的集合,那么如果我们要切换平假字和汉字,我们就需要新建一个语言,日文作为平假字的设置,新建 的语言作为汉字的设置方式. 添加一种新的语言 lily方案： 1 确认语言类型 language_code 与 country code 比如 ak-GH language code 就是 ak ， country code就是GH 资源文件夹可以定义为values-ak-rGH 如果没有国家码冲突，可以直接定义 values-ak 我们需要去下面网站查找 language code 和 contry code: language code: https://zh.wikipedia.org/wiki/ISO_639­1 country code : https://zh.wikipedia.org/wiki/ISO_3166­1 如果我们添加的语言在里面,就直接使用,如果不在里面,那我们需要确保我们添加的缩写不能与上面的ISO_639­1重复. 所以我们以hg_JP 作为新添加的一种语言,hg是 language cod, JP是conrty code 由于手表项目 语言客户指定了平假名的 语言类型 ak ，为了适配客户apk，在手表项目中没有新建一个语言，而是在现有ak的语言基础上做修改。同样需要到icu中更改icu数据。 2 添加ICU资源 由于Hiragana/Kanji是给上层语言切换做区分,ICU的资源我们主要是拷贝ja 里面的资源，再进行客制化的修改。 把对应的txt文件放到（external\\icu\\icu4c\\source\\data）目录下coll、curr、lang、locales、region，zone这些子文件夹 中。 主要是检查上面目录里面的ak.txt 文件， 将ja.txt 拷贝至ak.txt文件 主要差异话的，locales 里面的txt文件： 文字差异 午前 午後 1. --- a/icu4c/source/data/locales/ja.txt 2. +++ b/icu4c/source/data/locales/ja.txt 3. @@ -1258,16 +1258,16 @@ 4. } 5. gregorian{ 6. AmPmMarkers{ 7. - \"午前\", 8. - \"午後\", 9. + \"ごぜん\", 10. + \"ごご\", 11. } 12. AmPmMarkersAbbr{ 13. - \"午前\", 14. - \"午後\", 15. + \"ごぜん\", 16. + \"ごご\", 17. } 18. AmPmMarkersNarrow{ 19. - \"午前\", 20. - \"午後\", 21. + \"ごぜん\", 22. + \"ごご\", 23. } 24. DateTimePatterns{ 25. \"H時mm分ss秒 zzzz\", 26. @@ -1345,30 +1345,30 @@ 27. format{ 28. abbreviated{ 29. \"日\", 30. - \"月\", 31. - \"火\", 32. - \"水\", 33. - \"木\", 34. - \"金\", 35. - \"土\", 36. + \"にち\", 37. + \"げつ\", 38. + \"か\", 39. + \"すい\", 40. + \"もく\", 41. + \"きん\", 42. + \"ど\", 43. } 2.1 更新分词规则 客户报出问题，不同语言下，同样字符串，换行不一样。 经过分析。TextView 里面的换行规则是在StaticLayout里面： LineBreaker.Result res = lineBreaker.computeLineBreaks(measuredPara.getMeasuredText(), constraints, mLineCount); /** * Break paragraph into lines. * * The result is filled to out param. * * @param measuredPara a result of the text measurement * @param constraints for a single paragraph * @param lineNumber a line number of this paragraph */ public @NonNull Result computeLineBreaks( @NonNull MeasuredText measuredPara, @NonNull ParagraphConstraints constraints, @IntRange(from = 0) int lineNumber) { return new Result(nComputeLineBreaks( mNativePtr, // Inputs measuredPara.getChars(), measuredPara.getNativePtr(), measuredPara.getChars().length, constraints.mFirstWidth, constraints.mFirstWidthLineCount, constraints.mWidth, constraints.mVariableTabStops, constraints.mDefaultTabStop, lineNumber)); } nComputeLineBreaks 方法是一个Native的方法，用于计算什么时候开始换行 发现换行要根据分词规则去换行，那么日语ja有特定的分词规则，而额外添加的ak没有，使用的就是基础的分词规则。 如果要保持一致，那么就需要将ja的brkitr 资源拷贝一份给ak brkitr 说明 ICU（International Components for Unicode）的 brkitr 库是一个提供文本边界分析的库，brkitr 是“boundary breaker iterator”（边界分割迭代器）的缩写。它用来确定文本中的边界位置，如单词边界、句子边界、行边界和字符边界。这对于文本处理非常关键，尤其是在需要对文本进行分词、换行、选择或光标移动等操作时。 以下是 brkitr 库一些常见的使用场景： 单词边界：用于文本编辑或处理时确定单词的开始和结束，这在文本选择或者双击单词时特别有用。 句子边界：用于文本处理时确定句子的开始和结束，例如，在处理自动大写新句子的首字母或文本摘要时。 行边界：用于文本布局时确定在哪里进行换行，这在UI组件如TextView的文本折行处理中尤其重要。 字符边界：用于确定可分割的字符边界，比如在处理复合字符（如带变音符的字母）时正确地光标定位或者文本选择。 brkitr 库实现了国际化的文本边界规则，支持多种语言和文本规则。它利用Unicode文本分割算法和语言特定的规则来确定这些边界，从而提供准确的文本处理能力。在全球化的应用开发中，正确地识别和处理不同语言的文本边界是非常重要的。 3. 编译ICU资源 lili项目 进入到$AOSP/external/icu/icu4c/source/目录下的 在该目录下执行 ./runConfigureICU Linux命令生成MAKE文件 执行make INCLUDE_UNI_CORE_DATA=1 将第一步生成的external/icu4c/icubuild/data/out/tmp/icudtxxl.dat复制到external/icu4c/stubdata下并改名为 icudtxxl­all.dat覆盖原来的同名文件。 cpexternal/icu/icu4c/source/data/out/tmp/icudt58l.dat $AOSP/external/icu/icu4c/source/stubdata 该方案在A11 上编译失效，烧入手机后 ，载入icu会出错 开不了机器。 编译方案： 首先在工程根目录，进行source ,lunch ，设置环境变量。 然后在 aosp/external/icu/tools 目录下 执行下面脚本：updateicudata.py 会自动config 和编译，然后自动把结果copy 到 stubdata目录。 4.添加语言支持 # sdm429w_law.mk Definedthelocales PRODUCT_LOCALES:=en_US ja_JP ak_GK 5.翻译字符串 在frameworks/base/core/res/res/下新增加一个values­-ak的文件夹,新建一个strings.xml文件，把frameworks翻 译内容放在这个文件内: 对每个app做翻译，在每个app对应的res目录下面建立values­-ak文件夹，并将翻译好的strings.xml放在里面； 6. 添加设置菜单 设置语言主要就是通过 LocalePicker.updateLocale(hiragana); 来实现 import java.util.Locale; import com.android.internal.app.LocalePicker; static final Str","date":"2024-11-06","objectID":"/posts/%E5%A2%9E%E5%8A%A0%E8%AF%AD%E8%A8%80%E6%96%B9%E6%A1%88/:0:0","tags":["实战","blog","Framework"],"title":"增加语言方案","uri":"/posts/%E5%A2%9E%E5%8A%A0%E8%AF%AD%E8%A8%80%E6%96%B9%E6%A1%88/"},{"categories":null,"content":"本博客内容主要集中在 Android 开发和优化相关的话题，包括一些性能工具的使用、Android App 优化知识、Android Framework 知识讲解，性能理论知识讲解等，这里整理了一份目录供大家参考，大家可以挑感兴趣的部分来看。这里不仅仅包含博客中的内容，一些我在 知乎 或者 知识星球 - The Performance 的回答也会放到这里，不过这个目录里面放的都是我原创的博客，另外还收集了一些优秀文章，我也会不定期更新 Android 性能优化必知必会。 博客的每次更新都会更新这篇目录，方便大家查阅。我会尽量保证每周一更，学无止境，与大家共勉，有什么想了解的或者博客中不足的地方，请大家在博客或者知乎、微博、微信留言给我，我会积极改正。 理论知识 Android 性能优化的术、道、器 The Performance 知识星球简介 The Performance 星球茶话会 - 第一期 OS 设计之性能设计 Perfetto 系列 Perfetto 系列目录 Android Perfetto 系列 1：Perfetto 工具简介 Android Perfetto 系列 2：Perfetto Trace 抓取 Android Perfetto 系列 3：熟悉 Perfetto View Systrace 系列 Systrace 工具是分析 Android 性能问题的利器，它可以从一个图形的角度，来展现整机的运行情况。Systrace 工具不仅可以分析性能问题，用它来进行 Framework 的学习也是很好的，这也是我写本系列文章的一个原因 Systrace 简介 Systrace 基础知识 - Systrace 预备知识 Systrace 基础知识 - Why 60 fps ？ Systrace 基础知识 - SystemServer 解读 Systrace 基础知识 - Input 解读 Systrace 基础知识 - Vsync 产生与工作机制解读 Systrace 基础知识 - Vsync-App ：基于 Choreographer 的渲染机制详解 Systrace 基础知识 - MainThread 和 RenderThread 解读 Systrace 基础知识 - Binder 和锁竞争解读 Systrace 基础知识 - Triple Buffer 解读 Systrace 基础知识 - CPU Info 解读 Systrace 基础知识 - SystemServer 解读 Systrace 基础知识 - SurfaceFlinger 解读 Systrace 流畅性实战 1 ：了解卡顿原理 Systrace 流畅性实战 2 ：案例分析: MIUI 桌面滑动卡顿分析 Systrace 流畅性实战 3 ：卡顿分析过程中的一些疑问 Systrace 响应速度实战 1 ：了解响应速度原理 Systrace 响应速度实战 2 ：响应速度实战分析-以启动速度为例 Systrace 响应速度实战 3 ：响应速度延伸知识 Systrace 线程 CPU 运行状态分析技巧 - Runnable 篇 Systrace 线程 CPU 运行状态分析技巧 - Running 篇 Systrace 线程 CPU 运行状态分析技巧 - Sleep 和 Uninterruptible Sleep 篇 流畅性 流畅性主要指的是卡顿、掉帧，对应的英文是 Smooth vs Jank Android 中的卡顿丢帧原因概述 - 方法论 Android 中的卡顿丢帧原因概述 - 系统篇 Android 中的卡顿丢帧原因概述 - 应用篇 Android 中的卡顿丢帧原因概述 - 低内存篇 关于 Android 系统流畅性的一些思考 新的流畅体验，90Hz 漫谈 Android性能优化之过渡绘制(一) Android性能优化之过渡绘制( 二) Android性能优化后续 华为手机刷微博体验更好？技术角度的一些分析和思考 响应速度 响应速度主要指的是 App 冷热启动、界面跳转速度、亮灭屏速度等，对应的英文是 Fast vs Slow Android App 启动优化全记录 知乎 救救你的 StartingWindow Android 中如何计算 App 的启动时间？ Android 应用启动优化:一种 DelayLoad 的实现和原理(上篇) Android 应用启动优化:一种 DelayLoad 的实现和原理(下篇) 内存 主要记录 Android 内存优化相关的知识和工具，以及对系统的影响 Android 中低内存对性能的影响 Android 系统不释放内存吗？ Android 代码内存优化建议-Android 资源篇 Android 代码内存优化建议-Android 官方篇 Android 代码内存优化建议-Java 官方篇 Android 内存优化之一：MAT 使用入门 Android内存优化之二：MAT使用进阶 Android内存优化之三：打开MAT中的Bitmap原图 Framework 知识 博客中 Framework 相关的内容会集中在这里，包括一些 Framework 的运行原理、Framework 问题的解题思路、Framework 优化方法等 当 App 有了系统权限，真的可以为所欲为？ Android 中的“后台无效动画“行为分析 Android 框架问题分析案例 - 谁杀了桌面? Android 中的 Activity Launch Mode 详解 Android 中的 Hardware Layer 详解 Android 平台应用宝和讯飞输入法无障碍服务导致的全局卡顿分析 从用户角度来理解 Android 应用的状态 Android hwui 中 RenderThread 工作流程 HashMap 源码分析 细说Java单例模式 Android 系统开发源码环境搭建 Android App 链式唤醒分析 一个「闰」字引发的事故 - 三星系统重启分析 Android 系统开发系列（1）：Android 12 源代码下载、编译和刷机 App 开发 这里主要记录一些 App 开发相关的博文，由于写的比较早，大家随便看一下就可以了 Android Bottom navigation 规范一：使用方法 Android Bottom navigation 规范二：样式、行为与规格 Android Service：开发自己的通知中心(1):辅助性服务介绍 Android Service：开发自己的通知中心(2):辅助性服务实战 Android开发:Log2File工具类 Android:Ubuntu下执行Adb命令找不到设备 Android小技巧:如何让EditText不自动获取焦点 个人总结和好物推荐 与技术无关，但是可以提高幸福感和工作效率 2023 年的方方面面 回顾 2021 我是 Gracker，这是我的利器 Gracker 的 2018 年度最推荐 - 给辛勤工作的自己一点奖励 陆奇：除了好代码，工程师怎样才算优秀？ 2017 年度最推荐 - 给辛勤工作的自己一点奖励 关于 2017 Android 开发者学习路线(2020 版本) 我的 2020 年读书单 读书笔记 一本讲 Android 流畅性的书，应该有什么内容？ 程序员的修炼-01：绝地反击之术 程序员的修炼-02：编程之道 程序员的修炼-03：Web 设计原则 程序员的修炼-04：关于测试的一些思考 程序员的修炼-05：了解你的用户 程序员的修炼-06：互联网那些事 程序员的修炼-07：游戏与编程 程序员的修炼-08：阅读之美 性能优化典范和 Tips 性能优化典范是 Google 出品的一系列性能相关的短视频，总共出了 6 季，之前想的是每一集都来一个文章配合，后面发现不是很现实；Android Tips 则是翻译的另外一个博主的文章 Android性能优化典范综述 Android性能优化典范之Render Performance Android性能优化典范之Understanding Overdraw Android性能优化典范之Understanding VSYNC Android性能优化典范之Profile GPU Rendering Android Tips 1 Android Tips 2 Android Tips 3 Android Tips 4 Android Tips 5 知乎问答 知乎专栏会搬运一部分文章，这里只贴一些高赞的回答 个人知乎主页 ，欢迎大家点赞关注 如何看待小米部分机型运行《王者荣耀》时两个大核被锁 Flyme 5 相对于 Flyme 4 流畅得脱胎换骨，其中根本的变化是什么？ Android 系统不释放内存吗？ 了解Android的Framework层对工作有什么帮助吗？ 怎么看待三星大量手机在今天（5.23）凌晨系统崩溃并数据丢失？ ","date":"2024-11-06","objectID":"/posts/%E7%BD%AE%E9%A1%B6%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95/:0:0","tags":["clippings","转载","blog"],"title":"「置顶」博客文章目录","uri":"/posts/%E7%BD%AE%E9%A1%B6%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95/"},{"categories":["Android","ubuntu"],"content":"新版本的CTS工具，需要连接外网才能够测试，以往的版本是不需要的。 根据出错log，和源码 Site Unreachable DISABLE_CLEARCUT_KEY 出错log java.net.SocketTimeoutException: Connect timed out at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:546) at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) at java.base/java.net.Socket.connect(Socket.java:633) at java.base/sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:304) at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:178) at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:532) at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:637) at java.base/sun.net.www.protocol.https.HttpsClient.\u003cinit\u003e(HttpsClient.java:266) at java.base/sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:380) at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:193) at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1242) at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1128) at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:179) at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1430) at java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1401) at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:220) at com.android.tradefed.clearcut.ClearcutClient.sendToClearcut(ClearcutClient.java:344) at com.android.tradefed.clearcut.ClearcutClient.lambda$flushEvents$1(ClearcutClient.java:322) 问题源码： /** Client that allows reporting usage metrics to clearcut. */ public class ClearcutClient { public static final String DISABLE_CLEARCUT_KEY = \"DISABLE_CLEARCUT\"; /** Returns True if clearcut is disabled, False otherwise. */ @VisibleForTesting boolean isClearcutDisabled() { return \"1\".equals(System.getenv(DISABLE_CLEARCUT_KEY)); } /** * Create Client with customized posting URL and forcing whether it's internal or external user. */ @VisibleForTesting protected ClearcutClient(String url, String subToolName) { mDisabled = isClearcutDisabled(); // We still have to set the 'final' variable so go through the assignments before returning if (!mDisabled \u0026\u0026 isGoogleUser()) { mLogSource = INTERNAL_LOG_SOURCE; mUserType = UserType.GOOGLE; } else { mLogSource = EXTERNAL_LOG_SOURCE; mUserType = UserType.EXTERNAL; } if (url == null) { mUrl = CLEARCUT_PROD_URL; } else { mUrl = url; } mRunId = UUID.randomUUID().toString(); mExternalEventQueue = new ArrayList\u003c\u003e(); mSubToolName = subToolName; if (mDisabled) { return; } 根据代码，在测试前，需要 export DISABLE_CLEARCUT_KEY=1 mHasServerSideConfig 出错log Caused by: java.net.ConnectException: 连接超时 at java.base/sun.nio.ch.Net.connect0(Native Method) at java.base/sun.nio.ch.Net.connect(Net.java:579) at java.base/sun.nio.ch.Net.connect(Net.java:568) at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588) at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) at java.base/java.net.Socket.connect(Socket.java:633) at java.base/sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:304) at java.base/sun.security.ssl.BaseSSLSocketImpl.connect(BaseSSLSocketImpl.java:174) at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:183) at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:532) at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:637) at java.base/sun.net.www.protocol.https.HttpsClient.\u003cinit\u003e(HttpsClient.java:266) at java.base/sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:380) at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:193) at java.base/","date":"2024-11-06","objectID":"/posts/cts-%E5%9C%A8%E5%86%85%E7%BD%91%E6%9C%BA%E5%99%A8%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95/:0:0","tags":["blog","测试工具"],"title":"CTS 在内网机器如何测试","uri":"/posts/cts-%E5%9C%A8%E5%86%85%E7%BD%91%E6%9C%BA%E5%99%A8%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95/"},{"categories":["学习总结"],"content":"【Android Framework系列】第3章 Zygote进程相关_android zygote进程-CSDN博客 1 Zygote简介 Zygote是Android中最重要的一个进程，Zygote进程和Init进程、SystemServer进程是Android最重要的三大进程。Zygote是Android系统创建新进程的核心进程，负责启动Dalvik虚拟机，加载一些必要的系统资源和系统类，启动system_server进程，随后进入等待处理app应用请求。 在Android系统中，应用程序进程都是由Zygote进程孵化出来的，而Zygote进程是由Init进程启动的。Zygote进程在启动时会创建一个Dalvik虚拟机实例，每当它孵化一个新的应用程序进程时，都会将这个Dalvik虚拟机实例复制到新的应用程序进程里面去，从而使得每一个应用程序进程都有一个独立的Dalvik虚拟机实例。 Zygote涉及的类： frameworks/base/cmds/app_process/app_main.cpp frameworks/base/core/jni/AndroidRuntime.cpp frameworks/base/core/java/com/android/internal/os/ - Zygote.java - ZygoteInit.java - ZygoteServer.java - ZygoteConnection.java 2 Zygote启动 本文基于Android10（Q）的源码做分析 2.1 init进程解析init.rc脚本 Zygote由init进程解析init.rc脚本启动的。脚本传入app_process的main方法做分割，根据字符串命令做相应逻辑。 现在机器分为32位和64位，Zygote的启动脚本init.rc也各有区别: init.zygote32.rc：zygote进程对应的执行程序是app_process(纯32bit模式) init.zygote64.rc：zygote进程对应的执行程序是app_process64(纯64bit模式) init.zygote32_64.rc：启动两个zygote进程，对应的执行程序分别是app_process32(主模式)、app_process64 init.zygote64_32.rc：启动两个zygote进程，对应的执行程序分别是app_process64(主模式)、app_process32 zygote要执行的程序便是system/bin/app_process，它的源代码在app_main.cpp。我们先来看看app_main是如何处理脚本命令： frameworks/base/cmds/app_process/app_main.cpp 165 #if defined(__LP64__) 166 static const char ABI_LIST_PROPERTY[] = \"ro.product.cpu.abilist64\"; 167 static const char ZYGOTE_NICE_NAME[] = \"zygote64\"; 168 #else 169 static const char ABI_LIST_PROPERTY[] = \"ro.product.cpu.abilist32\"; 170 static const char ZYGOTE_NICE_NAME[] = \"zygote\"; 171 #endif 172 173 int main(int argc, char* const argv[]) 174 { ...... 256 // Parse runtime arguments. Stop at first unrecognized option. 257 bool zygote = false; 258 bool startSystemServer = false; 259 bool application = false; 260 String8 niceName; 261 String8 className; 262 263 ++i; // Skip unused \"parent dir\" argument. 264 while (i \u003c argc) { 265 const char* arg = argv[i++]; 266 if (strcmp(arg, \"--zygote\") == 0) { 267 zygote = true; 268 niceName = ZYGOTE_NICE_NAME; 269 } else if (strcmp(arg, \"--start-system-server\") == 0) { 270 startSystemServer = true; 271 } else if (strcmp(arg, \"--application\") == 0) { 272 application = true; 273 } else if (strncmp(arg, \"--nice-name=\", 12) == 0) { 274 niceName.setTo(arg + 12); 275 } else if (strncmp(arg, \"--\", 2) != 0) { 276 className.setTo(arg); 277 break; 278 } else { 279 --i; 280 break; 281 } 282 } ...... 309 if (startSystemServer) { 310 args.add(String8(\"start-system-server\")); 311 } ...... 331 if (!niceName.isEmpty()) { 332 runtime.setArgv0(niceName.string(), true /* setProcName */); 333 } 334 335 if (zygote) { 336 runtime.start(\"com.android.internal.os.ZygoteInit\", args, zygote); 337 } else if (className) { 338 runtime.start(\"com.android.internal.os.RuntimeInit\", args, zygote); 339 } else { 340 fprintf(stderr, \"Error: no class name or --zygote supplied.\\n\"); 341 app_usage(); 342 LOG_ALWAYS_FATAL(\"app_process: no class name or --zygote supplied.\"); 343 } 344 } 我们拿init.zygote64.rc为例： 1 service zygote /system/bin/app_process64 -Xzygote /system/bin --zygote --start-system-server 2 class main 3 priority -20 4 user root 5 group root readproc reserved_disk 6 socket zygote stream 660 root system 7 socket usap_pool_primary stream 660 root system 8 onrestart write /sys/android_power/request_state wake 9 onrestart write /sys/power/state on 10 onrestart restart audioserver 11 onrestart restart cameraserver 12 onrestart restart media 13 onrestart restart netd 14 onrestart restart wificond 15 writepid /dev/cpuset/foreground/tasks 主要是这个脚本命令：service zygote /system/bin/app_process64 -Xzygote /system/bin --zygote --start-system-server 实际上会被分割成： service：服务标识 zygote：表示要开启的服务名字 /system/bin/app_process64：服务对应的路径 -Xzygote：作为虚拟机启动时所需要的参数,在AndroidRuntime.cpp中的 startVm() 中调用JNI_CreateJavaVM 使用到 /system/bin：代表虚拟机程序所在目录,因为 app_process 可以不和虚拟机在一个目录,所以 app_process 需要知道虚拟机所在的目录 –zygote ：指明以 ZygoteInit 类作为入口,否则需要指定需要执行的类名 –start-system-server：仅在有 –zygote 参数时可用,告知 ZygoteInit 启动完毕后孵化出的第一个进程是 SystemServer 第一个if中\"--zygote\"命中，zygote变量置为true表示要启动zygote进程，并将进程名改成了zygote或zygote64","date":"2024-11-06","objectID":"/posts/zygote%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/:0:0","tags":["blog","Framework"],"title":"Zygote进程相关","uri":"/posts/zygote%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/"},{"categories":null,"content":"目标： 任务分析和分解： #一 监听多指事件 #二 任务跨屏移动 一 监听多指事件 监听手指事件可以参考SystemGesturesPointerEventListener.java 通过继承实现PointerEventListener 实现 import android.view.WindowManagerPolicyConstants.PointerEventListener; 实现其中的方法： @Override public void onPointerEvent(MotionEvent motionEvent) { //实现其中的 down move up 事件 } 二 任务跨屏移动 我们在DisplayContent里面做功能实现 mRootWindowContainer.moveRootTaskToDisplay(rootTaskId,otherDisplay.mDisplayId,true);//把task移动到另一屏 三 移动动画方案-虚拟镜像屏幕 方案： 镜像模式与真实镜像坐标是同步的。 先创建镜像屏幕图层，当前状态应该是镜像图层盖在源屏幕上面。 将源屏幕图层，移动到屏幕1的左边。镜像对应的需要在屏幕上显示。 移动原有屏幕画面到右侧显示器 判断开始动画移动 – \u003e 更改图层坐标，动画结束后，判断是否移位 1 移位动画，2 复位动画 创建镜像屏幕 //添加图层 SurfaceControl copyTaskSc = null; SurfaceControl copyTaskBuffer = null; SurfaceControl realWindwosSateBuffer = null; //创建一个镜像图层 if(copyTaskSc == null){ makeChildSurface(null).setName(\"copyTaskSc\") .setParent(getWindowingLayer()) .build();// getWindowingLayer 在app上吗 } if(copyTaskBuffer == null){ //镜像一个task的 surfacecontrol ---- copyTaskBuffer //surfacecontrol里面其实有一个layer copyTaskBuffer = SurfaceContrl.mirrorSurface(rootTask.getSurfaceControl()); //原生的一个 realWindwosSateBuffer = rootTask.getSurfaceControl(); //获取一个事务 SurfaceContrl.Transaction t = mWmSerivce.mTransactionFactory.get(); //把 拷贝的 copyTaskBuffer 放到了 copyTaskSc 下面，copyTaskSc 在原来的屏幕下面 t.reparent(copyTaskBuffer,copyTaskSc); //显示图层 t.show(copyTaskSc); t.show(copyTaskBuffer); //平移 Matrix matrix = new Matrix(); matrix.reset(); matrix.postTranslate(100,0); //往平移 t.setMatrix(copyTaskBuffer,matrix,new float[9]) t.apply(); } 移动屏幕到右侧，并且设置左边屏幕外面。 //由于移动到2屏幕，需要再移动到屏幕外，会有闪屏的情况，需要再移动之前，先进行移动。 //直接调用下面的 startMoveCurrentScreenTask（0，0） mRootWindowContainer.moveRootTaskToDisplay(rootTaskId,otherDisplay.mDisplayId,true);//把task移动到另一屏 动画 //移动镜像图层 public void startMoveCurrentScreenTask(int x ,int y){ if(copyTaskBuffer != null){ SurfaceControl.Transaction t = mWnService.mTrasactionFactory.get(); //屏幕2 Matrix matrix = new Matrix(); int width = getDisaplayINfog().logicalWIdth; matrix.postTranslate(-width+x,0); //屏幕1 matrix = new Matrix(); matrix.reset(); matrix.postTranslate(width,y); t.setMatrix(copyTaskBuffer,matrix,new floatp[9]); t.setMatix(reaWindowStateBuffer,matrix,new floatp[9]); t.aaply(); } } //真实图层 也需要操作,先移动到最左侧 reaWindowStateBuffer = rootTask.getSurfaceControl(); 手指抬起后处理流程： 如果是自动移动屏幕2，则offsetX —–\u003e 1440（width） 如果是自动移动屏幕1，则offsetX —–\u003e 0（原点） case MotionEvent.ACTION_POINTER_UP: case MotionEvent.ACTION_UP: startAutoMove(offsetX, .xxx \u003e xxx ? 1: 0) void startAutoMove(int offsetX, int destDisplay){ int endX = destDisplay 0 or width //判断最后屏幕。然后动画结束位置 ValueAnimator valueAnimiator = ValueAnimator.ofInt(offsetx,end); valueAnimator.addUpdateListener(new ValueAnimator.AnimatorUpdateListener(){ public onUpdate(){ int current = int animate.getValue(); startmovecurrentScreenTask(x,y); } }); valueAnimator.setInterpolator(); valueAnimator.setDuration(); valueAnimator.staret(); } onAnimationEnd //移除图层 SurfaceControl.Transaction t = mWnService.mTrasactionFactory.get(); t.remove(copyBuffer); t.remove(copyTaskSc); t.apply(); copyBuffer = null; copyTaskSc = null; //动画如果是返回，需要把原镜像move回去。 mRootWindowContainer.moveRootTaskToDisplay(mCurrentTaskId,mDisplayId.mDisplayId,true); //移动原镜像图层，从屏幕外再移动回来。 matrix.reset(); setMatrix()//归零 targetActivity.mLauncherTaskBehind =false mRootWindowContainer.ensureActiviesVisible(); //桌面可以可见 targetActivity.mLauncherTaskBehind =true 镜像模式，源界面发生变化，镜像坐标也会变化 问题分析： adb shell dumpsys SurfaceFlinger adb shell dumpsys input ToDo: ![image-20241017173033900](/Users/huangwentao/Library/Application Support/typora-user-images/image-20241017173033900.png) ======================================= DisplayContent.java 实现双指监听事件 DoubleScreenMovePoiListerner 继承 PointerEventListener DisplayContext.doTestMoveTaskToOtherDisplay //添加图层 SurfaceControl copyTaskSc = null; SurfaceControl copyTaskBuffer = null; SurfaceControl realWindwosSateBuffer = null; //add by doublescreenmove public void doTestMoveTaskToOtherDisplay() { DisplayContent otherDisplay = null; if (mRootWindowContainer.getChildCount() == 2) {//检测是不是双屏 ot","date":"2024-11-06","objectID":"/posts/%E5%8F%8C%E5%B1%8F%E5%8A%A8%E7%94%BB/:0:0","tags":["clippings","转载","blog","实战"],"title":"双屏动画","uri":"/posts/%E5%8F%8C%E5%B1%8F%E5%8A%A8%E7%94%BB/"},{"categories":["Android","ubuntu"],"content":"reboot_test.sh #Navy add for reboot/factory-reset test #adb reboot #adb reboot factory-reset #默认开关机测试次数 rebootNum=5 #开关机设备ID号 deviceId=null #开关机间隔时间 rebootInterval=30 if [ $# = 1 ];then rebootNum=$1 elif [ $# = 2 ];then rebootNum=$1 deviceId=$2 fi i=1 while [ $i -le $rebootNum ] do if [[ $deviceId =~ \"null\" ]];then echo \"reboot test num\" $i adb reboot else echo \"reboot \"$deviceId\" test num \"$i adb -s $deviceId reboot fi sleep $rebootInterval let i++ done ","date":"2024-11-06","objectID":"/posts/%E8%87%AA%E5%8A%A8%E5%BC%80%E5%85%B3%E6%9C%BA%E8%84%9A%E6%9C%AC/:0:0","tags":["blog","测试工具"],"title":"自动开关机脚本","uri":"/posts/%E8%87%AA%E5%8A%A8%E5%BC%80%E5%85%B3%E6%9C%BA%E8%84%9A%E6%9C%AC/"},{"categories":["学习总结","AMS"],"content":"AMS中Activity栈管理 WMS中app的添加过程 windows 层级树 添加Task 下 windowstate的堆栈 添加DefaultTaskDisplayArea 02-23 14:36:19.116 565 I test2 : DefaultTaskDisplayArea@243571827 addChild child = Task{a13d730 #1 type=home ?? U=0 visible=false visibleRequested=false mode=undefined translucent=true sz=0} 02-23 14:36:19.116 565 I test2 : java.lang.Exception 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.WindowContainer.addChild(WindowContainer.java:727) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.TaskDisplayArea.addChildTask(TaskDisplayArea.java:334) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.TaskDisplayArea.addChild(TaskDisplayArea.java:320) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.Task$Builder.build(Task.java:6551) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.TaskDisplayArea.createRootTask(TaskDisplayArea.java:1066) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.TaskDisplayArea.createRootTask(TaskDisplayArea.java:1040) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.TaskDisplayArea.getOrCreateRootHomeTask(TaskDisplayArea.java:1640) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.RootWindowContainer.setWindowManager(RootWindowContainer.java:1321) 02-23 14:36:19.116 565 I test2 : at com.android.server.wm.ActivityTaskManagerService.setWindowManager(ActivityTaskManagerService.java:1006) 02-23 14:36:19.116 565 I test2 : at com.android.server.am.ActivityManagerService.setWindowManager(ActivityManagerService.java:1923) 02-23 14:36:19.116 565 I test2 : at com.android.server.SystemServer.startOtherServices(SystemServer.java:1595) 02-23 14:36:19.116 565 I test2 : at com.android.server.SystemServer.run(SystemServer.java:939) 02-23 14:36:19.116 565 I test2 : at com.android.server.SystemServer.main(SystemServer.java:649) 02-23 14:36:19.116 565 I test2 : at java.lang.reflect.Method.invoke(Native Method) 添加Task 14:36:22.676 Task{a13d730 #1 type=home ?? U=0 visible=true visibleRequested=false mode=fullscreen translucent=true sz=0} addChild Comparator child = Task{63f31d4 #2 type=undefined A=1000:com.android.settings.FallbackHome U=0 visible=false quested=false mode=undefined translucent=true sz=0} 14:36:22.676 java.lang.Exception 14:36:22.676 at com.android.server.wm.WindowContainer.addChild(WindowContainer.java:694) 14:36:22.676 at com.android.server.wm.Task.addChild(Task.java:5935) 14:36:22.676 at com.android.server.wm.Task.-$$Nest$maddChild(Unknown Source:0) 14:36:22.676 at com.android.server.wm.Task$Builder.build(Task.java:6548) 14:36:22.676 at com.android.server.wm.Task.reuseOrCreateTask(Task.java:5819) 14:36:22.676 at com.android.server.wm.ActivityStarter.setNewTask(ActivityStarter.java:2872) 14:36:22.676 at com.android.server.wm.ActivityStarter.startActivityInner(ActivityStarter.java:1864) 14:36:22.676 at com.android.server.wm.ActivityStarter.startActivityUnchecked(ActivityStarter.java:1661) 14:36:22.676 at com.android.server.wm.ActivityStarter.executeRequest(ActivityStarter.java:1216) 14:36:22.676 at com.android.server.wm.ActivityStarter.execute(ActivityStarter.java:702) 14:36:22.676 at com.android.server.wm.ActivityStartController.startHomeActivity(ActivityStartController.java:179) 14:36:22.676 at com.android.server.wm.RootWindowContainer.startHomeOnTaskDisplayArea(RootWindowContainer.java:1493) 14:36:22.676 at com.android.server.wm.RootWindowContainer.lambda$startHomeOnDisplay$12$com-android-server-wm-RootWindowContainer(RootWindowContainer.java:1434) 14:36:22.676 at com.android.server.wm.RootWindowContainer$$ExternalSyntheticLambda7.apply(Unknown Source:16) 14:36:22.676 at com.android.server.wm.TaskDisplayArea.reduceOnAllTaskDisplayAreas(TaskDisplayArea.java:513) 14:36:22.676 at com.android.server.wm.DisplayArea.reduceOnAllTaskDisplayAreas(DisplayArea.java:404) 14:36:22.676 at com.android.server.wm.DisplayArea.reduceOnAllTaskDisplayAreas(DisplayArea.java:404) 14:36:22.676 at com.android.server.wm.DisplayArea.reduceOnAllTaskDisplayAreas(DisplayArea.java:404","date":"2024-11-06","objectID":"/posts/app-%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/:0:0","tags":["blog","Framework","AMS"],"title":"APP  启动过程","uri":"/posts/app-%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/"},{"categories":null,"content":"背景： Android12高版本以后系统生成的很多data路径下的xml都变成了二进制类型 具体原因分析 代码路径： frameworks/base/core/java/android/util/Xml.java 使用BinaryXmlSerializer最重要原因是： 1、可以有更快的速度 2、更小的体积 如何把二进制变成正常可读xml 方法1： 适合debug等版本上，可以随意进行恢复出厂删除相关的xml的场景 具体操作： 改变属性，删除原来的xml，或者恢复出厂，让系统重新生成xml， 属性修改如下： adb shell setprop persist.sys.binary_xml false 修改后在把相关的xml要进行删除重启触发重新生成xml 方法2： 这种属于已有了这种二进制格式的xml，也不想清除这个xml让重新生成，因为这样可能重新生成的数据就不是原来xml的数据。 所以得考虑把原来的二进制格式的xml 转化成可读xml文件 Android系统中有一部分xml是二进制加密保存的，当我门用adb pull导出查看的时候发现是乱码，不用慌，下面我给大家介绍安卓系统自带的xml加解密工具，位于 /system/bin下，有abx2xml和xml2abx Android xml二进制解压 usage: abx2xml [-i] input [output] adb shell abx2xml zipsrc.xml output.xml //注意：可进入到文件所在目录进行操作，也可以复制文件到sdcard进行操作 //例如我们要查看sdcard下的AndroidDemoZip.xml,手动不指定输出路径，默认覆盖当前XML 1、adb shell 2、cd sdcard 3、abx2xml AndroidDemoZip.xml output.xml Android xml压缩二进制 usage: xml2abx [-i] input [output] adb shell xml2abx inputsrc.xml zipsrc.xml //用法跟解压同理 源码位置： ~/Downloads/Study/Code/LA.QSSI.12.0.r1/frameworks/base/cmds/abx % ll total 56 drwxrwxr-x@ 9 huangwentao staff 288 12 31 2021 . drwxrwxr-x 35 huangwentao staff 1120 9 23 17:45 .. -rw-rw-r-- 1 huangwentao staff 637 12 31 2021 Android.bp -rw-rw-r-- 1 huangwentao staff 0 12 31 2021 MODULE_LICENSE_APACHE2 -rw-rw-r-- 1 huangwentao staff 10694 12 31 2021 NOTICE -rwxrwxr-x 1 huangwentao staff 128 12 31 2021 abx -rwxrwxr-x 1 huangwentao staff 128 12 31 2021 abx2xml drwxrwxr-x 3 huangwentao staff 96 12 31 2021 src -rwxrwxr-x 1 huangwentao staff 128 12 31 2021 xml2abx xml2abx ./system/users/0/appwidgets-read.xml ./system/users/0/appwidgets-binary.xml abx2xml ./system/users/0/appwidgets.xml ./system/users/0/appwidgets-read.xml ","date":"2024-11-06","objectID":"/posts/xml-%E6%A0%BC%E5%BC%8F-%E7%9B%B8%E5%85%B3/:0:0","tags":["blog","PMS","tools"],"title":"xml 格式 相关","uri":"/posts/xml-%E6%A0%BC%E5%BC%8F-%E7%9B%B8%E5%85%B3/"},{"categories":null,"content":"神经网络和深度学习简史 March 17, 2024 TL;DR 本文8200+字，全文阅读约需15分钟。从去年开始，我读了十余本人工智能方面入门的书籍（参见文末附2），酝酿了两个月，花了两周时间写作此文。本文简要回顾了从感知机到深度学习及Hugging Face的历史，并试图以通俗的语言来介绍神经网络和深度学习的原理。 生活中没有什么可怕的东西，只有需要理解的东西。 —— 居里夫人 一 深度信念网络 2006年，加拿大多伦多大学教授杰弗里·辛顿在研究如何训练多层神经网络，他已经在神经网络领域默默耕耘了三十多年，尽管在这个领域他算得上是泰斗级的人物，但由于神经网络在人工智能行业一直不被看好，所以他的研究成果一直不为业界所重视。 辛顿出生于英国伦敦，他的家族出过不少知名学者，创立布尔代数的逻辑学家乔治·布尔便是他的曾曾祖父。他的祖父是位科普作家，父亲是昆虫学家。辛顿比周围的人都要聪明，但他的求学之路却颇为曲折，先是在大学攻读建筑学，转而又选择物理学，后又改读哲学，最后以心理学学士身份毕业。1972年辛顿进入爱丁堡大学攻读博士学位，研究方向是神经网络。彼时神经网络被业界所鄙夷，连辛顿的导师也认为这玩意没什么实际用途，也没有前途可言。但辛顿却不为所动，对神经网络研究怀有信心，坚持认为能够证明神经网络的价值，这一坚持就是三十多年。 辛顿年轻的时候有一次搬移取暖器，腰椎间盘滑脱了，此后便一直饱受腰背病痛问题的困扰。近年来，问题更严重了，大多数时候，他需要平躺着以缓解疼痛，这意味着他不能开车，也不能坐飞机，甚至在实验室里会见学生时，也要平躺在办公室的折叠床上。身体上疼痛的折磨带给辛顿的打击还不如学术研究被冷漠那么大。早在1969年，明斯基在《感知机》一书中就对多层感知机下了定论，给后来的神经网络研究盖戳：“多层感知机不会有发展前景，因为世界上没人可以将多层感知机训练得足够好，哪怕是令它可以学会最简单的函数方法。” 单层感知机能力有限，连“异或”这种基础的分类问题也实现不了，而多层感知机又没有可用的训练方法，等于说神经网络的研究方向是死路一条。神经网络在业界被认为是学术异端，没有人相信它可以成功，因此一般学生在选择导师的时候都谨慎绕开神经网络，一时间辛顿甚至都招不满研究生。 1983年，辛顿发明玻尔兹曼机，后来，简化后的受限玻尔兹曼机被应用于机器学习，成为深度神经网络的层级结构基础。1986年，辛顿提出适用于多层感知机的误差反向传播算法（BP），这一算法奠定了后来深度学习的基础。辛顿每隔一段时间都能发明出新东西，而他也坚持写了两百多篇神经网络相关的论文，尽管这些论文不被待见。到了2006年，辛顿已经积累了丰富的理论和实践基础，而这一次，他发表的论文将改变整个机器学习乃至整个世界。 辛顿发现，拥有多个隐藏层的神经网络能够具有自动提取特征学习的能力，相比传统的手工提取特征的机器学习更有效果。另外，通过逐层预训练的方式可以降低多层神经网络的训练难度，而这解决了长期以来多层神经网络训练的难题。辛顿将他的研究成果发表在两篇论文中，而当时神经网络一词被许多学术期刊编辑所排斥，有些稿件的标题甚至因为包含“神经网络”就会被退回。为了不刺激这些人的敏感神经，辛顿取了个新名字，将该模型命名为“深度信念网络”（Deep Belief Network）。 二 感知机 其实神经网络的研究可以追溯到上世纪四十年代。1940年，17岁的沃尔特·皮茨在伊利诺伊大学芝加哥分校结识了42岁的教授沃伦·麦卡洛克，一见如故，便加入了后者的研究项目：尝试用神经元网络建立一个在逻辑运算基础上的机械性的大脑思维模型。他们用逻辑运算来抽象人类大脑的思维模型，提出了“神经网络”（Neural Network）这一概念，而神经元是神经网络中的最小信息处理单元；并且他们将神经元的工作过程抽象简化成一个非常简单的逻辑运算模型，后来这个模型被命名为“M-P神经元模型”，以他们两姓名的首字母来命名。 在这个模型中，一个神经元会接受过个来自于其他神经元传递过来的输入信号，不同的输入信号的重要性有差异，这种差异就通过连接上的“权重”（weight）大小来表示，该神经元将所有输入值按照权重加权求和，再将结果跟神经元的“激发阈值”（Threshold）进行比较，以决定是否对外输出信号。 “M-P模型”足够简单直接，而且可以通过符号逻辑来模拟实现，人工智能专家以该模型为基础，构建了神经网络模型，用来解决机器学习任务。这里简单说明下人工智能、机器学习和深度学习的关系：人工智能就是使用计算机技术来实现人类智能的技术，在一般教材定义为研究与构建智能体。智能体就是 Intelligent agent，或简称 agent，它通过模仿人类思维和认知来解决特定任务或通用任务，解决特性任务的智能体被称为弱人工智能，或狭义人工智能（ANI），而解决通用任务的智能体被称为强人工智能，或通用人工智能（AGI）。机器学习是人工智能的一个分支，它通过数据进行学习并改进系统。而深度学习则又是机器学习的一个分支，它使用神经网络技术进行机器学习。 1957年，康奈尔大学心理学教授罗森布拉特在IBM计算机上模拟实现了一个神经网络模型，他称之为“感知机”（Perceptron）。他的做法是将一组M-P模型神经元组合在一起，可以用来训练并完成一些机器视觉模式识别方面的任务。一般来说，机器学习有两种任务：分类和回归。分类问题是判断数据是哪一类的问题，比如识别图像是猫还是狗；而回归问题是根据一个数据预测另一个数据的问题，比如根据人的图像预测其体重。感知机解决的是线性分类问题。以《智慧的疆界》书中对感知机工作原理的举例来解释： 假设任务目标是自动识别阿拉伯数字，待识别的数字是将手写或印刷的各种形式的数字，将数字通过扫描后存储在14*14像素大小的图片文件中。首先，要准备类似下图的训练集供机器学习用。训练集即训练数据集，是专门提供给计算机学习使用的数据集，它不仅是一组图片之类的数据，还会由人工事先标注告诉机器这些图片数据代表的数字是什么。 然后，我们要设计一种数据结构，以便机器可以存储并处理这些图片。对于14*14的灰度数字图片，可以将黑色像素用1来表示，白色像素用0表示，介于黑白间的灰度像素根据其灰度强度用0-1间的浮点数表示。如下图所示对该图可以转换成一个二维张量数组： 而机器能够识别出图片中的数字是什么，主要是找到了该图片表示某个数字的特征。对于人类来说，对于识别这些手写体数字很容易，但我们很难解释这些特征是什么。机器学习的目标就是要提取出这些训练集中图片表示数字的特征，根据M-P模型，提取特征的方法就是选择对图片各个像素值进行加权求和，根据训练集中的样本图片和标注数据的对应结果来计算每个像素对应各数字的权值：如果某一个像素具有很负面的证据说明该图片不属于某个数字的话，就把该像素对应该数字的权值设置成负数，相反如果一个像素具有很正面的证据说明该图片属于某个数字，那么该像素对应该数字的权值设置成正值。比如对于数字“0”的图片中间点的像素不应该有黑色（1）像素，如果出现了则表明该图片属于数字0为负面证据，就降低该图片是数字0的概率。这样，经过对数据集的训练和校准，就可以得到14*14（=196）每个像素对应0-9各数字的权重分布。 我们再将每个数字的分类过程转换成一个M-P神经元，每个神经元都有196个像素输入，每个输入与该神经元之间的权重值由训练得到，这样就构成了一个10个神经元、196个输入以及它们之间1960个带权重的连接线组成的神经网络，如下图示：（一般在神经网络中，会将阈值转换成偏置bias，称为求和项的一项，简化运算过程。） 不过，在实际情况中，有些手写字体存在模棱两可的情况，可能会导致加权求和后，出现两个或两个以上的神经元被激活。因此感知机在实现时引入了激活函数的设计，如下图中的Softmax就是一种激活函数，该函数会对求和值进行处理，抑制概率小的、增强概率大的数字分类。 罗森布拉特又在两年后制造了世界第一台硬件感知机”Mark-1”，该感知机可以识别英文字母，在当时可是引起了巨大轰动。美国国防部和海军军方也注意到了，并给与了大量的资金支撑，罗森布拉特对感知机的自信也达到顶点，甚至有记者问“有没有感知机做不到的事情”，罗森布拉特的回答是“爱、希望、绝望”。罗森布拉特的名气越来越大，而张扬的性格也导致他四处树敌，其中最有名的是人工智能的另一位巨头马文·明斯基。明斯基是达特茅斯会议的组织者，也是人工智能的奠基者之一。1969年，他出版了《感知机》一书，该书明确指出了感知机存在的缺陷。首先是通过数学方法证明了感知机无法处理异或等非线性分类问题，而后又证明了多层感知机的复杂度导致连接数据急剧膨胀而没有合适的训练方法。明斯基在该书出版当年获得了第四届图灵奖，巨大的声望让他对感知机的判断给神经网络研究判了死刑。连接主义备受打击，而符号主义的研究则成为人工智能的主流。 人工智能领域有两大流派：连接主义和符号主义，有点像武侠小说中的剑宗和气宗，长期以来一直互相竞争。连接主义通过模拟人类的大脑构建神经网络，将知识存储在大量的连接中，基于数据学习来发展人工智能。而符号主义则是认为知识和推理都应该用符号和规则来表示，即大量的“if-then”规则定义，来产生决策和推理，基于规则和逻辑来发展人工智能。前者的代表是神经网络，后者的代表是专家系统。 三 深度学习 随着感知机的失败，政府对人工智能领域的投入减少，人工智能进入了第一次寒冬期。而到了八十年代，以专家系统为代表的符号主义成为人工智能的主流，引发了人工智能的第二波浪潮，而神经网络研究被冷落。前文说到，只有一个人还在坚持，那就是杰弗","date":"2024-11-06","objectID":"/posts/%E4%BB%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%B0-hugging-face/:0:0","tags":["clippings","转载","blog"],"title":"从神经网络到 Hugging Face","uri":"/posts/%E4%BB%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%B0-hugging-face/"},{"categories":["Android"],"content":"#Peppermill #算法研究 目前 落腕灭屏算法大致在 framework 层实现。 目前算法的思路： #运动检测，通过一些特征值，来判断是否是一个运动段落。 符合的运动检测后，我们来判断是否是落腕的动作。 符合的落腕的动作后，sensor 上报 event。 framework 监听获取后进行灭屏的判断动作。 背景介绍 早起的 Android 平台，Sensor 是放在 AP 侧实现的，Sensor 生成设备节点供上层使用，Sensor 的工作 CPU 就不能完好的休眠。 后续的高版本 android 各个平台厂商都有了不同的方案，SensorHub，ADSP SensorHub 个人理解啊，SensorHub 应该算一个独立的子系统，MCU，可以不依赖 CPU 架构独立运行，可以较大的程度省电。主要功能就是连接各类 sensor 并且去处理，MTK 采用的该方案，使用的是 SRAM 架构，通电就可以保存数据，相对内存需要不停的刷新，长期运行可以节省用电。 ADSP ADSP 部分 之前把落腕的检测放在 framework 里面实现，在亮屏之后，监听 Asensor 和 GSensor，做为落腕其实只在亮屏后使用，整体上来说，是不影响耗流。 将算法下沉到 ADSP，主要考虑后续方案的适配性，针对一些低耗流的需求，可以能够较好的满足。 编译 记录我目前编译的一个问题，完整的 AMSS 编译 OK，但是单独编译 ADSP 的时候就会报错 RuntimeError: Cannot proceed with encryption/decryption: openssl v1.0.1 is unavailable. 应该是编译出 adsp 的 mbn 后，签名找不到 openssl 导致的，全编译和单编译的环境变量可能有个环节有问题。后来添加了编译的环境变量才能够正常的编译 export PATH=/pkg/qct/software/python/2.7/bin:$PATH 虚拟合成 Sensor 添加 这部分是驱动同事做的，目前我只是记录下来，具体代码我也同步在了 Media\u0026File -\u003e WristDown 路径下面 主要一个是在 adsp_proc/ssc/build/ssc.scons 和 adsp_proc/ssc_api/build/ssc_api.scons 下添加 sensor diff --git a/adsp_proc/ssc/build/ssc.scons b/adsp_proc/ssc/build/ssc.scons index 8b6ab05..28f98a9 100755 (executable) --- a/adsp_proc/ssc/build/ssc.scons +++ b/adsp_proc/ssc/build/ssc.scons @@ -129,7 +129,7 @@ if env.IsKeyEnable(ssc_build_tags) is True: #------------------------------------------------------------------------------- - 'sns_pedometer','sns_psmd','sns_rmd','sns_rotv','smd','sns_multishake','sns_threshold','sns_tilt','sns_tilt_to_wake','sdc', + 'sns_pedometer','sns_psmd','sns_rmd','sns_rotv','smd','sns_multishake','sns_threshold','sns_tilt','sns_tilt_to_wake','sdc','sns_wrist_tilt_updown', 'pah_813x_algo','pah_hr','sns_pah_hrd_algo_lib'] #------------------------------------------------------------------------------- diff --git a/adsp_proc/ssc_api/build/ssc_api.scons b/adsp_proc/ssc_api/build/ssc_api.scons index b5ca9ee..d67bc30 100755 (executable) --- a/adsp_proc/ssc_api/build/ssc_api.scons +++ b/adsp_proc/ssc_api/build/ssc_api.scons @@ -127,7 +127,8 @@ WHITELIST = [ 'sns_heart_rate.proto', 'sns_offbody_detect.proto', 'sns_ppg.proto', - 'sns_philips_vso.proto'] + 'sns_philips_vso.proto', + 'sns_wrist_tilt_updown.proto'] if 'SENSORS_ALGO_DEV_FLAG' in env: WHITELIST += [ sensor hal 里面也要添加 算法添加 主要是在 adsp_proc/ssc/sensors/wrist_tilt_updown/src/sns_wrist_tilt_updown_sensor_instance_island.c 里面， 根据获取到的 Asensor 和 Gsensor 数据来计算处理 算法部分 数据结构 定义了一个先进先出的队列，用来保存 A sensor 和 G sensor 的数据 /*=========================================================================== LinkedList Definitions ===========================================================================*/ /* init */ void LinkedList_init(LinkedList *list, int capacity) { list-\u003eelements = (SensorState *)malloc(sizeof(SensorState) * capacity); list-\u003efront = 0; list-\u003erear = -1; list-\u003ecapacity = capacity; list-\u003ecount = 0; } /* destory */ void LinkedList_destroy(LinkedList *list) { free(list-\u003eelements); } /* add item to the tail */ void LinkedList_enqueue(LinkedList *list, SensorState item,sns_sensor_instance *const this) { list-\u003erear = (list-\u003erear + 1) % list-\u003ecapacity; list-\u003eelements[list-\u003erear] = item; SNS_INST_PRINTF(ERROR, this, \"wentao LinkedList_enqueue item speed = %d /1000\", (int) (1000*item.mSpeed) ); if (list-\u003ecount \u003c list-\u003ecapacity) { list-\u003ecount++; } else { list-\u003efront = (list-\u003efront + 1) % list-\u003ecapacity; } } /* remove oldest item */ SensorState LinkedList_dequeue(LinkedList *list) { SensorState item = list-\u003eelements[list-\u003efront]; list-\u003efront = (list-\u003efront + 1) % list-\u003ecapacity; list-\u003ecount--; return item; } typedef struct { double mSpeed; float x; float y; float z; uint64_t timestamp; } SensorState; typedef struct { SensorState *elements; int front; int rear; int capacity; int count; } LinkedList; 运动检测 采样数据 a Sensor 加速度 g Sensor 角速度 运动检测主要根据加速度来计算。 目前的运动检测算法 根据经验值来判断，后续如果有优化机会，还是考虑采用更科学的计算方法。 //这里面采样频率大概80ms一次，那么一个10个单位的采样数组，大概能记录到0.8秒前的数据。 float deltaX = x - lastX; float deltaY = y - lastY; float deltaZ = z - lastZ; //通过计算加速度差值的开方除以间隔时间，作为就检测运动强度的判断依据 float sqrtV","date":"2024-11-06","objectID":"/posts/adsp-wristdown-%E6%B5%81%E7%A8%8B%E4%B8%8E%E5%AE%9E%E7%8E%B0/:0:0","tags":["实战","算法研究","blog","sensor"],"title":"adsp wristdown 流程与实现","uri":"/posts/adsp-wristdown-%E6%B5%81%E7%A8%8B%E4%B8%8E%E5%AE%9E%E7%8E%B0/"},{"categories":null,"content":"官方文档： https://source.android.com/docs/security/features/selinux https://source.android.com/docs/security/features/selinux/images/SELinux_Treble.pdf Your visual how-to guide for SELinux policy enforcement | Opensource.com SeLinux（Security-Enhanced Linux）是一个标签系统（labeling system）。每个进程都有一个label（称为process label），每个文件系统所涵盖的文件/目录、网络端口、设备等对象也有一个lable（称为Object label）。SeLinux通过编写规则来控制一个process label对一个Object label的访问，这个规则称之为策略（Policy）。SeLinux的这种安全机制称为Mandatory Access Control (MAC)，是在内核层实现的。 在标准的Linux上，也就是未实施SeLinux的Linux上，传统的访问控制是通过owner/group + permission flags（比如rwx）实现的，称之为Discretionary Access Control (DAC). SeLinux和传统的DAC不是替代的关系，而是并行的关系。两者同时在起作用。之所以出现SeLinux，是因为传统DAC的安全机制过于粗粝，而Selinux提供了更为细致和安全的访问控制。简言之，传统DAC机制下，一旦你获得了root权限，将无所不能，但在SeLinux的机制下，即使获得了root权限，也仍然需要遵循已经设置好的访问策略，只有指定的进程才可以访问指定的文件。 SeLinux有两种运行模式： Permissive mode：当访问并未授权时，不会阻止访问，但会打印log Enforcing mode：当访问未被授权时，会阻止访问，并且会打印log log将出现在dmesg和logcat。 除了可以对整体进行模式设置，也可以针对某个进程单独设置某个模式，除此之外的进程使用全局模式。 设计 SeLinux在Android 4~7和Android 8以后采用了不同的设计 Android 4~7上，SeLinux的策略是作为一个整体来编译和更新的； Android 8及以后，SeLinux采用了模块化、动态化设计，Platform（可以理解为AOSP的部分）、Non-Platform（vendor、odm、oem的部分，这里总体称为vendor部分）的SeLinux策略分别独立编译、升级。 附一张Android设备的架构图： 编译后会生成对应的img文件 ● system.img. Contains mainly Android framework. ● boot.img. (kernel/ramdisk) Contains Linux kernel + Android patches. ● vendor.img. Contains SoC-specific code and configurations. ● odm.img. Contains device-specific code and configurations. ● oem.img. Contains OEM/carrier-related configurations and customizations. ● bootloader. Brings up the kernel (vendor-proprietary). ● radio. Modem (proprietary). Android 8以后，SeLinux的策略文件可以伴随相应的img独立编译或者OTA。 2. 概念 什么是标签（Label）？怎么基于Label对访问进行控制？ 先抛开Label这个概念不说。所谓SeLinux里的访问控制，就是判定一个Source有没有权限去访问Target。这里的Source一般就是进程，Target最长见的就是文件系统（比如文件、目录、socket、设备等等），当然还有其他类型的Target。换句话说，SeLinux的机制就是通过读取一个“规则”，来控制一个进程有没有权限去访问一个文件（或其他类型）。 上面说的“规则”，在SeLinux里的术语叫做Policy（策略）或叫Access Vector Rule。是可以由AOSP和厂商、供应商来编写的。 上面的Source，还叫做Subject（主体） 上面的Target，还叫做Object（对象或客体） Label、Source、Target、Subject、Object，这些都不重要， 在实际语法中并没有相关关键词，只要各种资料里出现这些词的时候知道其所指就可以。 2.1 规则Policy Rule（或叫Access Vector Rule） 策略规则的语法为： allow source target:class permissions; Source - The type (or attribute) of the subject of the rule. Who is requesting the access?（是谁在请求访问一个资源） Target - The type (or attribute) of the object. To what is the access requested?（被访问的对象） Class - The kind of object (e.g. file, socket) being accessed.（被访问者的类型） Permissions - The operation (or set of operations) (e.g. read, write) being performed.（对Target具体要做什么操作？比如对被访问者是文件来说，是要读、写它还是其他操作？） 具体例子如下： allow sample_app app_data_file:file { read write }; 这个例子是说，允许sample_app这个进程去访问app_data_file（它是一个file类型，也就是文件），允许的操作是read和write。 而其实这里的sample_app并不是一个真正的具体的进程名，而是在系统编译阶段就定义好的一个标签（Label），一些真正的进程被映射到sample_app这个标签上，那么在执行上面规则的时候，其实生效的、有权限访问app_data_file的是所有映射了sample_app标签的那些进程。同样的，app_data_file也不是一个具体的文件名。它也是一个提前声明了的标签，一些真正的文件被映射到这个标签上，sample_app有权访问的是所映射的这些文件。 从这里看出来，有别于传统DAC的Owner、Group、Permissions 的控制方式，所谓的“基于标签系统”的SeLinux，就是这种通过声明标签的方式来表述访问规则的。 标签只是一种概念性的东西，具体体现在策略文件里，则是抽象成了Type、Attribute、Class、Permissions这些具体关键字。 2.2 规则里的关键字说明 以下面这个规则举例 allow sample_app app_data_file:file { read write }; Rule Name 上面规则示例中，allow就是Rule Name的一种。SeLinux有多种RuleName： allow：表示允许Source对Target执行许可的操作 neverallow：表示不允许Source对Target执行制定的操作 auditallow：表示允许操作并记录访问决策信息 dontaudit：表示不记录违反规则的决策信息，切违反规则不影响运行。 其中allow是用的最多的。 Type 上面的示例中，sample_app、app_data_file都是一个Type。简单理解就是将一个或几个进程声明为Type A， 将一个或多个文件声明为Type B。那么在控制这个进程有没有权限访问这个文件的时候，只用A和B来表示就可以了。 这样做有什么好处？“一类进程”总比具体的“一个进程”要灵活的多。把多个进程声明为同一个Type，那么在写规则的时候只要描述这个Type，那么这个Type对应的所有进程都会生效。文件或其他对象也是同样的。 也就是说，在规则中描述Source能不能访问Target，是通过Type来表述的。 Type是厂商或供应商可以自定义的 Attribute 将多个Type归为一组，就是一个Attribute。 通俗的说，把一些进程声明为Type，但是多个Type有某种共通的特性，就可以把这些Type声明为同一个Attribute。在描述规则的时候，可以将Source或者Target指定为一个Attribute而不是Type，这样所有属于这个Attribute的Type都生效。 AOSP本身内置了一些Attribute，而这些Attribute很多都是约定俗称的固定含义。比如： domain 所有进程的type必须归属于domain。domain因此成了进程type的常见表述。 file_type 所有文件type都归属于file_type … AOSP内置的Attribute见 platform/syste","date":"2024-11-06","objectID":"/posts/android-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%90%86%E8%A7%A3selinux-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android - 深入浅出理解SeLinux-CSDN博客","uri":"/posts/android-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%90%86%E8%A7%A3selinux-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":["Android"],"content":" 高通回复容量疑问 case中提到的resize/recovery，就是我们之前提到的恢复出厂设置后userdata拓展到剩余空间，16G变32G的动作。 按高通的回复截图，resize/recovery之前 ui上面显示的总空间/已用空间大小没有任何参考意义（参考截图第四段落最后一行。这里提到的不可信大小就是之前你们看到的下载软件后开机，系统占用16G，总容量32G） 高通认为resize之后，此时UI上显示的存储空间数据是可信的（参考截图倒数第三行，这里提到的可信大小就是你们了解的恢复出厂设置后系统占用32G，总容量64G。我们和高通在case上沟通时提供的机器数据是基于128G的，所以高通在引用数据时写的是128G） 另外，目前PNC560我们已修改为下载软件后开机时自动拓展，无需再次恢复出厂设置了，所以用户是看不到16G系统占用这个resize之前的数据的。 高通的补充 New Comment from Qualcomm engineer: “Dear Customer, 我想你我都漏考虑了一点，所有ufs的实际容量都不是标称容量，大约相当于标称容量的93%左右（这一点在vendor提供的 specification文档中应该有写，你可以自行查阅或向vendor求证） 比如一个标称容量64G的Hynix UFS， 它的实际容量其实是59G LUN0 的实际容量是 59 - 6 = 53G userdata 理论上剩下的容量是 53 - 15 = 38G 并没有你说的那么夸张，而且我们的计算并没有考虑因为物理block对齐而没有被分配的部分空间，以及apt分区表（main + back）所占用的空间，这部分在partition.xml 和 操作系统中都是不可见的。 海能达疑问 New Comment: “你好！ 我们把你给的说明(4/8/2022 1:58 AM)反馈给客户了，下面是客户的回复： 高通的回复有些绕口，我确认下是不是这样： 安卓12的固件大小超过了16G，当前软件的大小统计是按照2的幂数来取整，所以显示为32G，而实际上这32G中有10多G是空的； 我看了下个人手机安卓11的固件大小是在11G左右，再怎么增加功能，也不可能到32G吧？ 还有一个问题，如果是显示问题，这部分有办法调整么？要不然每个用户都会有疑问的。 这个些问题是否可以协助确认一下？ 谢谢！” 高通回复客户答疑 “Dear Customer, 安卓12的固件大小超过了16G，当前软件的大小统计是按照2的幂数来取整，所以显示为32G，而实际上这32G中有10多G是空的； --\u003e 这个理解是正确的 我看了下个人手机安卓11的固件大小是在11G左右，再怎么增加功能，也不可能到32G吧？ --\u003e userdata分区是用来存放用户数据的，不是Android固件，你可以简单理解：android固件存放在userdata之外的分区中 从partition.xml可以看出 LUN0中除了usdata之外的分区占用大约14G，userdata分区初始空间15G 所以不存在“32G”的android固件 还有一个问题，如果是显示问题，这部分有办法调整么？要不然每个用户都会有疑问的。 --\u003e 发布到终端用户手中的设备应该是已经resize过的，用户看到的storage空间大小应该是64G/128G,这已经不存在歧义了。 Title 文韬，占飞， 3 .已用空间是不准确的，是通过2的幂数对齐后减去可用空间 显示可用 64-33 = 31G, 使用手机已用空间： 59-6-33 =20G，里面包括已用的空间和未对齐的空间。 所以里面虚标了 总容量 虚标了 5G 还有LUN4 6G 我看了下QFIL读取出来的分区表，lun4里存放的主要是modem，dsp等分区，是属于下载镜像内容，是我们传统理解的系统容量一部分。虚标只能算5G吧。 倒是lun0中的backup分区是应用保护分区，这部分是算到系统里的，有5G。这个是比标准Android12占用多出来的。 我把qfil dump出来的分区表贴在附件里了，每个分区的num_partition_sectors去乘以4就是该分区的总字节数。占飞要不把每个分区大小用excel转换为字节数和对应的GB数，会比较直观，然后再加总一下，误差就比较清楚了。 另外我比较了64G和128G的机器，系统占用都是32G，似乎高通说的也没有什么问题，关键还是客户这边。 Title 占飞， 我理了一下高通的回复。以我手里的pnc560的手机为例，我手里的是64G的手机。 在设置里面显示已使用31G，剩余33G的空间。 安装高通的说法和设置界面显示的规则： 剩余可用空间33G是准确的，代表剩余的userdate 空间有33G。 总容量是不准确的，相当于标称的93%，大约59G 但系统会以2的幂数来取整 已用空间是不准确的，是通过2的幂数对齐后减去可用空间 显示可用 64-33 = 31G, 使用手机已用空间： 59-6-33 =20G，里面包括已用的空间和未对齐的空间。 所以里面虚标了 总容量 虚标了 5G 还有LUN4 6G 按照目前的规则，可用空间肯定必须要准确无误的，那么在可用空间计算没有问题的情况下，已用空间只能是31G ","date":"2024-11-06","objectID":"/posts/android-%E8%AE%B0%E5%BD%95%E7%B3%BB%E7%BB%9F%E7%A9%BA%E9%97%B4%E7%9A%84%E9%AB%98%E9%80%9A%E7%AD%94%E7%96%91/:0:0","tags":["blog"],"title":"Android 记录系统空间的高通答疑","uri":"/posts/android-%E8%AE%B0%E5%BD%95%E7%B3%BB%E7%BB%9F%E7%A9%BA%E9%97%B4%E7%9A%84%E9%AB%98%E9%80%9A%E7%AD%94%E7%96%91/"},{"categories":null,"content":"****## 前言 接到一个开发需求，需要定制化开发一个安全音量功能；此前有了解过为了符合欧盟等有关国家和地区的规定，原生Android是有自带一个安全音量功能的，想要定制则先要了解这个功能原先长什么样子，下面我们就从一个系统工程师的角度出发去探寻一下，原生Android的安全音量功能是如何实现的。 安全音量配置 安全音量的相关配置都在framework的config.xml里面，可以直接修改或者overlay配置修改其默认值。 \u003c!-- Whether safe headphone volume is enabled or not (country specific). --\u003e \u003cbool name=\"config_safe_media_volume_enabled\"\u003etrue\u003c/bool\u003e \u003c!-- Safe headphone volume index. When music stream volume is below this index the SPL on headphone output is compliant to EN 60950 requirements for portable music players. --\u003e \u003cinteger name=\"config_safe_media_volume_index\"\u003e10\u003c/integer\u003e config_safe_media_volume_enabled是安全音量功能的总开关，config_safe_media_volume_index则是表明触发安全音量弹框的音量大小值。 安全音量相关流程 安全音量的主要流程都在AudioService里面，其大致流程如下图所示： MSG_CONFIGURE_SAFE_MEDIA_VOLUME_FORCED onSystemReady onConfigureSafeVolume checkSafeMediaVolume AudioManager adjustStreamVolume setStreamVolume showSafetyWarningH onSystemReady 初始化 系统启动过程略去不表，在系统启动完成后会调用onSystemReady；在onSystemReady中，service会发送一个MSG_CONFIGURE_SAFE_MEDIA_VOLUME_FORCED的msg，强制配置安全音量。 public void onSystemReady() { ... sendMsg(mAudioHandler, MSG_CONFIGURE_SAFE_MEDIA_VOLUME_FORCED, SENDMSG_REPLACE, 0, 0, TAG, SystemProperties.getBoolean(\"audio.safemedia.bypass\", false) ? 0 : SAFE_VOLUME_CONFIGURE_TIMEOUT_MS); ... } 发送的MSG_CONFIGURE_SAFE_MEDIA_VOLUME_FORCED会调用onConfigureSafeVolume()来进行安全音量的配置 onConfigureSafeVolume() 安全音量配置 private void onConfigureSafeVolume(boolean force, String caller) { synchronized (mSafeMediaVolumeStateLock) { //Mobile contry code，国家代码，主要用来区分不同国家，部分国家策略可能会不一致 int mcc = mContext.getResources().getConfiguration().mcc; if ((mMcc != mcc) || ((mMcc == 0) \u0026\u0026 force)) { //从config_safe_media_volume_index中获取回来的安全音量触发阈值 mSafeMediaVolumeIndex = mContext.getResources().getInteger( com.android.internal.R.integer.config_safe_media_volume_index) * 10; mSafeUsbMediaVolumeIndex = getSafeUsbMediaVolumeIndex(); //根据audio.safemedia.force属性值或者value配置的值来决定是否使能安全音量 boolean safeMediaVolumeEnabled = SystemProperties.getBoolean(\"audio.safemedia.force\", false) || mContext.getResources().getBoolean( com.android.internal.R.bool.config_safe_media_volume_enabled); //确认是否需要bypass掉安全音量功能 boolean safeMediaVolumeBypass = SystemProperties.getBoolean(\"audio.safemedia.bypass\", false); // The persisted state is either \"disabled\" or \"active\": this is the state applied // next time we boot and cannot be \"inactive\" int persistedState; if (safeMediaVolumeEnabled \u0026\u0026 !safeMediaVolumeBypass) { persistedState = SAFE_MEDIA_VOLUME_ACTIVE; //这个值只能是disable或者active，不能是inactive，主要用于下次启动。 // The state can already be \"inactive\" here if the user has forced it before // the 30 seconds timeout for forced configuration. In this case we don't reset // it to \"active\". if (mSafeMediaVolumeState != SAFE_MEDIA_VOLUME_INACTIVE) { if (mMusicActiveMs == 0) { //mMusicActiveMs主要用于计数，当安全音量弹框弹出时，如果按了确定，这个值便开始递增，当其达到UNSAFE_VOLUME_MUSIC_ACTIVE_MS_MAX时，则重新使能安全音量 mSafeMediaVolumeState = SAFE_MEDIA_VOLUME_ACTIVE; enforceSafeMediaVolume(caller); } else { //跑到这里则表示已经弹过安全音量警示了，并且按了确定，所以把值设置为inactive // We have existing playback time recorded, already confirmed. mSafeMediaVolumeState = SAFE_MEDIA_VOLUME_INACTIVE; } } } else { persistedState = SAFE_MEDIA_VOLUME_DISABLED; mSafeMediaVolumeState = SAFE_MEDIA_VOLUME_DISABLED; } mMcc = mcc; //持久化当前安全音量的状态 sendMsg(mAudioHandler, MSG_PERSIST_SAFE_VOLUME_STATE, SENDMSG_QUEUE, persistedState, 0, null, 0); } } } 由上可知，onConfigureSafeVolume()主要用于配置和使能安全音量功能，并且通过发送MSG_PERSIST_SAFE_VOLUME_STATE来持久化安全音量配置的值，这个持久化的值只能是active或者disabled。 case MSG_PERSIST_SAFE_VOLUME_STATE: onPersistSafeVolumeState(msg.arg1); break; .... .... private void onPersistSafeVolumeState(int state) { Settings.Global.putInt(mContentResolver, Settings.Global.AUDIO_SAFE_VOLUME_STATE, state); } 安全音量触发 从实际操作可知，安全音量触发条件是：音量增大到指定值。 从调节音量的代码出发，在调用mAudioManager.adjustStreamVolume和mAudioManager.setStreamVolume时，最终会调用到AudioService中的同名方法，在执行该方法的内部： protected void adjustStreamVolume(int streamType, int direction, int flags, String callingPackage, String caller, int ui","date":"2024-11-06","objectID":"/posts/android-%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8%E9%9F%B3%E9%87%8F%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1/:0:0","tags":["clippings","转载","blog"],"title":"android 原生安全音量逻辑设计","uri":"/posts/android-%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8%E9%9F%B3%E9%87%8F%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"背景 项目中为了适应产品形态需要对Android系统状态栏系统图标以及时钟和电池等做客制化，满足不同用户群体的视觉特性，那在定制过程中需要注意哪些事项？图标icon是否可以任意大小？状态栏多颜色模式下图标如何适配？复杂状态图标如何调整逻辑？ 状态栏是什么？ 首先来看下状态栏载体是什么？状态栏本质其实就是一个悬浮窗，在systemui初始化时创建显示。SystemUI/src/com/android/systemui/statusbar/phone/StatusBar.java protected void inflateStatusBarWindow(Context context) { mStatusBarWindow = (StatusBarWindowView) mInjectionInflater.injectable( LayoutInflater.from(context)).inflate(R.layout.super_status_bar, null); } 由上可知状态栏就是使用super_status_bar.xml布局创建的一个悬浮窗。而这个布局包含了状态栏所有内容，应用通知，系统图标，时钟等。其主体内容如下 \u003ccom.android.systemui.statusbar.phone.StatusBarWindowView ... \u003cFrameLayout android:id=\"@+id/status_bar_container\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" /\u003e ... \u003c/com.android.systemui.statusbar.phone.StatusBarWindowView\u003e 其中包含status_bar_container 的framelayout的容器即为状态栏的view，在代码中通过fragmentmanager替换了了这个container。 protected void makeStatusBarView(@Nullable RegisterStatusBarResult result) { ... FragmentHostManager.get(mStatusBarWindow) .addTagListener(...).getFragmentManager() .beginTransaction() .replace(R.id.status_bar_container, new CollapsedStatusBarFragment(), CollapsedStatusBarFragment.TAG) .commit(); 而CollapsedStatusBarFragment的实现就是加载了status_bar.xml 这个布局。 @Override public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, Bundle savedInstanceState) { return inflater.inflate(R.layout.status_bar, container, false); } status_bar.xml 布局内容就是显示出来的状态栏布局。这样状态栏整体布局就比较清晰，包含了应用通知，系统图标, 时钟，电池等。 \u003ccom.android.systemui.statusbar.phone.PhoneStatusBarView ... android:layout_height=\"@dimen/status_bar_height\" android:id=\"@+id/status_bar\" ... \u003e ... \u003cLinearLayout android:id=\"@+id/status_bar_contents\" ... \u003c!-- 左侧显示区域 整体权重只占了1--\u003e \u003cFrameLayout android:layout_height=\"match_parent\" android:layout_width=\"0dp\" android:layout_weight=\"1\"\u003e ... \u003cLinearLayout android:id=\"@+id/status_bar_left_side\" ... \u003e \u003c!-- 时钟 --\u003e \u003ccom.android.systemui.statusbar.policy.Clock android:id=\"@+id/clock\" ... android:textAppearance=\"@style/TextAppearance.StatusBar.Clock\" /\u003e \u003c!-- 应用通知icon区域 --\u003e \u003ccom.android.systemui.statusbar.AlphaOptimizedFrameLayout android:id=\"@+id/notification_icon_area\" android:layout_width=\"0dp\" android:layout_height=\"match_parent\" android:layout_weight=\"1\" android:orientation=\"horizontal\" android:clipChildren=\"false\"/\u003e \u003c/LinearLayout\u003e \u003c/FrameLayout\u003e ... \u003c!-- 中间icon显示区域 --\u003e \u003ccom.android.systemui.statusbar.AlphaOptimizedFrameLayout android:id=\"@+id/centered_icon_area\" android:layout_width=\"wrap_content\" android:layout_height=\"match_parent\" android:orientation=\"horizontal\" android:clipChildren=\"false\" android:gravity=\"center_horizontal|center_vertical\"/\u003e \u003c!-- 系统icon显示区域--\u003e \u003ccom.android.keyguard.AlphaOptimizedLinearLayout android:id=\"@+id/system_icon_area\" android:layout_width=\"0dp\" android:layout_height=\"match_parent\" android:layout_weight=\"1\" android:orientation=\"horizontal\" android:gravity=\"center_vertical|end\" \u003e \u003c!-- 系统icon实际显示布局 --\u003e \u003cinclude layout=\"@layout/system_icons\" /\u003e \u003c/com.android.keyguard.AlphaOptimizedLinearLayout\u003e \u003c/LinearLayout\u003e ... \u003c/com.android.systemui.statusbar.phone.PhoneStatusBarView\u003e 系统icon区域 system_icons.xml \u003cLinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:systemui=\"http://schemas.android.com/apk/res-auto\" android:id=\"@+id/system_icons\" ...\u003e \u003ccom.android.systemui.statusbar.phone.StatusIconContainer android:id=\"@+id/statusIcons\" android:layout_width=\"0dp\" android:layout_weight=\"1\" .../\u003e \u003ccom.android.systemui.statusbar.phone.seewo.BatteryImageView android:id=\"@+id/battery\" .../\u003e \u003c/LinearLayout\u003e 整个状态栏整体布局示意如下： 其中我们需要定制的从UI设计稿中可以看出，是三个区域，时钟， 系统icon，电池， 应用通知在这个项目中不需要，可以直接去掉通知信息功能，就不会显示出来。clock和battery都是自定义控件，比较好处理。重点看下系统icon实现。 系统ICON布局 由上客制系统图标区域包含一个statusIcons 的容器view，还有battery 显示view。 其布局也是自定义view, StatusIconContainer.java \u003ccom.android.systemui.statusbar.phone.StatusIconContainer android:id=\"@+id/statusIcons\" android:layout_width=\"0dp\" .../\u003e 其实现是基于AlphaOptimizedLinearLayout布局实现的一个自定义布局。AlphaOptimizedLinearLayout是继承自LinearLayout只是覆盖了 public boo","date":"2024-11-06","objectID":"/posts/android%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%A0%8F%E5%AE%9A%E5%88%B6/:0:0","tags":["clippings","转载","blog"],"title":"Android系统状态栏定制","uri":"/posts/android%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%A0%8F%E5%AE%9A%E5%88%B6/"},{"categories":"Android","content":" style: nestedList # TOC style (nestedList|inlineFirstLevel) maxLevel: 0 # Include headings up to the speficied level includeLinks: true # Make headings clickable debugInConsole: false # Print debug info in Obsidian console 关于AP端 HSM签名的配置说明 Archer 项目签名使用的加密狗来自YubiHSM 具体的一些操作说明需要到官网寻找： YubiHSM2 用于签名的HSM项目目前有: Archer A11 Archer A13 ArcherIS 编译的服务器分别在北京和沈阳 北京服务器 上插着两个加密狗 一个加密狗 用于 ArcherIS ==serial=0016980259== 目前的usb serial no： connector=yhusb://serial=0016980259 配置和密码： [pkcs11_section] engine_id = pkcs11 #dynamic_path = /usr/lib/ssl/engines/libpkcs11.so MODULE_PATH = /usr/lib/x86_64-linux-gnu/pkcs11/yubihsm_pkcs11.so INIT_ARGS = \"connector=yhusb://serial=0016980259\" # PIN is the \u003ckey_id\u003e\u003ckey-password\u003e, by default this is 0001password. Meaning the default key_id is '0001' and the default password is 'password' # key_id = 0x2873 password = ef94cc600359806750df6595bbdf9652 # remove the 0x from the key_id and add the password to the end of it # PIN = \u003ckey_id\u003e\u003cpassword\u003e # PIN = \u003c2873\u003e\u003cef94cc600359806750df6595bbdf9652\u003e # PIN = 5147bb4dc2069b1094a80b0311a91afd72f8 PIN = \"5147bb4dc2069b1094a80b0311a91afd72f8\" init = 0 列出里面的pkcs11 key的情况： builder@builder:~/archeris_hsm_apk_signer$ YUBIHSM_PKCS11_CONF=./conf/yubihsm_connector.conf keytool -list -keystore NONE -storetype PKCS11 -storepass 5147bb4dc2069b1094a80b0311a91afd72f8 -providerClass sun.security.pkcs11.SunPKCS11 -providerArg ./conf/hsm_config.conf Keystore type: PKCS11 Keystore provider: SunPKCS11-yubihsm-pkcs Your keystore contains 9 entries is_platform, PrivateKeyEntry, Certificate fingerprint (SHA-256): 4A:EE:97:7C:1C:10:E4:1A:59:38:8F:3A:20:27:17:55:3C:EF:7E:7D:30:B4:10:B1:40:15:09:FC:4F:57:7D:79 media, PrivateKeyEntry, Certificate fingerprint (SHA-256): 90:02:EB:69:82:F9:B8:F1:6A:0F:02:2F:03:0E:F8:AC:6E:78:27:41:86:D1:D8:0F:87:39:A1:2D:40:49:2F:1C networkstack, PrivateKeyEntry, Certificate fingerprint (SHA-256): B7:7A:E1:E4:80:90:73:DC:C2:D1:09:BB:E8:28:81:65:29:BF:97:7C:33:07:73:53:8C:67:11:14:F8:69:17:49 partner, PrivateKeyEntry, Certificate fingerprint (SHA-256): 12:13:92:C9:91:78:7C:96:84:25:1C:A3:49:94:CF:E6:C8:E7:90:85:F7:E7:4D:15:A6:D9:D7:86:81:E1:51:51 platform, PrivateKeyEntry, Certificate fingerprint (SHA-256): D8:4F:01:E6:6F:5E:CD:05:4A:B3:67:0F:EA:5A:E1:FA:EA:A7:73:04:A2:9D:F1:C2:59:48:09:52:E5:FB:C4:6B release, PrivateKeyEntry, Certificate fingerprint (SHA-256): 09:55:75:AE:AE:A3:AE:20:BB:B9:43:2C:1D:47:73:09:BC:E4:22:A0:F3:60:38:0F:E0:31:2F:2C:FE:27:D9:3F shared, PrivateKeyEntry, Certificate fingerprint (SHA-256): 84:CE:CB:ED:38:A7:00:AB:D1:E4:71:0C:8C:51:0D:3F:77:D6:B2:CB:72:B3:96:94:83:7A:A8:8A:FE:C2:93:9B webview, PrivateKeyEntry, Certificate fingerprint (SHA-256): 06:DC:3A:86:59:EF:66:95:5B:C6:18:37:A3:D1:F3:5D:44:18:01:59:43:0D:3B:27:ED:B6:A7:D5:80:0C:7A:EA wrap_259, SecretKeyEntry, 用途： ArcherIS AP apk 签名 ArcherIS releasekey ota签名 Archer A13 AP apk 签名(计划中，验证中) Archer A13 目前延用A11 的项目 release ota 采用直接用releasekey的方案 一个加密狗 用于 Archer ==551== connector=yhusb://serial=0016499551 [pkcs11_section] engine_id = pkcs11 #dynamic_path = /usr/lib/ssl/engines/libpkcs11.so dynamic_path = /usr/lib/x86_64-linux-gnu/openssl-1.0.0/engines/libpkcs11.so MODULE_PATH = /usr/lib/x86_64-linux-gnu/pkcs11/yubihsm_pkcs11.so PIN = \"60d4458874be39d674225d861b3080f02068\" INIT_ARGS = \"connector=yhusb://serial=0016499551\" #INIT_ARGS = \"connector=http://localhost:12345\" init = 0 builder@builder:~/hsm_apk_signer$ YUBIHSM_PKCS11_CONF=./conf/yubihsm_connector.conf keytool -list -keystore NONE -storetype PKCS11 -storepass 60d4458874be39d674225d861b3080f02068 -providerClass sun.security.pkcs11.SunPKCS11 -providerArg ./conf/hsm_config.conf Keystore type: PKCS11 Keystore provider: SunPKCS11-yubihsm-pkcs Your keystore contains 0 entries 用途： ArcherIS CP SecureBoot 应该也是用的该加密狗。 Archer A11 CP SecureBoot 应该也是用的该加密狗。 Archer A13 CP SecureBoot 应该也是用的该加密狗。 沈阳服务器 上插着一个加密狗 Archer A11的项目 ==561== [pkcs11_section] engine_id = pkcs11 #dynamic_path = /usr/lib/ssl/engines/libpkcs11.so MODULE_PATH = /usr/lib/x86_64-linu","date":"2024-11-06","objectID":"/posts/archerarcheris-ap%E7%AD%BE%E5%90%8D%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/:0:0","tags":["blog","实战"],"title":"Archer\u0026ArcherIS AP签名方案总结","uri":"/posts/archerarcheris-ap%E7%AD%BE%E5%90%8D%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"},{"categories":"ubuntu","content":"#obsidian style: nestedList # TOC style (nestedList|inlineFirstLevel) maxLevel: 0 # Include headings up to the speficied level includeLinks: true # Make headings clickable debugInConsole: false # Print debug info in Obsidian console dateview 可以用来生成目录 节选：快速聚合 Obsidian 笔记，试试用 Dataview 生成目录 以下是一些场景： 生成包含同样关键字的笔记的目录 生成同一个标签的笔记的目录 生成同一个作者的书目的目录 这时候，Dataview 就派上用场了。 Dataview 可以生成 MOC，或者你也可以跟我一样，不去管 MOC 是什么，就把它当作一个目录。 我们知道，目录是一篇文章的概览。Dataview 其实生成了你的多篇文章目录。 如果你有这种需要的话，就接着看下去吧。 安装插件 从文件名 场景：假设，现在你有多篇关于【习惯】的笔记，并且这些笔记的名称中都有 「习惯」 两个字。记录了好几个习惯养成的方法，今天你忽然意识到，关于习惯的方法论已经看了好几个了，想把它们列出来放到一起看看能不能产生什么化学效果。 老规矩，先贴一个语法和效果图： list from \"工具\" where contains(file.name,\"Dataview\") sort file.ctime list：你创建了一个列表 / 清单。 from：留空就是不筛选文件夹和标签，从所有笔记文件去找。 where 条件：匹配（contains）了文件名（file.name）中包含「习惯」两个字的笔记 如果你需要排序，就写 sort，不需要，留空就可以。 Dataview 使用 yml 的元素 where 和 sort 就可以直接使用你在 yml 中设置的 key 了。看看下面的写法： 上面依次是：包含作者为「鲁迅」的原笔记、聚合作者为「鲁迅」的目录编辑模式、聚合作者为「鲁迅」的目录预览模式。 嗯哼，鲁迅合集就做好了。 扩展：创建一个书目列表吧！ 上面你已经学会了限制检索范围、模糊搜索文件名来创建列表，学会了从标签创建列表，还学会了用 yml 定义的 key 当作字段做条件，基本的检索语法你已经学会啦。 现在我们想在展示形式上有所改变，比如书目列表。我不想只展示作品的名字，我还想展示作者、阅读日期、标签。 还记得上面列表中的展示形式吗？ 对，就是 Dataview 语法的第一行那个 ，现在我们来变一下，写个 吧。 不过我们的语法有一点小小的改动。既然是 table，那么列名就必不可少。 先贴一下代码看看吧: ","date":"2024-11-06","objectID":"/posts/dataview-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/:0:0","tags":["obsidian","blog"],"title":"dataview 使用技巧","uri":"/posts/dataview-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"},{"categories":null,"content":"1. Perfetto 是什么？ Perfetto 是 google 从 Android10 开始引入的一个全新的平台级跟踪分析工具。它可以记录 Android 系统运行过程中的关键数据，并通过图形化的形式展示这些数据。Perfetto 不仅可用于系统级的性能分析，也是我们学习系统源码流程的好帮手。 Perfetto 算是Systrace的升级版本，可以直观的看到跨进程的调用方式。 2. 如何抓取 Trace 使用 Perfetto 一般分两步进行： 收集手机运行过程中的信息，这些信息通常称之为 Trace，收集的过程称之为抓取 Trace。 使用 Perfetto 打开 Trace，分析 Trace 本节介绍如何抓取 Trace 。 2.1 使用命令行抓取 Trace 2.1.1 使用 perfetto 命令抓取 首先使用 usb 线将电脑和手机连接，确保 adb shell 命令能正常工作。 接着执行下面的命令： adb shell perfetto -o /data/misc/perfetto-traces/trace_file.perfetto-trace t 20s \\ sched freq idle am wm gfx view binder_driver hal dalvik camera input res memory 这个命令会启动一个 20 秒钟的跟踪，收集指定的数据源信息，并将跟踪文件保存到 /data/misc/perfetto-traces/trace_file.perfetto-trace ,执行完会在后台执行。 最后，把 trace 文件 pull 出来： adb pull /data/misc/perfetto-traces/trace_file.perfetto-trace 整个抓取过程就完成了。 也可以做成手机的内置的功能，执行shell命令来离线抓去trace。 2.1.2 使用 record_android_trace 命令抓取 record_android_trace 是 Perfetto 团队提供的一个简化脚本，使得我们的抓取工作更加简单。record_android_trace 在源码路径下面也有。 curl -O https://raw.githubusercontent.com/google/perfetto/master/tools/record_android_tracechmod u+x record_android_trace ./record_android_trace -o trace_file.perfetto-trace -t 10s -b 64mb \\ sched freq idle am wm gfx view binder_driver hal dalvik camera input res memory record_android_trace 命令能自动处理好路径，抓取完成后自动打开 Trace 文件。 2.2 使用 UI 工具抓取 2.2.1 Perfetto UI 抓取 Perfetto 也提供了图形化的工具来抓取 Trace。 该工具以网站的方式提供：https://ui.perfetto.dev/#!/record 打开后，第一步，完成基本的设置： 左侧 tab 栏，选择 Record new trace 选项。 使用 usb 线连接好手机和电脑后，选项好目标平台。 选择抓取的模式。 Stop when full，抓取的 trace 达到设置的容量后就停止。 Ring buffer，环形缓存，设置的容量满了后会被覆盖。 Long Trace，任性，一直记录。 第二步，配置我们要抓取的内容： 箭头指向的内容全部选中，这部分主要是 App 相关的内容。 把调用栈选上，这对我们分析代码很有帮助。 最后点击，右上角的 Start Recording 就开始抓取了。 2.3 使用配置文件简化命令行抓取 在使用 Perfetto UI 抓取时，当我们配置好以后。 进入到 Recording command，然后把右侧两个 EOF 之间的内容复制下来，保存在 config.pbtx 配置文件中。 接着就可以用这个配置文件来抓取 Trace 了： ./record_android_trace -c config.pbtx -o trace_file.perfetto-trace -t 10s -b 64mb 3. Perfetto 使用基础 3.1 进入 Perfetto Trace 界面 使用 record_android_trace 命令或者 Perfetto UI 抓取 Trace 后，会自动打开 Perfetto Trace 界面。 使用 perfetto 命令抓取 Trace 后，需要手动打开 Perfetto Trace 界面。打开的方法如下： 使用浏览器打开 https://ui.perfetto.dev/，界面如下： 可以把 trace 文件直接拖到浏览器中，也可以通过左上角的 Open trace file 打开 trace 文件。 3.2 Perfetto Trace 界面基本内容 Perfetto Trace 界面大致可分为 4 个区域： 操作区，主要用到 Current Trace 下的几个选项： Show timeline ：显示当前 Trace，切到了别的界面之后，再点这个就会回到 Trace View 界面。 Query：写 SQL 查询语句和查看执行结果的地方。 Metrics：官方默认帮你写好的一些分析结果。 Info and stats ：当前 Trace 和手机 App 的一些信息。 信息区：时间与搜索。 Trace 内容区：图形化展示 Trace 的区域。 信息区：展示Trace 内容区中选择中的元素的详细信息。 在 Trace 内容区中，可以通过 w/s 按键缩小放大界面， a/d 移动界面。 Trace 内容区中主要有以下一些元素： 3.2.1 slice，片段 鼠标单击后会有一个黑框包围住，信息区会显示相关信息： slice 代表了一段代码的执行过程，起于 Trace.traceBegin \\ ，终于 Trace.traceEnd \\ ATRACE_END Trace.traceBegin(Trace.TRACE_TAG_ACTIVITY_MANAGER, \"bindApplication\"); AppBindData data = (AppBindData)msg.obj; handleBindApplication(data); Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER); 线程状态查看 深绿色 : 运行中（Running） 在Running状态就代表着处于cpu上的运行中 状态作用：看某个方法是否耗时，可以通过测量Running时间长短判断，也可以进行竞品对比看看cpu能力如何，或者前后对比各个大小核cpu影响方法的耗时 浅绿色 : 可运行（Runnable） 代表线程可以运行但当前没有真正运行中，需要等待 cpu 调度，这个时间长短代表着cpu调度快慢 重要作用：点击Runnable这个块，下面信息会显示当前线程唤醒者是谁，即可以清楚知道整个线程之间唤醒逻辑。 白色/无色: 睡眠中（Sleeping） 代表当前线程没有工作可以做，等待事件驱动干货，比如looper就是大部分时间睡眠，小部分时间有消息后处理消息 橙色Uninterruptible Sleep (IO) 代表不可以中断的休眠状态，一般线程在IO操作上阻塞了 不可中断状态实际上是系统对进程和硬件设备的一种保护机制。比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的。 紫红色Uninterruptible Sleep (Non IO) 不可中断的休眠状态，非IO导致，在等内核锁。通常是低内存导致等待、各种各样的内核锁。 Uninterruptible情况都可以点击后看到blocked方法是哪个 Blocked function jbd2_log_wait_commit 3.2.2 counter，计数器 用于记录一些关键数据。 对应于代码中的 Trace.traceCounter/ATRACE_INT： ATRACE_INT(ftl::Concat(\"HW_VSYNC_\", displayIdOpt-\u003evalue).c_str(), displayData.vsyncTraceToggle); 3.2.3 CPU Sched Slice， cpu 调度片段 用于展示 cpu 的调度情况。 3.2.4 thread_state，线程状态 点击片段上方线程调度信息片段(Running)，可以看到线程当前运行在哪个CPU上。 点击信息区中的 Running on CPU 7 旁边的斜箭头： 可以在 CPU 调度中看到该运行片段。 再次点击斜箭头，可以回到原来位置。 这里的 thread_state 实际是我们的主线程，由用户点击屏幕唤醒运行，实际很多线程都是由其他线程/进程唤醒的，比如在 CPU 调度中选择一个 Slice： 这里的意思是当前 thread 由 P（Process）/system/bin/surfaceflinger [584] 中的 T（Thread）app [689] 唤醒。 线程从就绪到运行延迟了 48us 381ns 3.3 Perfetto","date":"2024-11-06","objectID":"/posts/perfetto-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/:0:0","tags":["clippings","转载","工具","blog"],"title":"Perfetto 使用指南","uri":"/posts/perfetto-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"该文章为窗口层级结构系列文章的总结，重新回看这方面内容的时候我自己也有了一些新的感悟，希望通过本次总结能让大家再次对窗口有一个全面的认识。 一般来说，屏幕上最起码包含三个窗口，StatusBar窗口、Activity窗口以及NavigationBar窗口： 我们想要了解窗口，可以按照从小到大，从表到里的顺序进行： 1）、微观角度，探究单个窗口内部的组成。 2）、宏观角度，探究WMS如何管理屏幕上显示的诸多窗口。 3）、底层角度，探究SurfaceFlinger如何管理窗口，和WMS在这方面有何联系。 至于窗口，我们先理解它为一块在屏幕上可以显示图像的区域。 1 微观下的Window —— View层级结构 窗口本身作为View对象的容器只是一个抽象的概念，真正可见的则是View对象，那么我们探究单个窗口的表现形式，其实就是探究组成窗口的View层级结构。 这里我们写一个单选按钮组： \u003cRadioGroup android:id=\"@+id/radio_group\" android:layout_width=\"300dp\" android:layout_height=\"wrap_content\" android:layout_marginTop=\"50dp\" android:layout_marginStart=\"20dp\" android:background=\"@color/material_dynamic_neutral70\"\u003e \u003cRadioButton android:id=\"@+id/radio_button1\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"A\" /\u003e \u003cRadioButton android:id=\"@+id/radio_button2\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"B\" /\u003e \u003cRadioButton android:id=\"@+id/radio_button3\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"C\" /\u003e \u003c/RadioGroup\u003e 看起来是这样子： 这已经是一个简单的View层级结构了，父View为RadioGroup，其中有3个RadioButtion的子View，那么它的层级结构就是： 我之前习惯用树状图的形式： 不过似乎还是第一种表现形式更好，能够更加直观的反映上下级的关系，后面描述层级结构的时候我仍然用树状图的一些叫法。 Android对此层级结构的建立提供了哪些支持呢？ 1.1 每一个UI元素都是一个View 比如这里的单选按钮RadioButton类，它的继承关系为： RadioButtion -\u003e CompoundButton -\u003e Button -\u003e TextView -\u003e View RadioGroup类的继承关系为： RadioGroup -\u003e LinearLayout -\u003e ViewGroup -\u003e View 就像每一个类的基类是Object一样，每一个用来组成Activity界面的UI元素，其基类都是View类，因此我个人喜欢称这些由UI元素搭建的组织架构为View层级结构，层级结构里的每一个节点都是一个View。 1.2 父View和子View 以刚刚的单选按钮组为例，这里是一个RadioGroup包含了3个RadioButtion，父View为RadioGroup，子View为3个RadioButtion。 回看RadioGroup，它是一种特殊的View，继承自ViewGroup，ViewGroup顾名思义，就是一种能够包含其它View的特殊View，它有一个View数组类型的成员变量mChildren： // frameworks\\base\\core\\java\\android\\view\\ViewGroup.java // Child views of this ViewGroup @UnsupportedAppUsage(maxTargetSdk = Build.VERSION_CODES.P) private View[] mChildren; 用来保存它容纳的子View。 既然父View有一个mChildren用来拿到子View对象，那么子View也应该有一个成员变量用来保存父View的引用，实际上也的确如此，View中也定义了一个ViewParent类型的成员变量mParent用来指向当前View的父View： // frameworks\\base\\core\\java\\android\\view\\View.java /** * The parent this view is attached to. * {@hide} * * @see #getParent() */ @UnsupportedAppUsage(maxTargetSdk = Build.VERSION_CODES.P) protected ViewParent mParent; ViewParent是一个接口类，定义一个能够作为父View的类的通用接口，这里看到ViewGroup就实现了这个接口类： // frameworks\\base\\core\\java\\android\\view\\ViewGroup.java public abstract class ViewGroup extends View implements ViewParent, ViewManager 那么为什么不让View来实现ViewParent接口，而让ViewGroup来实现呢？不难想到，对于参与建立View层级结构的View来说，其实可以分为两类，一类就像RadioButtion一样，它们是View层级结构中的最小单位，或者叫做View层级结构中的叶节点，无法作为父View再去容纳其它子View。而对于RadioGroup，它们作为父View可以容纳其它子View，在View层级结构中充当中间节点（当然也可以作为叶节点）。 最后说下如何向ViewGroup中添加子View，用的是ViewGroup.addChild方法： /** * Adds a child view with the specified layout parameters. * * \u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e do not invoke this method from * {@link #draw(android.graphics.Canvas)}, {@link #onDraw(android.graphics.Canvas)}, * {@link #dispatchDraw(android.graphics.Canvas)} or any related method.\u003c/p\u003e * * @param child the child view to add * @param index the position at which to add the child or -1 to add last * @param params the layout parameters to set on the child */ public void addView(View child, int index, LayoutParams params) 最终会将child参数代表的子View加入到当前VIewGroup.mChildren中，同时将子View的mParent指向当前ViewGroup。 LayoutInflater解析xml文件，其实也是实例化xml中定义的View，然后通过ViewGroup.addChild方法将子View添加到父View中，以这种方式将xml文件中定义的View层级结构建立起来。 1.3 根View 对于所有组成同一个Activity界面的UI元素，它们都在同一个层级结构中，自然它们都有一个共同的根View，那这个根View是谁？ 我们新建一个Activity，一般来说都在其onCreate方法中去加载其布局，比如像这样： @Override protected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_pip); } 那通过解析这个 R.layout.activity_pip 对应的xml文件所生成的View就是根View吗，仍然拿这里的demo进行验证，我自己定义的actiivty_pip.xml是一个LInearLayout，里面包含了两个单选按钮组。需要注意的是这个LinearLayout有一个不为“match_parent”的自定义高度，并且设置了一个背景色，其层级结构为： 看下实际情况： 对于它没有覆盖到的区域，仍有一个白色背景，说明这个LinearLayout并不是根View。 如果想要找到根View，就需要去跟踪Activity.setContentView流程，这个流程我之前有总结过文档，这","date":"2024-11-06","objectID":"/posts/%E8%AE%A4%E8%AF%86%E7%AA%97%E5%8F%A3-%E7%AA%97%E5%8F%A3%E6%A8%A1%E5%BC%8F-%E7%AA%97%E5%8F%A3%E5%B1%82%E7%BA%A7android-12-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","转载"],"title":"【Android 12】认识窗口_android 窗口模式 窗口层级-CSDN博客","uri":"/posts/%E8%AE%A4%E8%AF%86%E7%AA%97%E5%8F%A3-%E7%AA%97%E5%8F%A3%E6%A8%A1%E5%BC%8F-%E7%AA%97%E5%8F%A3%E5%B1%82%E7%BA%A7android-12-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"整体框架 VsyncConfiguration：一些基本参数的配置类，比如PhaseOffsets、WorkDuration等。 Scheduler：作为SF生成和派发VSync的整体调度器，主要面向SurfaceFlinger提供VSync相关接口。Scheduler包含对所有屏幕的VSync的控制。本身是MessageQueue的子类。 Refresh****RateSelector：每个Display屏幕对应一个RefreshRateSelector，用于基于屏幕支持的刷新率范围，选择一个合适的Refresh Rate和Frame Rate，并会传递给VSyncSchedule作为软件VSync生成的重要因素。 VsyncSchedule：Vsync生成的调度器。每个屏幕对应一个VsyncSchedule。包含一个Tracker（VSyncPredictor）、一个Dispatch（VSyncDispatchTimerQueue）、一个Controller（VSyncReactor）。一方面对接硬件VSync信号的接收、开关，一方面对接软件VSync的计算、输出。 VSyncPredictor ：在VsyncSchedule的语境中为一个Tracker，是负责综合各方因素根据算法由硬件VSync计算出软件VSync周期的工具类。 VSyncDispatchTimerQueue：在VsyncSchedule的语境中为一个Dispather，负责将VSync分发到使用者。 VSyncCallbackRegistration：代表一个VSync使用者的注册。比如常见的针对上层应用的VSYNC-app、针对SurfaceFlinger合成的VSYNC-sf，都对应一个VSyncCallbackRegistration。另外在客户端，还有一个VSYNC-appSf。 EventThread：处理客户端应用VSYNC的一个独立线程。期内维护一个不断请求VSYNC的死循环。比如VSYNC-app，一方面，通过VSyncCallbackRegistration去申请下一次VSYNC，另一方面，当VSYNC生成，通过Connection将VSYNC发送给DisplayEventReceiver，也就是VSYNC的终端接收者。一般情况下有两个EventThread，一个是针对客户端应用侧的VSYNC-app，另一个是客户端想使用SF同步信号的VSYNC-appSf。 DisplayEventReceiver：通过socket机制提供了一个SF与客户端应用传递VSYNC的通道。在服务端，EventThread通过DisplayEventReceiver发送VSYNC事件，在客户端，Choreographer通过DisplayEventReceiver接收到VSYNC后，下发给ViewRootImp驱动下一次绘制渲染。 Android 13以后，VSYNC架构变化之一是给SF使用的VSYNC-sf信号，不再通过EventThread维护，而是直接在Schedule内维护。供客户端应用使用的VSYN-app仍然由EventThread维护，另外，新增了一个VSYN-appSf信号，也是由EventThread维护。主要作用是如果客户端想使用SF同步的信号，可以切换到VSYNC-appSf这个信号源来。在Android 13之前，这个机制是通过VSYNC-sf实现的，Android 13后将SF专门使用的VSYNC-sf从EventThread剥离出来直接由Schedule维护，VSYN-appSf则专门针对客户端。 关键****参数 在探索VSync机制前，需要对一些关键参数的概念有所了解，从dumpsys SurfaceFlinger入手： 屏幕刷新率 ColorMode：设备支持的ColorMode；可根据系统设置或应用自身设定的颜色模式最终决定使用那个ColorMode。 deviceProductInfo： 屏幕设备信息；manufacturerPnpId=QCM为Plug and Play即插即用设备唯一识别码。 activeMode：当前使用的帧率模式 displayModes：当前屏幕支持的帧率模式。从打印的信息看支持60Hz、90Hz两种帧率 displayManagerPolicy：当前采用的帧率管理策略。primaryRanges代表的是在选取帧率时，通常采纳的范围，如果用户通过setFrameRate手动指定一个帧率，其可能超出primaryRanges的范围；appRequestRanges代表用户可以指定的帧率范围。最终的帧率可能超过primaryRanges，但绝不会超过appRequestRanges。 主要组件的初始化 SurfaceFlinger的初始化 SurfaceFlinger的启动源于SystemServer执行main_surfaceflinger.cpp的main方法： int main(int, char**) { ... sp\u003cSurfaceFlinger\u003e flinger = surfaceflinger::createSurfaceFlinger(); ... flinger-\u003einit(); ... } surfaceflinger::createSurfaceFlinger()的实现在platform/frameworks/native/services/surfaceflinger/SurfaceFlingerFactory.cpp sp\u003cSurfaceFlinger\u003e createSurfaceFlinger() { static DefaultFactory factory; return sp\u003cSurfaceFlinger\u003e::make(factory); } 随后，调用SurfaceFlinger的init方法： platform/frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp void SurfaceFlinger::init() FTL_FAKE_GUARD(kMainThreadContext) { ... sp\u003cconst DisplayDevice\u003e display; if (const auto indexOpt = mCurrentState.getDisplayIndex(getPrimaryDisplayIdLocked())) { const auto\u0026 displays = mCurrentState.displays; const auto\u0026 token = displays.keyAt(*indexOpt); const auto\u0026 state = displays.valueAt(*indexOpt); processDisplayAdded(token, state); mDrawingState.displays.add(token, state); display = getDefaultDisplayDeviceLocked(); } ... initScheduler(display); ... } 构建RefreshRateSelector 上面的代码中调用了processDisplayAdded添加主屏幕，后续挂载一个新屏幕也会走此流程： void SurfaceFlinger::processDisplayAdded(const wp\u003cIBinder\u003e\u0026 displayToken, const DisplayDeviceState\u0026 state) { ... auto display = setupNewDisplayDeviceInternal(displayToken, std::move(compositionDisplay), state, displaySurface, producer); ... } sp\u003cDisplayDevice\u003e SurfaceFlinger::setupNewDisplayDeviceInternal( const wp\u003cIBinder\u003e\u0026 displayToken, std::shared_ptr\u003ccompositionengine::Display\u003e compositionDisplay, const DisplayDeviceState\u0026 state, const sp\u003ccompositionengine::DisplaySurface\u003e\u0026 displaySurface, const sp\u003cIGraphicBufferProducer\u003e\u0026 producer) { ... creationArgs.refreshRateSelector = mPhysicalDisplays.get(physical-\u003eid) .transform(\u0026PhysicalDisplay::snapshotRef) .transform([\u0026](const display::DisplaySnapshot\u0026 snapshot) { return std::make_shared\u003c scheduler::RefreshRateSelector\u003e(snapshot.displayModes(), creationArgs.activeModeId, config); }) .value_or(nullptr); ... sp\u003cDisplayDevice\u003e display","date":"2024-11-06","objectID":"/posts/android-14-%E7%BB%98%E5%88%B6%E4%BD%93%E7%B3%BB-vsync1-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android 14 - 绘制体系 - VSync（1）-CSDN博客","uri":"/posts/android-14-%E7%BB%98%E5%88%B6%E4%BD%93%E7%B3%BB-vsync1-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"一、Surface介绍 在Android系统中，Surface是一种用于图形和视频渲染的抽象概念，它可以用来将应用程序绘制的图形或视频显示在屏幕上。一个Surface代表一个屏幕表面，可以是整个屏幕或者应用程序UI的一个独立窗口。 Surface通过一个SurfaceHolder对象来提供访问接口。SurfaceHolder管理了Surface的生命周期和绘画信息，并提供了锁定(SurfaceHolder.lockCanvas())和解锁(SurfaceHolder.lockCanvas())和解锁(SurfaceHolder.unlockCanvasAndPost())Canvas对象接口，使得应用程序可以直接在Surface上进行绘制操作。 一个Surface可以包含多个Buffer，每个Buffer都包含了一个图像或视频的副本，应用程序可以在一个Buffer中渲染图形或视频数据，而使用另一个Buffer时，只需要将绘图信息提交后，即可直接显示另一个Buffer的图像或视频内容，从而提高了渲染效率和性能。 在Android系统中，Surface还被广泛用于多媒体、游戏和图形渲染等应用程序场景。例如，MediaCodec和MediaPlayer类使用Surface作为视频输出的目标，OpenGL ES库也使用Surface作为渲染目标，而游戏引擎中也常常会使用Surface作为游戏画面的输出目标。 surface和surfaceflinger之间的关系 一个surface与surfaceflinger中一个layer一一对应。layer中有bufferqueue用于接收surface通过producer发过来的图形数据。 surface的绘制流程 surface的绘制流程分别LockCanvas-\u003edrawBitmap-\u003eUnlockCanvasAndPost几个阶段，最后通知SurfaceFlinger进行合成，整体流程如下： 三、Surface相关类和接口 JAVA类 Surface Surface是Android中用于表示一个图像缓冲区的类，Surface包括JAVA部分，JNI和C++部分。 Surface代码位于： frameworks/base/core/java/android/view/Surface.java Surface的定义： public class Surface implements Parcelable {} SurfaceControl SurfaceControl是一个用于创建和管理Surface的类，其中的Surface对象就是一个用于图像展示的承载器。而SurfaceControl对象，则是用于对Surface对象进行操作的控制器。使用SurfaceControl，应用程序可以根据需要创建新的Surface，或将现有的Surface与当前会话进行关联，通过SurfaceControl可以对Surface属性进行设置，例如对Surface进行裁剪、设置Surface位置和大小、设置Surface的透明度等。 SurfaceControl通过SurfaceSession来和SurfaceFlinger进行交互、完成对Surface的创建、设置和控制等操作，SurfaceControl包括JAVA部分，JNI和C++部分。 SurfaceControl代码位于： frameworks/base/core/java/android/view/SurfaceControl.java SurfaceControl的定义： public final class SurfaceControl implements Parcelable {public static class Builder {}} SurfaceSession SurfaceSession是Android系统中与图形表面相关的一个关键类，它提供了与SurfaceFlinger服务通信以创建和管理图形表面连接的API，SurfaceSession的主要作用包括： 创建和管理图形表面连接：SurfaceSession充当了应用程序和系统级SurfaceFlinger服务之间的中介，通过IPC机制与SurfaceFlinger通信，创建和管理图形表面连接。 分配和管理表面标识符：图形表面在Android系统中是由唯一的标识符来进行识别的和管理的，SurfaceSession类会分配和管理这些标识符，避免表面之间出现冲突和重复问题 。同时，SurfaceSession还会将每个表面与其所属的进程关联起来，以确保安全和可靠的表面交互。 提供与表面相关的API接口：SurfaceSession类提供了一系列与表面相关的API接口，包括创建和设置表面属性，通过BufferQueue和IGraphicBufferProducer进行表面缓冲区管理和交互等。这些API接口为开发人员提供了方便的方法来创建和管理表面，同时实现了内部和外部之间的隔离，确保了系统的安全和稳定性。 SurfaceSession代码位于： frameworks/base/core/java/android/view/SurfaceSession.java SurfaceSession的定义： public final class SurfaceSession {} C++类 Surface Surface是Android中用于表示一个图像缓冲区的类，Surface包括JAVA部分，JNI和C++部分。 Surface代码位于： frameworks/base/core/jni/android_view_Surface.cpp framework/native/libs/gui/Surface.cpp frameworks/native/include/gui/Surface.h Surface的定义： class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e {} Surface方法： int connect(int api, const sp\u003cIProducerListener\u003e\u0026 listener)：连接 int Surface::disconnect(int api, IGraphicBufferProducer::DisconnectMode mode) ：断开 int queueBuffers(const std::vector\u003cBatchQueuedBuffer\u003e\u0026 buffers)：生产者填充缓存区并返回给队列 int dequeueBuffers(std::vector\u003cBatchBuffer\u003e* buffers)：生产者请求一块空闲的缓存区 int cancelBuffers(const std::vector\u003cBatchBuffer\u003e\u0026 buffers)：关闭缓冲区 SurfaceControl SurfaceControl是一个用于创建和管理Surface的类，其中的Surface对象就是一个用于图像展示的承载器。而SurfaceControl对象，则是用于对Surface对象进行操作的控制器。使用SurfaceControl，应用程序可以根据需要创建新的Surface，或将现有的Surface与当前会话进行关联，通过SurfaceControl可以对Surface属性进行设置，例如对Surface进行裁剪、设置Surface位置和大小、设置Surface的透明度等。 SurfaceControl通过SurfaceSession来和SurfaceFlinger进行交互、完成对Surface的创建、设置和控制等操作，SurfaceControl包括JAVA部分，JNI和C++部分。 SurfaceControl代码位于： frameworks/base/core/jni/android_view_SurfaceControl.cpp frameworks/native/libs/gui/SurfaceControl.cpp frameworks/native/include/gui/SurfaceControl.h SurfaceControl的定义： public final class SurfaceControl implements Parcelable { } class SurfaceControl : public RefBase{ } ComposerService This holds our connection to the composer service (i.e. SurfaceFlinger). ComposerService代码位于： frameworks/native/libs/gui/include/private/gui/ComposerService.h ComposerService的定义： class ComposerService : public Singleton\u003cComposerService\u003e {} ComposerServiceAIDL This holds our connection to the composer service (i.e. SurfaceFlinger). ComposerServiceAIDL 代码位于： frameworks/native/libs/gui/include/private/gui/Compos","date":"2024-11-06","objectID":"/posts/android-surface-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","转载"],"title":"Android Surface-CSDN博客","uri":"/posts/android-surface-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"背景： 设想一下，假如我们又如下场景，一个闪黑一瞬间的问题，正常我们看到黑屏冻屏问题，是不是时刻想到是要来dumpsys SurfaceFlinger和dumpsys window windows相关的信息来辅助我们分析问题，但奈何这个是个瞬时问题。。。我们dumpsys很难抓住那一瞬间，而且即使抓到了黑一瞬间的，我们有时候分析也要又黑屏前一帧后一帧相关等才可以分析进一步原因。 所以在开发过程中，经常会遇到各种各样的窗口问题，比如动画异常、窗口异常、闪屏、闪黑、黑屏、错位显示… 对于这些问题，添加日志，调试分析代码等手段去解决，但这些 UI 问题往往出现在一瞬间，很难把握出现的时机，录制下来的日志往往也是巨大的，从海量的日志中提取有效的信息是一个枯燥且繁琐的事情，而且也根本没有办法把显示时间戳和日志时间戳完全对好。 Android 也意识到了这个问题，WinScope 的出现有效的帮助我们跟踪窗口和显示问题。它向开发者提供一个可视化的工具，让开发者能使用工具跟踪整个界面的变化过程。 怎么抓winscope相关文件： 抓取winscope 把这里面的Winscope Trace开关打开 这时候下拉状态栏多了它的图标 当我们需要开始抓取时候点击图标既可以 然后开始操作手机复现对应的bug现象，复现完毕则再点击图标关闭 最后会再系统的如下路径生成对应的winscope文件 使用chrome浏览器加载观看winscope 打开使用配套源码aosp中的winscope的html文件 文件路径如下： /home/test/aosp/prebuilts/misc/common/winscope/winscope.html 把这个winscope.html打开 然后把手机上的winscope抓取的文件pull到本地 adb pull /data/misc/wmtrace 再点击如下区域： 选择对应文件，这里一般常用是SurfaceFlinger和Window的相关： 这里我们最常见的就是SurfaceFlinger和Window的分析 选择后点击Submit 然后就可以相当于对着录屏的每一帧图像看对应的surfaceflinger中各个layer的信息，相当于每一帧我们都可以又对应的dumpsys数据分析 4、原因寻找及解决办法 上面已经分析了bugreport的原理，实际是借助dumpstate来实现获取高权限root的，那么问题来了，为啥wmtrace相关文件夹呢？这个问题就得看dumpstate相关源码了： frameworks/native/cmds/dumpstate/dumpstate.cpp 看到了如下的代码： #define PSTORE_LAST_KMSG \"/sys/fs/pstore/console-ramoops\" #define ALT_PSTORE_LAST_KMSG \"/sys/fs/pstore/console-ramoops-0\" #define BLK_DEV_SYS_DIR \"/sys/block\" #define RECOVERY_DIR \"/cache/recovery\" #define RECOVERY_DATA_DIR \"/data/misc/recovery\" #define UPDATE_ENGINE_LOG_DIR \"/data/misc/update_engine_log\" #define LOGPERSIST_DATA_DIR \"/data/misc/logd\" #define PREREBOOT_DATA_DIR \"/data/misc/prereboot\" #define PROFILE_DATA_DIR_CUR \"/data/misc/profiles/cur\" #define PROFILE_DATA_DIR_REF \"/data/misc/profiles/ref\" #define XFRM_STAT_PROC_FILE \"/proc/net/xfrm_stat\" #define WLUTIL \"/vendor/xbin/wlutil\" #define WMTRACE_DATA_DIR \"/data/misc/wmtrace\" #define OTA_METADATA_DIR \"/metadata/ota\" #define SNAPSHOTCTL_LOG_DIR \"/data/misc/snapshotctl_log\" #define LINKERCONFIG_DIR \"/linkerconfig\" #define PACKAGE_DEX_USE_LIST \"/data/system/package-dex-usage.list\" #define SYSTEM_TRACE_SNAPSHOT \"/data/misc/perfetto-traces/bugreport/systrace.pftrace\" #define CGROUPFS_DIR \"/sys/fs/cgroup\" 可以看到有列出一个个的data相关目录，有RECOVERY_DATA_DIR和WMTRACE_DATA_DIR，这里重点看看WMTRACE_DATA_DIR为啥没有被导出看看是否有相关的限制条件： 看到了如下的代码，这里有一个条件就是!PropertiesHelper::IsUserBuild() 即只有在非user手机才可以导出WMTRACE_DATA_DIR目录 /* Add window and surface trace files. */ if (!PropertiesHelper::IsUserBuild()) { ds.AddDir(WMTRACE_DATA_DIR, false); } 修改方案探索： 1、直接删除 if (!PropertiesHelper::IsUserBuild()) 条件（比较暴力不安全） //if (!PropertiesHelper::IsUserBuild()) { ds.AddDir(WMTRACE_DATA_DIR, false); // } 2、可以加一个或条件，加入自己的暗门（建议这种），比如自己也搞一个prop，可以通过adb shell改变的prop if (!PropertiesHelper::IsUserBuild() || isEnableProp（）) { ds.AddDir(WMTRACE_DATA_DIR, false); } ","date":"2024-11-06","objectID":"/posts/winscope%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"android车机手机黑屏闪黑终结者-Winscope工具使用介绍-CSDN博客","uri":"/posts/winscope%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"背景 发现有一个问题，那就发现在user版本的手机设备上发现无法抓取相关的winscope，哪怕可以抓取也发现没办法导出来分析。 1、user手机上网页获取winscope失败 winscope在user手机上的效果如下： 可以看出一直是显示个error，但是具体是啥原因error呢？ 从服务端的python程序输出日日志看看： 明显看到其实服务端也只是去执行相关的adb shell命令，只不过这个命令需要有su root这样高级别的权限。自然在user手机上是没有的 2、手机上可以抓取，但是无权限获取文件 快捷按钮可以去setting中放开 抓取完成后有相关的trace文件： 可以看到trace文件被导出到了 data/misc/wmtrace文件夹，那么尝试取出 发现有如下权限问题 可以看出这个wmtrace文件夹压根没有权限哈，自然无法取出 3、尝试探索解决办法 使用bugreoport命令： test@test:~$ adb bugreport /data/user_de/0/com.android.shell/files/bugreports/bugreport-crosshatch-SP1A.210812.016.C1-2022-06-28-12-21-13.zip: 1 file pulled. 27.7 MB/s (11790205 bytes in 0.406s) test@test:~$ adb pull /data/user_de/0/com.android.shell/files/bugreports/bugreport-crosshatch-SP1A.210812.016.C1-2022-06-28-12-21-13.zip /data/user_de/0/com.android.shell/files/bugreports/bugreport-crosshatch-SP1A.210812.016.C1-2022-06-28-12-21-13.zip: 1 file pulled. 27.7 MB/s (11790205 bytes in 0.406s) 看看这个bugreport命令导出的相关文件： 发现FS文件夹下面有个data的文件夹，还有misc，因为本身misc根本adb shell是没有权限可以查看的，看着是不是很有希望。。 但是情况却如下： 只有recovery相关，没有看到wmtrace相关文件夹 但是明明就是/data/misc/wmtrace路径，为啥没有导出呢？ 需要知道这个原因就必须要看源码了 首先需要了解点bugreport其实本质上也最多只能有shell权限，因为也属于adb shell拉起的进程， 但是为啥它可以导出data/misc/下面相关文件夹 为了解密这个我们可以来看看相关源码 frameworks/native/cmds/bugreport/bugreport.cpp int main() { fprintf(stderr, \"=============================================================================\\n\"); fprintf(stderr, \"WARNING: Flat (text file, non-zipped) bugreports are deprecated.\\n\"); fprintf(stderr, \"WARNING: Please generate zipped bugreports instead.\\n\"); fprintf(stderr, \"WARNING: On the host use: adb bugreport filename.zip\\n\"); fprintf(stderr, \"WARNING: On the device use: bugreportz\\n\"); fprintf(stderr, \"WARNING: bugreportz will output the filename to use with adb pull.\\n\"); fprintf(stderr, \"=============================================================================\\n\\n\\n\"); return 0; } 可以看出的这里其实bugreport已经是一个空壳了，真正还是bugreportz在起作用 看看bugreportz的相关命令： frameworks/native/cmds/bugreportz/main.cpp int main(int argc, char* argv[]) { //省略 // TODO: code below was copy-and-pasted from bugreport.cpp (except by the // timeout value); // should be reused instead. // Start the dumpstatez service. //启动相关的 dumpstate服务 if (stream_data) { property_set(\"ctl.start\", \"dumpstate\"); } else { property_set(\"ctl.start\", \"dumpstatez\"); } // Socket will not be available until service starts. int s = -1; for (int i = 0; i \u003c 20; i++) { //与dumpstate进行本地socket跨进程通讯 s = socket_local_client(\"dumpstate\", ANDROID_SOCKET_NAMESPACE_RESERVED, SOCK_STREAM); if (s \u003e= 0) break; // Try again in 1 second. sleep(1); } int ret; //socket接受相关的数据进行处理 if (stream_data) { ret = bugreportz_stream(s); } else { ret = bugreportz(s, show_progress); } return ret; } 总结如下图所示： 验证方式： 在执行bugreport命令时候： test@test:~/aosp/frameworks/native/cmds$ adb bugreport [ 5%] generating bugreport-crosshatch-SP1A.210812.016.C1-2022-06-28-13-02-19.zip 开另一个在终端进行adb shell查看一下阿dumpstate服务是啥权限： crosshatch:/ $ ps -A | grep dump root 16137 1 10878140 5172 0 0 S dumpstate 明显看到是一个root权限的进程 4、原因寻找及解决办法 上面已经分析了bugreport的原理，实际是借助dumpstate来实现获取高权限root的，那么问题来了，为啥wmtrace相关文件夹呢？这个问题就得看dumpstate相关源码了： frameworks/native/cmds/dumpstate/dumpstate.cpp 看到了如下的代码： #define PSTORE_LAST_KMSG \"/sys/fs/pstore/console-ramoops\" #define ALT_PSTORE_LAST_KMSG \"/sys/fs/pstore/console-ramoops-0\" #define BLK_DEV_SYS_DIR \"/sys/block\" #define RECOVERY_DIR \"/cache/recovery\" #define RECOVERY_DATA_DIR \"/data/misc/recovery\" #define UPDATE_ENGINE_LOG_DIR \"/data/misc/update_engine_log\" #define LOGPERSIST_DATA_DIR \"/data/misc/logd\" #define PREREBOOT_DATA_DIR \"/data/misc/prereboot\" #define PROFILE_DATA_DIR_CUR \"/data/misc/profiles/cur\" #define PROFILE_DATA_DIR_REF \"/data/misc/profiles/ref\" #define XFRM_STAT_PROC_FILE \"/proc/net/xfrm_stat\" #define WLUTIL \"/vendor/xbin/wlutil\" #define WMTRACE_DATA_DIR \"/data/misc/wmtrace\" #define OTA_METADATA_DIR \"/metadata/ota\" #define SNAPSHOTCTL_LOG_DIR \"/data/misc/snapshotctl_log\" #define LINKERCONFIG_DIR \"/linkerconfig\" #define PACKAGE_DEX_USE_LIST \"/data/system/package-dex-us","date":"2024-11-06","objectID":"/posts/winscope%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0user%E7%89%88%E6%9C%AC%E4%B8%8A%E5%AF%BC%E5%87%BA%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E6%8E%A2%E8%AE%A8-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"winscope怎么实现user版本上导出方案设计探讨","uri":"/posts/winscope%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0user%E7%89%88%E6%9C%AC%E4%B8%8A%E5%AF%BC%E5%87%BA%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E6%8E%A2%E8%AE%A8-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"binder讨论的一些场景面试题 问题1：binder中有多个进程作为客户端通过servicemanager获取service的bpbinder，bpbinder都会有一个handle，那么多个进程获取同一个service对应的handle一样么？ 是的，多个进程获取同一个服务对应的 BpBinder 的 handle 是一样的。 在 Android 的 Binder IPC 机制中，ServiceManager 负责管理系统中的各种服务。当一个客户端进程请求某个服务时，它会通过 ServiceManager 获取到服务的 Binder 引用（即 BpBinder），这个引用在内部包含了一个 handle，该 handle 是一个整数值，唯一标识了这个服务在 Binder 驱动中的位置。 由于不同进程获取的都是同一个服务的引用，所以它们获取到的 BpBinder 中的 handle 是相同的。这个 handle 用于在 Binder 驱动层进行通信时标识目标服务，从而确保客户端进程能够正确地与目标服务进行交互。 总结来说： 不同进程通过 ServiceManager 获取同一个服务的 BpBinder。 这些 BpBinder 对象中的 handle 是一样的，因为它们都指向同一个服务。 这个 handle 是用于在底层 Binder 驱动中唯一标识该服务的。 希望这个回答能帮到你！如果你有更多问题，请随时提问。 问题2：请问binder通讯过程中是否可以传递bpbinder对象？ 是的，在 Binder 通信过程中可以传递 BpBinder 对象。 BpBinder 是一个客户端侧的 Binder 引用，它在跨进程通信中可以被当作普通的 Binder 对象传递。具体过程如下： 创建 BpBinder: 客户端进程通过 ServiceManager 获取服务的 BpBinder 引用。 传递 BpBinder: 在进行 Binder 通信时，这个 BpBinder 可以作为参数附带在 Parcel 中传递给其他进程。 使用 BpBinder: 接收方进程会收到这个 BpBinder 引用，并可以通过它与原服务进行通信。 这种机制使得 Binder 能够灵活地支持对象引用的传递和跨进程交互，是 Android IPC 的核心特性之一。 问题3：请问同binder 服务端进程自己进程内部如果进行binder调用需要经过binder驱动吗，需要和不需要请详细描述？ 这个要看情况和调用方式： 一 通过aidl的方式，AIDL 接口生成的时候，有区分是否是本地进程还是远程进程 Stub 的空构造函数。而Stub 本身又是Binder 的子类。调用了Binder 的attachInterface 方法。 public Stub() { this.attachInterface(this, DESCRIPTOR); } public void attachInterface(@Nullable IInterface owner, @Nullable String descriptor) { mOwner = owner; mDescriptor = descriptor; } 分别保存了当前类的实例对象（This）和当前类接口描述符（DESCRIPTOR），其实就是 private static final java.lang.String DESCRIPTOR = “com.example.aidlapplication.IMyAidlInterface”; 当前类的全路径，这也是我们在使用aidl 的时候服务端和客户端必须要保证相同路径下的原因，因为他被保存下来作为参数用于比对当前类是否是本地类还是远程。 所以在 IMyAidlInterface iMyAidlInterface = IMyAidlInterface.Stub.asInterface(service) public static com.example.aidlapplication.IMyAidlInterface asInterface(android.os.IBinder obj) { if ((obj==null)) { return null; } android.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); if (((iin!=null)\u0026\u0026(iin instanceof com.example.aidlapplication.IMyAidlInterface))) { return ((com.example.aidlapplication.IMyAidlInterface)iin); } return new com.example.aidlapplication.IMyAidlInterface.Stub.Proxy(obj); } @Override public android.os.IBinder asBinder() { return this; } 参考这篇：android Binder queryLocalInterface 本地与远程-CSDN博客 二 通过bind service 这种方式可能还是要通过binder去调用，但在binder驱动内部，可能还是有一定的优化流程。 #TODO 问题4：Android App进程天生支持binder通讯的原理是什么，刚开始初始化时候自带了几个binder线程？ zygote 启动的时候就支持了binder通讯，所有后面的app孵化之后，也会自带binder通讯。 zygote 在 init的时候： 1. 启动 ProcessState ProcessState::self() 2. 启动线程池：proc-\u003estartThreadPool(); virtual void onZygoteInit() { sp\u003cProcessState\u003e proc = ProcessState::self(); ALOGV(\"App process: starting thread pool.\\n\"); proc-\u003estartThreadPool(); } new ProcessState(kDefaultDriver); sp\u003cProcessState\u003e ProcessState::self() { Mutex::Autolock _l(gProcessMutex); if (gProcess != nullptr) { return gProcess; } gProcess = new ProcessState(kDefaultDriver); return gProcess; } mDriverFD(open_driver(driver)) 打开驱动 mMaxThreads(DEFAULT_MAX_BINDER_THREADS) 最大线程数 mmap(0, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); 映射内存 BINDER_VM_SIZE 默认 1M- 2PageSize ProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver)) , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mManagesContexts(false) , mBinderContextCheckFunc(NULL) , mBinderContextUserData(NULL) , mThreadPoolStarted(false) , mThreadPoolSeq(1) { if (mDriverFD \u003e= 0) { // mmap the binder, providing a chunk of virtual address space to receive transactions. mVMStart = mmap(0, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); if (mVMStart == MAP_FAILED) { // *sigh* ALOGE(\"Using /dev/binder failed: unable to mmap transaction memory.\\n\"); close(mDriverFD); mDriverFD = -1; mDriverName.clear(); } } LOG_ALWAYS_FATAL_IF(mDriverFD \u003c 0, \"Binder driver could not be opened. Terminating.\"); } void IPCThreadState::joinThreadPool(b","date":"2024-11-06","objectID":"/posts/%E6%B1%87%E6%80%BBbinder%E7%9B%B8%E5%85%B3%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98-%E5%AE%89%E5%8D%93%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:0:0","tags":["clippings","转载","blog"],"title":"汇总binder相关一些常见面试题-安卓系统常见面试题-CSDN博客","uri":"/posts/%E6%B1%87%E6%80%BBbinder%E7%9B%B8%E5%85%B3%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98-%E5%AE%89%E5%8D%93%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"从Android 12开始，Android的绘制系统有结构性变化， 在绘制的生产消费者模式中，新增BLASTBufferQueue，客户端进程自行进行queue的生产和消费，随后通过Transation提交到SurfaceFlinger，如此可以使得各进程将缓存提交到SufrfaceFlinger后合并到同一事务后同步提交，在同一帧生效。实际上，从Android12到Android14整个绘制系统在各个环节也都有了或大或小的调整，比如Android13发布了1.3版本的Vulkan, Android14新增了TextureView，等等。本文基于Android14。1 Android 绘制系统整体架构： 从上到下可以理解为“生产者（Producer）”到“消费者（Consumer）”的处理过程。 首先，从WindowManagerService的角度，每个窗口称为Window，一个Window一般是一个APP的页面，或者Status Bar，或者Navigation Bar，或者WallPaper，这些都是一个个Window。WindowManagerService（WMS）作为服务端，对所有客户端窗口的添加、层级、布局等进行统一管理。在WMS端，每个Window对应一个Surface。Surface可以理解为图像数据缓存的持有者，以及Canvas的持有者。Canvas是画布，提供了绘制各种图形的能力供开发者使用。一个客户端窗口在建立之初，会先向WMS去申请一个Surface，WMS在创建了Surface之后，通过binder返回给客户端。客户端拿到Surface后，会去创建一个BLASTBufferQueue来管理图像内存的申请。每次要使用Surface的Canvas进行绘制前，需要先向BLASTBufferQueue申请一块内存（dequeue），我们这里称为Buffer，然后再将生成的图像数据写入Buffer。这个向BLASTBufferQueue申请Buffer并写入图像数据的过程，可以认为是“生产”阶段。随后，enqueue这个buffer，将其提交给SurfaceFlinger去合成。这个阶段，可以理解为图像Buffer的“消费”阶段。 SurfaceFlinger（SF）是负责与Hardware层沟通，维护着设备挂载、VSync信号收发、Layer合成等工作。WMS的每个Surface在SurfaceFlinger中都对应生成一个Layer对象。客户端将某个Surface上的Buffer提交给SurfaceFlinger，实际上就是更新了对应Layer的Buffer数据。SurfaceFlinger调用HWComposer将这些Layer进行合成并显示在屏幕。 Android在HAL层提供称为一个Hardware Composer的组件，用于隔离与具体硬件的交互。Hardware Composer简称HWComposer或HWC2（之所以是2，是早期已有一个HWC版本，只支持软件合成）。SurfaceFlinger把Layer数据交给HWComposer，各厂商来负责HWComposer合成接口的具体实现。在合成完毕后，将数据提交到屏幕设备的缓存（一般称为Frame Buffer），屏幕就显示出画面来了。 上面的过程，可以拆解为几部分： Surface的创建与管理。 客户端（EndPoint）绘制（Draw）和渲染（Render）图像。 第三部分，是硬件Composition（合成）工作 Vsync：由硬件产生的信号，用于同步framebuffer的生产和消费。SurfaceFlinger对Vsync进行了使用和管理，并向上分发给APP。Vsync是不断绘制的驱动力，也是图像缓存有序投送到屏幕的重要机制。 现在，分别讨论下四部分： Surface的创建与管理 在Surface的创建过程中，有几个角色贯穿其中： PhoneWindow：一个Activity对应一个PhoneWindow，代表一个应用窗口。在AMS创建Activity之初，PhoneWindow在服务端的对应的window对象（ActivityRecord）已经添加到WMS。 ViewRootImpl：其主要作用是与服务端通信，承接外部触发的绘制调用，从而从上往下对整个View树进行绘制。可以把ViewRootImp理解为View的调度者。ViewRootImp在逻辑上是View Hierarchy的最顶层，但其并不是一个真正的View。他持有一个字View–DecorView，DecorView才是真正的View，是View树的最上层，包含着Activity的画面内容。在Activity的resume阶段，ViewRootImpl的relayout方法会将DecorView添加到WMS中，这样Activity的内容就显示了出来。逻辑上，我们可以把DecorView也理解为一个Window。Activity对应一个PhoneWindow，再通过ViewRootImpl将DecorView在WMS端添加为PhoneWindow的子Window。 WMS的Session：客户端一个进程对应WMS里的一个Session，客户端持有Session的binder客户端，在窗口添加等事务上，客户端都是通过这个Session来与WMS通信的。 WindowContainer：WMS端管理系统整体的Window体系，包括其位置、层级关系。它是通过WindowContainer这个类来表达一个Window的。DisplayContent代表一个屏幕级别的Window，DisplayArea代表一块屏幕上的一块区域，比如平板等大屏幕设备上，可能一块屏幕上同时显示多个应用区域，此时就用DisplayArea表达。WindowToken简单理解为对应一个客户端Window，比如一个应用的Activity，这里需要注意的是，Activity的WindowToken是作为ActivityRecord存在的，也就是说ActivityRecord是WindowToken的子类。而Activity的具体内容的承载者，DecorView，对应WindowState。上面所有的DisplayContent、DisplayArea、WindowToken、WindowState等，都是WindowContainer的子类，这些Window在WMS内是以window树的形式组织起来的。事实上，在DisplayContent下面，还有一个层级，称为Feature，具体的层级结构见Android12 - WMS之WindowContainer树（DisplayArea）_android windowcontainer-CSDN博客。当客户端通过Session接口调用添加DecorView时，WMS端会生成一个对应的WindowState对象，并将其作为Activity对应的ActivityRecord（也就是WindowToken）的子window。 SurfaceControl：在WMS端，每个WindowContainer对应一个SurfaceControl。SurfaceControl是WMS端管理Surface的具体对象，在WMS端，可以理解一个SurfaceControl就代表一个Surface。SurfaceControl在SurfaceFlinge端对应一个Layer，持有一个layer的句柄handle。所有的绘制动作，最后都会提交到SurfaceFinger作为Layer去合成。SurfaceControl的作用，或者Surface的作用，主要是将客户端的窗口与SurfaceFlinger的Layer关联起来。在客户端Add一个DecorView时， 在WMS端对应创建的WindowState会同时创建一个SurfaceControl、Layer，随后将SurfaceControl返回给客户端。客户端拿到SurfaceControl之后转换成Surface。后续的绘制就在这个Surface上进行。 SurfaceComposerClient：是一个Binder，主要作用是SurfaceControl调用SurfaceFlinger过程中，作为一个通道的角色。由于SurfaceControl在WMS、客户端都持有，所以客户端、WMS都可以通过这个通道调用SF。比如Layer的创建、Graphihc Buffer的提交等。 1. 客户端绘制和渲染 客户端通过Surface中提供的Canvas进行绘制，Canvas是基于Skia的SKCanvas。Skia（https://skia.org/）是由Google管理的开源2D（也可以支持3D）图像库，目前Android、Google Chrome、ChromeOS、Mozilla FireFox、FireFoxOS上都使用Skia作为绘制引擎。Skia可以集成OPEN GL和Vulkan进行3D绘制。Android Q以后，Skia作用被加强，即使硬件加速场景中，绘制也会先封装成Skia的GrOpList再提交给GPU。在Android 14中， Skia包的目录为external/skia。 渲染的过程是将画好的图像，进行栅格化（Rasterizer），变成一个个像素，这是一个非常耗时的过程。Android 3以前，只支持软件渲染，即Software Render。过程如下： APP在View的onDraw阶段使用Canvas绘制后，通过Skia进行软件的","date":"2024-11-06","objectID":"/posts/android-14-%E7%BB%98%E5%88%B6%E4%BD%93%E7%B3%BB-%E6%A6%82%E8%A7%88_blastbufferqueue-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android 14 - 绘制体系 - 概览_blastbufferqueue-CSDN博客","uri":"/posts/android-14-%E7%BB%98%E5%88%B6%E4%BD%93%E7%B3%BB-%E6%A6%82%E8%A7%88_blastbufferqueue-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"一、SurfaceFlinger介绍 SurfaceFlinger是Android系统中的一个重要组件，它主要负责窗口管理与界面显示。具体来说，SurfaceFlinger作为系统的显示引擎，负责接收各应用程序发来的图像数据，并组合成一张完整的画面，并输出到显示屏上。SurfaceFlinger通过重绘整个屏幕或部分屏幕来更新UI界面。它还提供了多种硬件加速技术，如OpenGL ES、Vulkan等，使应用程序能够更快地渲染UI界面。 SurfaceFlinger还支持窗口叠加、透明度、混合模式等特性，以支持复杂的多层UI界面。此外，它还能管理所有Surface对象（如视频、图片等），并为每个Surface对象分配一个BufferQueue（缓冲区队列），确保每个Surface都能按时完成显示。 SurfaceFlinger启动流程： SurfaceFlinger送显的流程： 二、Surface的渲染 Android系统的UI从绘制到显示在屏幕上可分为两个步骤： 1、Android App进程：将UI绘制到一个图形缓冲区GraphicBuffer中，然后通知SurfaceFlinger进行合成。 2、SurfaceFlinger进程：将GraphicBuffer数据合成并交给屏幕缓冲区去显示，这一步本身就是通过软件（Skia）和硬件（Open GL和 HardWare Composer）去完成的。 软件渲染介绍 当App更新部分UI时，CPU会遍历ViewTree计算处需要重绘的赃区，接着在View层次结构中绘制所有跟脏区相交的区域，因此软件绘制会绘制到不需要重绘的视图。 软件绘制的绘制过程是在主线程进行的，可能会造成卡顿等情况。 软件绘制把要绘制的内容写进一个Bitmap位图，在之后的渲染过程中，这个Bitmap的像素内容会填充到Surface的缓冲区里。 软件绘制使用Skia库，Skia是Google开发的一个跨平台的2D图形库，它提供了一组强大的API，可以实现高质量的2D图形渲染。 需要注意的是，软件渲染的性能相对较低，而且可能会因为大量的图像计算而占用大量CPU资源，导致应用程序的运行速度变慢。 如下为软件渲染流程： 1、构建视图树：Android应用程序中的UI由视图树来组织的，首先需要构建视图树。 2、计算布局：在获得视图树之后，系统需要计算每个视图的大小和位置，并将它们放置在正确的位置上，以完成布局。 3、绘制视图：接下来，系统将开始使用软件渲染引擎(Skia)，对每一个视图进行主意绘制，即使用CPU执行图像计算并将图像渲染到GraphicBuffer上。 4、合成图像：当所有的视图都绘制完成后，SurfaceFlinger会将它们合成在一起，生成最终屏幕图像，并将其放到主显示缓冲区中。 硬件渲染介绍 当App更新部分UI时，CPU会计算出脏区，但是不会立即执行绘制命令，而是将darwXXX函数作为绘制指令(DrawOp)记录在一个列表(DisplayList中)，然后交给单独的Render线程使用GPU进行硬件加速渲染。 只需要针对需要更新的View对象的脏区进行记录或更新，无需更新的View对象则能重用先前DisplayList中记录的指令。 硬件加速是在单独的Render线程中绘制的，分担了主线程的压力，提高了响应速度。 硬件绘制使用OpenGL在GPU上完成，OpenGL是跨平台的图形API，为2D/3D图形处理硬件制定了标志的软件接口。 如下为硬件渲染的流程： 1、构建视图树：与软件渲染一样，硬件渲染也需要构建应用程序的视图树。 2、计算布局：与软件渲染一样，硬件渲染也需要对每个视图计算布局。 3、创建OpenGL的渲染上下文和纹理：Android使用OpenGL ES作为硬件加速的渲染引擎。因此，当硬件加速被开启时，系统会创建OpenGL的渲染上下文，同时为每个视图分配一个渲染纹理。 4、上传纹理数据：在计算好视图的布局之后，系统将视图的图像数据上传到渲染纹理中。这通常由GPU完成。 5、绘制纹理：最后，系统将视图的渲染纹理绑定到OpenGL的渲染上下文中，并执行GPU计算，即使用GPU绘制图像。 6、合成图像：当所有的视图都绘制完成后，SurfaceFlinger会将它们合成在一起，生成最终屏幕图像，并将其放到主显示缓冲区中。 Android在什么时候使用软件渲染、什么时候使用硬件渲染？ 在Android系统中，软件渲染和硬件渲染是根据应用程序的需求和设备的性能决定的的。通常情况，系统会优先使用硬件渲染来提高图形的速度和效率。如果系统检测到设备的GPU不支持某种特定的图像特效或功能，或在硬件渲染的过程中出现问题，那么系统将退回到软件渲染。下列情况可能触发系统使用软件渲染： 1、设备的GPU不支持当前应用程序的某些特性或图像格式。 2、当前应用程序需要在屏幕上叠加多个图像层，而GPU能力不足以处理所有的层级叠加。 3、在某些情况下，使用硬件加速可能会导致应用程序出现性能问题，此时系统可能会切换到使用软件渲染。 SurfaceFlinger的双缓冲与VSYNC机制 缓冲机制介绍 显示缓冲机制是指定在计算机系统中，将显示数据缓存到到内存中以提高处理速度的一种计算，在图形和图像处理中，显示缓冲机制可以提升图像、图形的渲染效率和质量。 在早期的Android版本中，SurfaceFlinger使用的是三重缓冲区机制，即前台、后台和显示三个缓冲区。从Android8.0开始，SurfaceFlinger该为采用双缓冲区机制，只有前台和后台两个缓冲区。采用三重缓冲区机制的优点在于可以减少屏幕撕裂现象的产生，提高显示画面的连贯性。但同时增加了内存占用，因此在Android8.0及以上版本中，为了提高性能和减少内存占用，SurfaceFlinger改为采用双缓冲区机制。 双缓冲区机制下，前台缓冲区用于显示当前帧的内容，后台缓冲区用于绘制下一帧的内容。当绘制下一帧完成后，SurfaceFlinger会将后台缓冲区的内容交换到前台缓冲区，从而实现帧与帧之间的切换。这种机制可以减少一次缓冲区的创建及销毁操作，以提高性能和解约内存。 三重缓存机制是Android中的一种优化技术，用于提高绘制性能。它包括前缓冲区（Front Buffer）、后缓冲区（Back Buffer）和显示缓冲区（Display Buffer）。前缓冲区用于显示当前帧，后缓冲区用于绘制下一帧，而显示缓冲区则用于将前缓冲区的内容显示在屏幕上。当VSYNC信号到达时，前缓冲区和后缓冲区会进行交换，从而实现流畅的显示效果。 VSYNC机制介绍 在图形和图像显示中，VSYNC是一个非常重要的概念，它是指垂直同步信号，用于控制显示器刷新率和显示时序。在Android系统中，VSYNC机制被广泛应用于控制屏幕显示和动画渲染，以提高显示效果和性能。 在Android中，每台设备都有一个硬件VSYNC信号发生器，用于生成恒定的刷新率信号。通常情况下这个信号的刷新率为60Hz或90Hz，Android显示框架可以根据这个信号来调整自己的显示和渲染速度。在SurfaceFlinger的生成者消费者模型中，当硬件VSYNC信号发生时，SurfaceFlinger会开始读取缓冲区中的数据，并将其显示在屏幕上。因此，如果Android显示框架在VSYNC前完成了数据处理和绘制，则可以实现零延迟的图像或动画渲染。 VSYNC机制的主要优点是可以避免在图像渲染过程中出现屏幕撕裂和卡顿现象，同时，使用硬件信号，可以使图形和图像处理与显示保持同步，提高显示效果和渲染性能。 由于图像绘制和屏幕读取 使用的是同个buffer，所以屏幕刷新时可能读取到的是不完整的一帧画面。双缓存，让绘制和显示器拥有各自的buffer：GPU 始终将完成的一帧图像数据写入到 Back Buffer，而显示器使用 Frame Buffer，当屏幕刷新时，Frame Buffer 并不会发生变化，当Back buffer准备就绪后，它们才进行交换。 什么时候进行两个buffer的交换呢？ 当扫描完一帧画面后，设备需要重新回到第一行以进入下一次的循环，此时有一段时间空隙，称为VerticalBlanking Interval(VBI)。那，这个时间点就是我们进行缓冲区交换的最佳时间。因为此时屏幕没有在刷新，也就避免了交换过程中出现 screen tearing的状况。 VSYNC 信号是由屏幕（显示设备）产生的，利用VBI时期出现的vertical sync pulse（垂直同步脉冲）来保证双缓冲在最佳时间点才进行交换。并且以 60fps 的固定频率发送给 Android 系统，Android 系统中的 SurfaceFlinger 接收发送的 VSYNC 信号。VSYNC 信号表明可对屏幕进行刷新而不会产生撕裂。另外，交换是指各自的内存地址，可以认为该操作是瞬间完成。 Android 4.4上又引入了Vsync虚拟化，通过DispSyncThread把Vsync虚拟化成Vsync-app和Vsync-sf，Vsync-app和Vsync-sf直接有固定的时机偏移，各自分别掌控着App和SurfaceFlinger的工作节奏，他们一前一后保持着绘制任务的流水节奏。 CPU/GPU根据VSYNC信号同步处理数据，可以让CPU/GPU有完整的16ms时间来处理数据，减少了jank（丢帧）。 一句话总结，VSync同步使得CPU/GPU充分利用了16.6ms时间，减少jank。 应用在每个Vsync信号到来后都会通过dequeueBuffe","date":"2024-11-06","objectID":"/posts/android-surfaceflinger-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android SurfaceFlinger-CSDN博客","uri":"/posts/android-surfaceflinger-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"GraphicBuffer用于管理图形缓存数据的类，GraphicBuffer的构造方法如下： //frameworks/native/libs/ui/GraphicBuffer.cpp class GraphicBuffer : public ANativeObjectBase\u003cANativeWindowBuffer, GraphicBuffer, RefBase\u003e, public Flattenable\u003cGraphicBuffer\u003e{ GraphicBuffer::GraphicBuffer(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName) : GraphicBuffer() { mInitCheck = initWithSize(inWidth, inHeight, inFormat, inLayerCount, inUsage, std::move(requestorName)); } } GraphicBuffer 的构造函数非常简单, 它只是调用了一个初始化函数 initWithSize： //frameworks/native/libs/ui/GraphicBuffer.cpp class GraphicBuffer : public ANativeObjectBase\u003cANativeWindowBuffer, GraphicBuffer, RefBase\u003e, public Flattenable\u003cGraphicBuffer\u003e{ status_t GraphicBuffer::initWithSize(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName){ // 获取一个 GraphicBufferAllocator 对象, 这个对象是一个单例 // GraphicBufferAllocator 主要负责 GraphicBuffer 的内存分配 GraphicBufferAllocator\u0026 allocator = GraphicBufferAllocator::get(); uint32_t outStride = 0; // 分配一块制定宽高的 GraphicBuffer status_t err = allocator.allocate(inWidth, inHeight, inFormat, inLayerCount, inUsage, \u0026handle, \u0026outStride, mId, std::move(requestorName)); if (err == NO_ERROR) { // 通过 GraphicBufferMapper 将这块 GraphicBuffer 的参数记录下来 // GraphicBufferMapper 负责的是 GraphicBuffer 的内存映射 mBufferMapper.getTransportSize(handle, \u0026mTransportNumFds, \u0026mTransportNumInts); // 初始化参数 width = static_cast\u003cint\u003e(inWidth); height = static_cast\u003cint\u003e(inHeight); format = inFormat; layerCount = inLayerCount; usage = inUsage; usage_deprecated = int(usage); stride = static_cast\u003cint\u003e(outStride); } return err; } } 调用allocator(GraphicBufferAllocator)的allocate方法，分配一块制定宽高的 GraphicBuffer： //frameworks/native/libs/ui/GraphicBufferAllocator.cpp class GraphicBufferAllocator : public Singleton\u003cGraphicBufferAllocator\u003e { status_t GraphicBufferAllocator::allocate(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, uint64_t /*graphicBufferId*/, std::string requestorName) { return allocateHelper(width, height, format, layerCount, usage, handle, stride, requestorName, true); } } GraphicBufferAllocator allocateHelper 调用GraphicBufferAllocator的allocateHelper方法： //frameworks/native/libs/ui/GraphicBufferAllocator.cpp class GraphicBufferAllocator : public Singleton\u003cGraphicBufferAllocator\u003e { std::unique_ptr\u003cconst GrallocAllocator\u003e mAllocator; status_t GraphicBufferAllocator::allocateHelper(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, std::string requestorName, bool importBuffer) { ATRACE_CALL(); // make sure to not allocate a N x 0 or 0 x N buffer, since this is // allowed from an API stand-point allocate a 1x1 buffer instead. // 如果宽或者高为0, 则将宽高设置为1 if (!width || !height) width = height = 1; const uint32_t bpp = bytesPerPixel(format); if (std::numeric_limits\u003csize_t\u003e::max() / width / height \u003c static_cast\u003csize_t\u003e(bpp)) { ALOGE(\"Failed to allocate (%u x %u) layerCount %u format %d \" \"usage %\" PRIx64 \": Requesting too large a buffer size\", width, height, layerCount, format, usage); return BAD_VALUE; } // Ensure that layerCount is valid. // 如果图层的数量少于1, 则将图层的数量设置为1 if (layerCount \u003c 1) { layerCount = 1; } // TODO(b/72323293, b/72703005): Remove these invalid bits from callers usage \u0026= ~static_cast\u003cuint64_t\u003e((1 \u003c\u003c 10) | (1 \u003c\u003c 13)); // 分配内存，使用的是 GrallocAllocator 指针，根据不同的版本有哦不同的实现，这里我们假设它的实现是 Gralloc3Allocator status_t error = mAllocator-\u003eallocate(requestorName, width, height, format, layerCount, usage, 1, stride, handle, importBuffer); if (error != NO_ERROR) { ALOGE(\"Failed to allocate (%u x %u) layerCount %u format %d \" \"usage %\" PRIx64 \": %d\", width, height, layerCount, format, usage, error); return error; } if (!importBuffer) { return NO_ERROR; } size_t bufSize; // if stride has no meaning or is too large, // approximate size with the input width","date":"2024-11-06","objectID":"/posts/android13-graphicbuffer-%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 GraphicBuffer 创建流程-CSDN博客","uri":"/posts/android13-graphicbuffer-%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Surface的connect方法用于建立与BufferQueueCoreAndroid13 BufferQueueLayer onFirstRef流程分析-CSDN博客#new BufferQueueCore连接，代码如下： //frameworks/base/core/java/android/view/Surface.java class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { int Surface::connect(int api) { static sp\u003cIProducerListener\u003e listener = new StubProducerListener(); return connect(api, listener); } } 调用重载方法： //frameworks/base/core/java/android/view/Surface.java class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { int Surface::connect(int api, const sp\u003cIProducerListener\u003e\u0026 listener) { return connect(api, listener, false); } } 调用重载方法： //frameworks/base/core/java/android/view/Surface.java sp\u003cIGraphicBufferProducer\u003e mGraphicBufferProducer; class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { int Surface::connect( int api, const sp\u003cIProducerListener\u003e\u0026 listener, bool reportBufferRemoval) { ATRACE_CALL(); ALOGV(\"Surface::connect\"); Mutex::Autolock lock(mMutex); IGraphicBufferProducer::QueueBufferOutput output; mReportRemovedBuffers = reportBufferRemoval; int err = mGraphicBufferProducer-\u003econnect(listener, api, mProducerControlledByApp, \u0026output); if (err == NO_ERROR) { mDefaultWidth = output.width; mDefaultHeight = output.height; mNextFrameNumber = output.nextFrameNumber; mMaxBufferCount = output.maxBufferCount; // Ignore transform hint if sticky transform is set or transform to display inverse flag is // set. Transform hint should be ignored if the client is expected to always submit buffers // in the same orientation. if (mStickyTransform == 0 \u0026\u0026 !transformToDisplayInverse()) { mTransformHint = output.transformHint; } mConsumerRunningBehind = (output.numPendingBuffers \u003e= 2); } if (!err \u0026\u0026 api == NATIVE_WINDOW_API_CPU) { mConnectedToCpu = true; // Clear the dirty region in case we're switching from a non-CPU API mDirtyRegion.clear(); } else if (!err) { // Initialize the dirty region for tracking surface damage mDirtyRegion = Region::INVALID_REGION; } return err; } } 调用mGraphicBufferProducer(IGraphicBufferProducer)的connect方法，IGraphicBufferProducer是一个接口，由BpGraphicBufferProducer 实现： //frameworks/native/libs/gui/IGraphicBufferProducer.cpp class BpGraphicBufferProducer : public BpInterface\u003cIGraphicBufferProducer\u003e { virtual status_t connect(const sp\u003cIProducerListener\u003e\u0026 listener, int api, bool producerControlledByApp, QueueBufferOutput* output) { Parcel data, reply; data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor()); if (listener != nullptr) { data.writeInt32(1); data.writeStrongBinder(IInterface::asBinder(listener)); } else { data.writeInt32(0); } data.writeInt32(api); data.writeInt32(producerControlledByApp); status_t result = remote()-\u003etransact(CONNECT, data, \u0026reply); if (result != NO_ERROR) { return result; } reply.read(*output); result = reply.readInt32(); return result; } } 发送CONNECT消息，发送的消息在onTransact中处理： //frameworks/native/libs/gui/IGraphicBufferProducer.cpp status_t BnGraphicBufferProducer::onTransact( uint32_t code, const Parcel\u0026 data, Parcel* reply, uint32_t flags) { switch(code) { case CONNECT: { CHECK_INTERFACE(IGraphicBufferProducer, data, reply); sp\u003cIProducerListener\u003e listener; if (data.readInt32() == 1) { listener = IProducerListener::asInterface(data.readStrongBinder()); } int api = data.readInt32(); bool producerControlledByApp = data.readInt32(); QueueBufferOutput output; status_t res = connect(listener, api, producerControlledByApp, \u0026output); reply-\u003ewrite(output); reply-\u003ewriteInt32(res); return NO_ERROR; } } } BufferQueueProducer connect 调用BnGraphicBufferProducer的connect方法，BufferQueueProducer继承于BnGraphicBufferProducer，调用BufferQueueProducer的connect方法： //frameworks/native/libs/gui/BufferQueueProducer.cpp class BufferQueueProducer : public BnGraphicBufferProducer, private IBinder::DeathRecipient { sp\u003cBufferQueueCore\u003e mCore; status_t BufferQueueProducer::connect(const sp\u003cIProducerListener\u003e\u0026 listener, int api, bool producerControlledByApp, QueueBufferOutput *output) { ATRACE_CALL()","date":"2024-11-06","objectID":"/posts/android13-surface-connect%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 Surface connect流程分析-CSDN博客","uri":"/posts/android13-surface-connect%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"SurfaceControl是Android系统中的一个类，用于管理和控制Surface的创建、显示和销毁，SurfaceControl的创建过程如下： 下面分析WindowManagerService创建SurfaceControl的步骤： 首先应用进程会new一个java层SurfaceControl，什么都没做，然后传递到WMS进程，因为SurfaceControl在AIDL中是out类型，所以在WMS进程赋值。 WMS在创建java层SurfaceControl的同时通过nativeCreate方法到native层做一系列初始化。 在SurfaceComposerClient的createSurfaceChecked函数中通过ISurfaceComposerClient的Bp端mClient向SurfaceFlinger进程请求创建Surface，即调用createSurface函数，而在SurfaceFlinger进程Surface对应的是Layer。 在第一次创建Layer的子类BufferQueueLayer的过程中，即在BufferQueueLayer的onFirstRef函数中会创建生产者消费者模型架构。Android13 BufferQueueLayer onFirstRef流程分析-CSDN博客 SurfaceFlinger进程的任务完成之后会直接new一个SurfaceControl，并将SurfaceFlinger进程创建的Layer引用和生产者保存到SurfaceControl中，最后将native层SurfaceControl指针保存到java层SurfaceControl。 native层SurfaceControl创建好了之后就可以通过此对象创建native层的Surface对象，最后将native层Surface指针保存到java层Surface，最终java层和native层的Surface和SurfaceControl都创建完毕。 下面我们通过代码分析，首先在WindowManagerService的relayoutWindow方法中，会调用createSurfaceControl方法： 我们继续从SurfaceControl构造器(SurfaceControl.Builder)的build方法开始分析SurfaceControl的创建过程： //frameworks/base/core/java/android/view/SurfaceControl.java public final class SurfaceControl implements Parcelable { public static class Builder { public SurfaceControl build() { if (mWidth \u003c 0 || mHeight \u003c 0) { throw new IllegalStateException( \"width and height must be positive or unset\"); } if ((mWidth \u003e 0 || mHeight \u003e 0) \u0026\u0026 (isEffectLayer() || isContainerLayer())) { throw new IllegalStateException( \"Only buffer layers can set a valid buffer size.\"); } if ((mFlags \u0026 FX_SURFACE_MASK) == FX_SURFACE_NORMAL) { setBLASTLayer(); } return new SurfaceControl( mSession, mName, mWidth, mHeight, mFormat, mFlags, mParent, mMetadata, mLocalOwnerView, mCallsite); } } } 直接通过new的方式创建SurfaceControl，接着看SurfaceControl的构造方法： // frameworks/base/core/java/android/view/SurfaceControl.java private SurfaceControl(SurfaceSession session, String name, int w, int h, int format, int flags, SurfaceControl parent, SparseIntArray metadata) throws OutOfResourcesException, IllegalArgumentException { ...... mName = name; mWidth = w; mHeight = h; Parcel metaParcel = Parcel.obtain(); try { if (metadata != null \u0026\u0026 metadata.size() \u003e 0) { metaParcel.writeInt(metadata.size()); for (int i = 0; i \u003c metadata.size(); ++i) { metaParcel.writeInt(metadata.keyAt(i)); metaParcel.writeByteArray( ByteBuffer.allocate(4).order(ByteOrder.nativeOrder()) .putInt(metadata.valueAt(i)).array()); } metaParcel.setDataPosition(0); } mNativeObject = nativeCreate(session, name, w, h, format, flags, parent != null ? parent.mNativeObject : 0, metaParcel); } finally { metaParcel.recycle(); } if (mNativeObject == 0) { throw new OutOfResourcesException( \"Couldn't allocate SurfaceControl native object\"); } mCloseGuard.open(\"release\"); } 这里面核心就是调用nativeCreate方法，并将window的各种数据一并传递到native层处理，对应的native类是android_view_SurfaceControl。 // frameworks/base/core/jni/android_view_SurfaceControl.cpp static jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jobject metadataParcel) { ScopedUtfChars name(env, nameStr); //应用层访问SurfaceFlinger的client端 sp\u003cSurfaceComposerClient\u003e client; //这里的sessionObj是java层传递下来的SurfaceSession对象，如果不为空就从此对象中获取SurfaceComposerClient，否则重新创建一个 //addview --\u003e viewrootImpl 创建 SurfaceSession --\u003e natvieCreate //--\u003e SurfaceComposerClient 创建 if (sessionObj != NULL) { client = android_view_SurfaceSession_getClient(env, sessionObj); } else { client = SurfaceComposerClient::getDefault(); } //parentObject是java层传递下来的SurfaceControl，将其强转为native层SurfaceControl，parentObject有可能为空的 SurfaceControl *parent = reinterpret_cast\u003cSurfaceControl*\u003e(parentObject); sp\u003cSurfaceControl\u003e surface; LayerMetadata metadata; Parcel* parcel = parcelForJavaObject(env, metadataParcel); if (parcel \u0026\u0026 !parcel-\u003eobjectsCount()) { status_t err = metadata.readFromParcel(parcel); if (err != NO_ERROR) { jniThrowException(env, \"java/lang/IllegalArgumentException\", \"Metadata parcel has wrong format\"); } } //此函数是具体初始化SurfaceControl的函数 status_t err = client","date":"2024-11-06","objectID":"/posts/android13-surfacecontrol%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceControl创建流程分析-CSDN博客","uri":"/posts/android13-surfacecontrol%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"在Android13版本中，SurfaceFlinger是由Android.bp去启动init.rc文件，然后再解析文件去加载SurfaceFlinger。 //frameworks/native/services/surfaceflinger/SurfaceFlinger.rc service surfaceflinger /system/bin/surfaceflinger class core animation user system group graphics drmrpc readproc capabilities SYS_NICE onrestart restart --only-if-running zygote task_profiles HighPerformance socket pdx/system/vr/display/client stream 0666 system graphics u:object_r:pdx_display_client_endpoint_socket:s0 socket pdx/system/vr/display/manager stream 0666 system graphics u:object_r:pdx_display_manager_endpoint_socket:s0 socket pdx/system/vr/display/vsync stream 0666 system graphics u:object_r:pdx_display_vsync_endpoint_socket:s0 on property:vendor.debug.sf.restart=1 restart surfaceflinger on property:init.svc.zygote=restarting \u0026\u0026 property:debug.sf.toomanylayers=1 restart surfaceflinger setprop debug.sf.toomanylayers \"0\" 然后以此来调用main_SurfaceFlinger.cpp文件的main函数： //frameworks/native/services/surfacefilinger/main_SurfaceFlinger.cpp int main(int, char**) { signal(SIGPIPE, SIG_IGN); hardware::configureRpcThreadpool(1 /* maxThreads */, false /* callerWillJoin */); startGraphicsAllocatorService(); // When SF is launched in its own process, limit the number of // binder threads to 4. ProcessState::self()-\u003esetThreadPoolMaxThreadCount(4); // Set uclamp.min setting on all threads, maybe an overkill but we want // to cover important threads like RenderEngine. if (SurfaceFlinger::setSchedAttr(true) != NO_ERROR) { ALOGW(\"Couldn't set uclamp.min: %s\\n\", strerror(errno)); } // The binder threadpool we start will inherit sched policy and priority // of (this) creating thread. We want the binder thread pool to have // SCHED_FIFO policy and priority 1 (lowest RT priority) // Once the pool is created we reset this thread's priority back to // original. int newPriority = 0; int origPolicy = sched_getscheduler(0); struct sched_param origSchedParam; int errorInPriorityModification = sched_getparam(0, \u0026origSchedParam); if (errorInPriorityModification == 0) { int policy = SCHED_FIFO; newPriority = sched_get_priority_min(policy); struct sched_param param; param.sched_priority = newPriority; errorInPriorityModification = sched_setscheduler(0, policy, \u0026param); } // start the thread pool //构建ProcessState全局对象gProcess，打开binder驱动，建立链接 //在驱动内部创建该进程的binder_proc,binder_thread结构，保存该进程的进程信息和线程信息，并加入驱动的红黑树队列中。 //获取驱动的版本信息，把该进程最多可同时启动的线程告诉驱动，并保存到改进程的binder_proc结构中 //把设备文件/dev/binder映射到内存中 sp\u003cProcessState\u003e ps(ProcessState::self()); ps-\u003estartThreadPool(); // Reset current thread's policy and priority if (errorInPriorityModification == 0) { errorInPriorityModification = sched_setscheduler(0, origPolicy, \u0026origSchedParam); } else { ALOGE(\"Failed to set SurfaceFlinger binder threadpool priority to SCHED_FIFO\"); } // instantiate surfaceflinger // 实例化surfaceflinger sp\u003cSurfaceFlinger\u003e flinger = surfaceflinger::createSurfaceFlinger(); // Set the minimum policy of surfaceflinger node to be SCHED_FIFO. // So any thread with policy/priority lower than {SCHED_FIFO, 1}, will run // at least with SCHED_FIFO policy and priority 1. if (errorInPriorityModification == 0) { flinger-\u003esetMinSchedulerPolicy(SCHED_FIFO, newPriority); } //设置优先级 setpriority(PRIO_PROCESS, 0, PRIORITY_URGENT_DISPLAY); //把SF的自身调用限制在4线程 set_sched_policy(0, SP_FOREGROUND); // Put most SurfaceFlinger threads in the system-background cpuset // Keeps us from unnecessarily using big cores // Do this after the binder thread pool init if (cpusets_enabled()) set_cpuset_policy(0, SP_SYSTEM); // initialize before clients can connect // 在客户端连接之前进行初始化 flinger-\u003einit(); // publish surface flinger // 将surfaceflinger放入servicemanager sp\u003cIServiceManager\u003e sm(defaultServiceManager()); sm-\u003eaddService(String16(SurfaceFlinger::getServiceName()), flinger, false, IServiceManager::DUMP_FLAG_PRIORITY_CRITICAL | IServiceManager::DUMP_FLAG_PROTO); // publish gui::ISurfaceComposer, the new AIDL interface sp\u003cSurfaceComposerAIDL\u003e composerAIDL = new SurfaceComposerAIDL(flinger); sm-\u003eaddService(","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger启动流程分析-CSDN博客","uri":"/posts/android13-surfaceflinger%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"SurfaceSession是Android系统中与图形表面相关的一个关键类，它提供了与SurfaceFlinger服务通信以创建和管理图形表面连接的API，SurfaceSession在WindowManagerService的addWindow时创建，构造方法如下： //frameworks/base/core/java/android/view/SurfaceSession.java public final class SurfaceSession { public SurfaceSession() { mNativeClient = nativeCreate(); } } 调用nativeCreate方法，nativeCreate是个Native方法，通过查表调用android_view_SurfaceSession.cpp的nativeCreate方法： //frameworks/base/core/jni/android_view_SurfaceSession.cpp static jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); //创建SurfaceComposerClient对象 client-\u003eincStrong((void*)nativeCreate); return reinterpret_cast\u003cjlong\u003e(client); } 通过new的方式创建SurfaceComposerClient对象，SurfaceComposerClient的构造方法如下： //frameworks/native/libs/gui/SurfaceComposerClient.cpp class SurfaceComposerClient : public RefBase SurfaceComposerClient::SurfaceComposerClient() : mStatus(NO_INIT) {} } ","date":"2024-11-06","objectID":"/posts/android13-surfacesession%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceSession创建流程分析_android surfacesession-CSDN博客","uri":"/posts/android13-surfacesession%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Surface是Android中用于表示一个图像缓冲区的类，Surface是在SurfaceControl创建时创建的，代码如下： //frameworks/native/services/surfaceflinger/Client.cpp class Client : public BnSurfaceComposerClient status_t Client::createSurface(const String8\u0026 name, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, const sp\u003cIBinder\u003e\u0026 parentHandle, LayerMetadata metadata, sp\u003cIBinder\u003e* handle, sp\u003cIGraphicBufferProducer\u003e* gbp) { // We rely on createLayer to check permissions. return mFlinger-\u003ecreateLayer(name, this, w, h, format, flags, std::move(metadata), handle, gbp, parentHandle); } } SurfaceFlinger createLayer mFlinger是SurfaceFlinger，所以Client的具体实现还是依靠的SurfaceFlinger，并且注意，在应用层的Surface在SurfaceFlinger进程名叫Layer，它和应用层的Surface是一 一对应的关系，我们来看createLayer函数： //frameworks/native/service/SurfaceFlinger/SurfaeFlinger.cpp class SurfaceFlinger : public BnSurfaceComposer, public PriorityDumper, private IBinder::DeathRecipient, private HWC2::ComposerCallback, private ICompositor, private scheduler::ISchedulerCallback { status_t SurfaceFlinger::createLayer(const String8\u0026 name, const sp\u003cClient\u003e\u0026 client, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, LayerMetadata metadata, sp\u003cIBinder\u003e* handle, sp\u003cIGraphicBufferProducer\u003e* gbp, const sp\u003cIBinder\u003e\u0026 parentHandle, const sp\u003cLayer\u003e\u0026 parentLayer) { //宽高合法检查 if (int32_t(w|h) \u003c 0) { ALOGE(\"createLayer() failed, w or h is negative (w=%d, h=%d)\", int(w), int(h)); return BAD_VALUE; } status_t result = NO_ERROR; //layer sp\u003cLayer\u003e layer; ...... //根据不同flag创建不同layer switch (flags \u0026 ISurfaceComposerClient::eFXSurfaceMask) { case ISurfaceComposerClient::eFXSurfaceBufferQueue: result = createBufferQueueLayer(client, uniqueName, w, h, flags, std::move(metadata), format, handle, gbp, \u0026layer); break; case ISurfaceComposerClient::eFXSurfaceBufferState: result = createBufferStateLayer(client, uniqueName, w, h, flags, std::move(metadata), handle, \u0026layer); break; case ISurfaceComposerClient::eFXSurfaceColor: // check if buffer size is set for color layer. if (w \u003e 0 || h \u003e 0) { ALOGE(\"createLayer() failed, w or h cannot be set for color layer (w=%d, h=%d)\", int(w), int(h)); return BAD_VALUE; } result = createColorLayer(client, uniqueName, w, h, flags, std::move(metadata), handle, \u0026layer); break; case ISurfaceComposerClient::eFXSurfaceContainer: // check if buffer size is set for container layer. if (w \u003e 0 || h \u003e 0) { ALOGE(\"createLayer() failed, w or h cannot be set for container layer (w=%d, h=%d)\", int(w), int(h)); return BAD_VALUE; } result = createContainerLayer(client, uniqueName, w, h, flags, std::move(metadata), handle, \u0026layer); break; default: result = BAD_VALUE; break; } ....... return result; } } SurfaceFlinger createBufferQueueLayer 上面函数的核心代码就是根据应用请求不同的flag创建不同的显示Layer，从上面代码看创建的Layer有四种类型，我们看看系统中大多数界面的Layer ，flage 为eFXSurfaceBufferQueueyer，我们就大致看看createBufferQueueLayer函数。 //frameworks/native/service/surfaceflinger/SurfaeFlinger.cpp status_t SurfaceFlinger::createBufferQueueLayer(const sp\u003cClient\u003e\u0026 client, const String8\u0026 name, uint32_t w, uint32_t h, uint32_t flags, LayerMetadata metadata, PixelFormat\u0026 format, sp\u003cIBinder\u003e* handle, sp\u003cIGraphicBufferProducer\u003e* gbp, sp\u003cLayer\u003e* outLayer) { // initialize the surfaces switch (format) { case PIXEL_FORMAT_TRANSPARENT: case PIXEL_FORMAT_TRANSLUCENT: format = PIXEL_FORMAT_RGBA_8888; break; case PIXEL_FORMAT_OPAQUE: format = PIXEL_FORMAT_RGBX_8888; break; } sp\u003cBufferQueueLayer\u003e layer = getFactory().createBufferQueueLayer( LayerCreationArgs(this, client, name, w, h, flags, std::move(metadata))); status_t err = layer-\u003esetDefaultBufferProperties(w, h, format); if (err == NO_ERROR) { *handle = layer-\u003egetHandle(); *gbp = layer-\u003egetProducer(); *outLayer = layer; } return err; } 可以看到上面函数的核心是调用getFactory().createBufferQueueLayer，最终创建的是Layer的子类BufferQueueLayer： //frameworks/native/service/surfaceflinger/SurfaeFlinger.cpp sp\u003cBufferQueueLayer\u003e createBufferQueueLayer(const LayerCreationArgs\u0026 args) override { return new BufferQueueLayer(args); } SurfaceFlingerFactory的createBufferQueueLayer函数只是new了一个BufferQueueL","date":"2024-11-06","objectID":"/posts/android13-surface%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","Framework","转载"],"title":"Android13 Surface创建流程分析-CSDN博客","uri":"/posts/android13-surface%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"“JNI开发中请问如果想要一个纯native线程中执行的native方法需要调用到Java层应该要怎么做？” 大家注意这个问题哈，是纯native线程和方法，即没有我们正常jni调用的env环境的，正常的如果jni方法是由java层调用到jni一般都是自带了JNIEnv变量如下： 拿getMemInfo举例子，如： java层： public static native void getMemInfo(long[] outSizes); 转变成了native层面代码就是如下： static void android_os_Debug_getMemInfo(JNIEnv *env, jobject clazz, jlongArray out) 大家看这里是不是自带了一个变量JNIEnv *env，有了这里env后再想调用Java层面的方法就很简单，具体看参考如下： 比如经常Java调用jni时候。 tatic void android_os_Debug_getMemInfo(JNIEnv *env, jobject clazz, jlongArray out) { char buffer[1024]; size_t numFound = 0; if (out == NULL) { jniThrowNullPointerException(env, \"out == null\");//抛出空指针到java return; } //省略。。。。 } jniThrowNullPointerException方法就需要传递env，jniThrowNullPointerException最后调用到了jniThrowException：如下 // libnativehelper/JNIHelp.cpp extern \"C\" int jniThrowException(C_JNIEnv* env, const char* className, const char* msg) { JNIEnv* e = reinterpret_cast\u003cJNIEnv*\u003e(env); if ((*env)-\u003eExceptionCheck(e)) { /* TODO: consider creating the new exception with this as \"cause\" */ scoped_local_ref\u003cjthrowable\u003e exception(env, (*env)-\u003eExceptionOccurred(e)); (*env)-\u003eExceptionClear(e); if (exception.get() != NULL) { std::string text; getExceptionSummary(env, exception.get(), text); ALOGW(\"Discarding pending exception (%s) to throw %s\", text.c_str(), className); } } scoped_local_ref\u003cjclass\u003e exceptionClass(env, findClass(env, className)); if (exceptionClass.get() == NULL) { ALOGE(\"Unable to find exception class %s\", className); /* ClassNotFoundException now pending */ return -1; } if ((*env)-\u003eThrowNew(e, exceptionClass.get(), msg) != JNI_OK) { ALOGE(\"Failed throwing '%s' '%s'\", className, msg); /* an exception, most likely OOM, will now be pending */ return -1; } return 0; } 这里就需要使用env来获取对应的java类，及对应属性，方法等 回到面试题目，人家要求没有纯native线程里面native方法，即说明这种情况下肯定不自带JNIEnv的，故这里该怎么办呢？ 不自带JNIEnv，但是调用java又需要JNIEnv，故得想方法构造出JNIEnv具体如下： 下面以一个Android源码中实战例子来说明： 源码位子参考： frameworks/base/core/jni/android/graphics/SurfaceTexture.cpp 1、获取JavaVM,通过AndroidRuntime::getJavaVM()获取JavaVM 2、通过JavaVM绑定到当前线线程获取JNIEnv，通过vm-\u003eAttachCurrentThread方法中参数赋值JNIEnv JNIEnv* JNISurfaceTextureContext::getJNIEnv(bool* needsDetach) { *needsDetach = false; JNIEnv* env = AndroidRuntime::getJNIEnv(); if (env == NULL) { JavaVMAttachArgs args = { JNI_VERSION_1_4, \"JNISurfaceTextureContext\", NULL }; JavaVM* vm = AndroidRuntime::getJavaVM();//获取JavaVM int result = vm-\u003eAttachCurrentThread(\u0026env, (void*) \u0026args);//赋值env if (result != JNI_OK) { ALOGE(\"thread attach failed: %#x\", result); return NULL; } *needsDetach = true; } return env; } 3、使用env： void JNISurfaceTextureContext::onFrameAvailable(const BufferItem\u0026 /* item */) { bool needsDetach = false; JNIEnv* env = getJNIEnv(\u0026needsDetach); if (env != NULL) { env-\u003eCallStaticVoidMethod(mClazz, fields.postEvent, mWeakThiz);//使用env调用java方法 } else { ALOGW(\"onFrameAvailable event will not posted\"); } if (needsDetach) { detachJNI(); } } 4、不需要使用了记得与当前线程解绑定，调用JavaVM的DetachCurrentThread方法 void JNISurfaceTextureContext::detachJNI() { JavaVM* vm = AndroidRuntime::getJavaVM(); int result = vm-\u003eDetachCurrentThread();//解绑定 if (result != JNI_OK) { ALOGE(\"thread detach failed: %#x\", result); } } ","date":"2024-11-06","objectID":"/posts/android%E6%BA%90%E7%A0%81%E4%B8%AD%E5%AD%A6%E4%B9%A0jni%E9%82%A3%E4%BA%9B%E4%BA%8B--%E5%85%B3%E9%94%AE%E6%8A%80%E5%B7%A7-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android源码中学习JNI那些事--关键技巧-CSDN博客","uri":"/posts/android%E6%BA%90%E7%A0%81%E4%B8%AD%E5%AD%A6%E4%B9%A0jni%E9%82%A3%E4%BA%9B%E4%BA%8B--%E5%85%B3%E9%94%AE%E6%8A%80%E5%B7%A7-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BLASTBufferQueue创建部分 BLASTBufferQueue::BLASTBufferQueue(const std::string\u0026 name, bool updateDestinationFrame) : mSurfaceControl(nullptr), mSize(1, 1), mRequestedSize(mSize), mFormat(PIXEL_FORMAT_RGBA_8888), mTransactionReadyCallback(nullptr), mSyncTransaction(nullptr), mUpdateDestinationFrame(updateDestinationFrame) { //创建BufferQueue部分，并且会给mProducer，mConsumer进行赋值 createBufferQueue(\u0026mProducer, \u0026mConsumer); //创建BLASTBufferItemConsumer部分 mBufferItemConsumer = new BLASTBufferItemConsumer(mConsumer, GraphicBuffer::USAGE_HW_COMPOSER | GraphicBuffer::USAGE_HW_TEXTURE, 1, false, this); static int32_t id = 0; mName = name + \"#\" + std::to_string(id); auto consumerName = mName + \"(BLAST Consumer)\" + std::to_string(id); mQueuedBufferTrace = \"QueuedBuffer - \" + mName + \"BLAST#\" + std::to_string(id); id++; mBufferItemConsumer-\u003esetName(String8(consumerName.c_str())); mBufferItemConsumer-\u003esetFrameAvailableListener(this); mBufferItemConsumer-\u003esetBufferFreedListener(this); ComposerService::getComposerService()-\u003egetMaxAcquiredBufferCount(\u0026mMaxAcquiredBuffers); mBufferItemConsumer-\u003esetMaxAcquiredBufferCount(mMaxAcquiredBuffers); mCurrentMaxAcquiredBufferCount = mMaxAcquiredBuffers; mNumAcquired = 0; mNumFrameAvailable = 0; } BufferQueue部分 下面来看看核心的方法createBufferQueue void BLASTBufferQueue::createBufferQueue(sp\u003cIGraphicBufferProducer\u003e* outProducer, sp\u003cIGraphicBufferConsumer\u003e* outConsumer) { //创建核心的BufferQueueCore sp\u003cBufferQueueCore\u003e core(new BufferQueueCore()); //基于BufferQueueCore创建BBQBufferQueueProducer sp\u003cIGraphicBufferProducer\u003e producer(new BBQBufferQueueProducer(core)); //基于BufferQueueCore创建BufferQueueConsumer sp\u003cBufferQueueConsumer\u003e consumer(new BufferQueueConsumer(core)); consumer-\u003esetAllowExtraAcquire(true); *outProducer = producer; *outConsumer = consumer; } 下面重点看看BufferQueueCore BufferQueueCore::BufferQueueCore() : mMutex(),//若干个成员变量初始化 mIsAbandoned(false), mConsumerControlledByApp(false), mConsumerName(getUniqueName()), mConsumerListener(), mConsumerUsageBits(0), mConsumerIsProtected(false), mConnectedApi(NO_CONNECTED_API), mLinkedToDeath(), mConnectedProducerListener(), mBufferReleasedCbEnabled(false), mSlots(), mQueue(), mFreeSlots(), mFreeBuffers(), mUnusedSlots(), mActiveBuffers(), mDequeueCondition(), mDequeueBufferCannotBlock(false), mQueueBufferCanDrop(false), mLegacyBufferDrop(true), mDefaultBufferFormat(PIXEL_FORMAT_RGBA_8888), mDefaultWidth(1), mDefaultHeight(1), mDefaultBufferDataSpace(HAL_DATASPACE_UNKNOWN), mMaxBufferCount(BufferQueueDefs::NUM_BUFFER_SLOTS), mMaxAcquiredBufferCount(1), mMaxDequeuedBufferCount(1), mBufferHasBeenQueued(false), mFrameCounter(0), mTransformHint(0), mIsAllocating(false), mIsAllocatingCondition(), mAllowAllocation(true), mBufferAge(0), mGenerationNumber(0), mAsyncMode(false), mSharedBufferMode(false), mAutoRefresh(false), mSharedBufferSlot(INVALID_BUFFER_SLOT), mSharedBufferCache(Rect::INVALID_RECT, 0, NATIVE_WINDOW_SCALING_MODE_FREEZE, HAL_DATASPACE_UNKNOWN), mLastQueuedSlot(INVALID_BUFFER_SLOT), mUniqueId(getUniqueId()), mAutoPrerotation(false), mTransformHintInUse(0) { int numStartingBuffers = getMaxBufferCountLocked(); for (int s = 0; s \u003c numStartingBuffers; s++) { mFreeSlots.insert(s);//初始化时候针对mFreeSlots填入了MaxBufferCount个 } for (int s = numStartingBuffers; s \u003c BufferQueueDefs::NUM_BUFFER_SLOTS; s++) { mUnusedSlots.push_front(s);//除了mFreeSlots部分，其他都是填入mUnusedSlots } } 上面的构造中有以下几个成员变量非常关键需要重点介绍 // mSlots is an array of buffer slots that must be mirrored on the producer // side. This allows buffer ownership to be transferred between the producer // and consumer without sending a GraphicBuffer over Binder. The entire // array is initialized to NULL at construction time, and buffers are // allocated for a slot when requestBuffer is called with that slot's index. BufferQueueDefs::SlotsType mSlots; // mQueue is a FIFO of queued buffers used in synchronous mode. Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently // have a buffer attached. std::set\u003cint\u003e mFreeSlots;","date":"2024-11-06","objectID":"/posts/blastbufferqueue%E6%BA%90%E7%A0%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"BLASTBufferQueue源码深入理解-CSDN博客","uri":"/posts/blastbufferqueue%E6%BA%90%E7%A0%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"前言 作为本系列文章的首篇文章，在开始之前我一直在思考，首篇文章应该写啥内容？才能让读者很容易明白PackageManagerService是啥呢，如何为后面文章起到承上启下的作用呢。 后来我决定以介绍PackageManagerService服务中的各种繁多复杂的数据类为开篇，理由是数据类是基础，故数据类先行。遂开始一顿猛的输出，当即将接近尾声的时候，我发现不对啊，假如我是一个对PackageManagerService完全没接触的人，刚一上来就看到这么多非常陌生的数据类，那完全就是一种懵逼的感觉啊。 于是我决定重新规划，以介绍PackageManagerService及它包含的模块为首篇，这样即使对PackageManagerService陌生的人，也能先对它有一个初步的认识。同时后面的文章中会逐步深入的介绍PackageManagerService的内容。 本文摘要 这里的包管理指的是PackageManagerService这个服务，本篇是包管理系列文章的第一篇，既然整个系列文章都在介绍PackageManagerService，那本篇就带大家先认识一下PackageManagerService，通过本文您将了解PackageManagerService是啥，它被划分为哪些主要模块，这些模块之间又有啥关系。(文中代码基于Android13) 1 我是一个服务 大家好，我的名字叫PackageManagerService，如果觉得这名字太长大家可以叫我的小名PMS，我运行于systemserver进程，systemserver进程中有很多很多的服务，比如大家熟知的ActivityManagerService、WindowManagerService。而我也是一个服务，一个非常非常重要的服务。 上面多次提到一个词服务，那它到底意味着啥呢？那我就来给大家解释下，在Android中进程之间的通信用的最多的是鼎鼎大名的binder，而binder是client/server模式，也就是binder分为client端和server端，server端可以提供各种服务供多个client端使用。因此服务这个词就是指binder的server端，也就是说我PMS提供了包管理相关的功能，其他进程如果要想使用的话可以通过binder通信来“呼我”。 既然提到了包管理，其中包指的就是一个apk，那包管理也可以理解为对apk的管理，那PMS对apk主要进行以下几项管理： apk的安装/更新/卸载：这三件事情我全权交给PackageInstallerService，关于apk安装可以查看apk安装这篇文章。 apk信息查询，啥是apk信息查询呢？比如想要知道当前Android设备都安装了哪些apk，可以来我这取；再比如想要知道某个apk都包含了哪些四大组件，也可以来我这取。 apk权限管理，基本每个被安装的apk都是需要申请一些权限的，那这些权限是被用户授权了呢，还是被用户拒绝了呢，都可以来找我。我把这个事情交给PermissionManagerService来管理。 可别小看了我，我可不是只负责上面的这些事情，只不过上面这些事情经常用到，故只罗列了它们而已。。我就是一个运行于systemserver进程对apk进行管理的非常重要的服务。 介绍完我自己，我觉得非常有必要介绍一下我管理的对象apk，你们人类有句话是这样说的：对自己的管理对象没有深入了解的领导不是一个好领导。并且对apk有一个深入了解后，再来理解我就更容易了。(对apk熟悉的话该部分可以跳过) 1 我管理的对象 我管理的对象apk，是 Android Package 的缩写，它其实是一个zip格式的压缩文件，只不过为了能让大家从文件名上一眼认出来，故文件后缀是 .apk。 贴心的我为了让大家更容易了解apk，故画了一幅图，下图展示了apk内包含的主要文件和目录。 图解 lib目录 该目录下面包含了使用到的so库。 res、assets目录 这两个目录下面包含了各种资源比如图片、layout文件等。 META-INF 该目录下面包含了和签名证书有关的文件。 dex java/kotlin编译后的字节码文件。 resources.arsc 文件可以视为一个资源表，它存储了所有资源的ID和这些资源在APK文件或其他位置中的引用。 AndroidManifest.xml需要着重介绍下，因为它对于我PMS来说非常重要。 2.1 AndroidManifest.xml 可以在AndroidManifest.xml文件中使用activity、provider、service、receiver标签来声明四大组件，也可以使用uses-permission标签来申请使用哪些权限，当然还有其他的标签。 那AndroidManifest.xml和使用标签声明或者申请的这些信息到底是给谁用的呢？ 答案是PMS，AndroidManifest.xml就像饭馆的菜单，从菜单上可以看出这个饭馆到底有哪些饭、菜，菜单是给顾客使用的。而AndroidManifest.xml是给PMS使用的，PMS只有通过AndroidManifest.xml才能知道一个apk内到底声明了哪些四大组件、申请了哪些权限、使用了哪些共享库等等，因此对于PMS可以通过解析AndroidManifest.xml内的各种标签来获取apk内声明的各种信息。 下图展示了AndroidManifest.xml中常用的标签。 2.2 小结 我把我的管理对象apk介绍给了大家，其实我主要目的是想把apk中的AndroidManifest.xml着重介绍给大家，因为它对于我PMS来说非常重要，我只有通过它才能知道一个apk内到底声明了哪些四大组件、申请了哪些权限、使用了哪些共享库等等。 那接下来大家把“视线”再次聚焦到我身上，继续把我自己介绍给大家。 3 我的“小伙伴” 你们可不要把我想象的很厉害，很多工作都是由我和我的“小伙伴们”共同完成的，单凭我一个“人”可不行。为了让大家能更清楚的认识我的“小伙伴”，我用一张图把它们展示给大家。 我的主要“小伙伴”有apk管理模块、权限管理模块、共享库模块、记录存储模块、所有apk信息模块、四大组件模块。那我就把舞台交给它们，让它们亲自把自己介绍给大家吧。 3.1 权限管理模块 大家好，我是权限管理模块，为了让大家更了解我的工作，我先来介绍下权限，权限分为声明权限和请求权限。 声明权限 还记得在上面介绍apk的AndroidManifest.xml的时候，声明权限需要在AndroidManifest.xml文件中使用permission标签，如下例子： \u003cpermission android:description=\"string resource\" android:icon=\"drawable resource\" android:label=\"string resource\" android:name=\"string\" android:permissionGroup=\"string\" android:protectionLevel=[\"normal\" | \"dangerous\" | \"signature\" | ...] /\u003e 每个apk都可以声明自己的权限，那当别的apk访问自己的一些关键信息时候就可以要求它具有某个声明的权限后才可以访问。 请求权限 每个安装在Android设备上的apk或多或少的都会用到一些权限，请求权限就是在AndroidManifest中通过uses-permission标签来使用权限，如下代码： \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"/\u003e 而我权限管理模块所做的事情如下： 把所有的apk声明的权限收集并集中管理起来 而每个apk请求的权限和权限对应的状态我也会保存起来，权限对应的状态是指比如某个apk的权限是否被允许、是否拒绝、是否只是允许一次 apk在请求某个权限时，当用户不管是点击了允许、拒绝等，都需要经过我 以上就是我所做的事情，而我把这些事情全权交给了PermissionManagerService服务来处理，关于我会在后面的文章再次与大家见面。 3.2 共享库模块 大家好，我是共享库模块，同样我也先来介绍下共享库，像framework.jar这个库包含了很多的类比如Activity、Context、Service等，而framework.jar在zygote进程中已经被预加载了，因此每个apk直接使用即可。而像一些库比如com.google.android.maps，它是没有被包含在framework.jar中的，而com.google.android.maps以共享库的方式提供给使用者来使用。而共享库也分为声明共享库和使用共享库。 声明共享库 首先只有系统apk才可以声明共享库，为啥有这样的规定？主要原因是既然是共享库就需要保证它的稳定性，如果是普通apk可以声明共享库，那设备上没有装该apk，那共享库就不存在。声明共享库非常简单在AndroidManifest.xml文件中使用library标签，如下例子： \u003clibrary android:name=\"android.ext.shared\" /\u003e 使用共享库 使用共享库在AndroidManifest.xml文件中使用uses-library (使用java库)或者uses-native-library (使用native库) 标签，如下例子： ","date":"2024-11-06","objectID":"/posts/packagemanagerservice%E5%92%8C%E5%AE%83%E7%9A%846%E4%B8%AA%E5%B0%8F%E4%BC%99%E4%BC%B4/:0:0","tags":["clippings","转载","blog"],"title":"PackageManagerService和它的6个“小伙伴”","uri":"/posts/packagemanagerservice%E5%92%8C%E5%AE%83%E7%9A%846%E4%B8%AA%E5%B0%8F%E4%BC%99%E4%BC%B4/"},{"categories":null,"content":"背景 前面文章和视频课程都是直接从SurfaceFlinger层面开始讲解Vsync部分的，当然vsync的主要核心逻辑也确实在SurfaceFlinger，但是一般vsync都是由app层面发起请求的，这一部分也还是有必要带大家了解清楚 java层面的分析和堆栈： 在Activity进行Resume时候，会addView,这个时候会对ViewRootImpl进行够着，构建出一个Choreographer，在构造时候会构造方法里面又会对应的FrameDisplayEventReceiver，FrameDisplayEventReceiver本身继承DisplayEventReceiver 这里的DisplayEventReceiver就是核心部分，它负责和sf进行双向通讯，不过这里双向不是一种ipc通讯方式，涉及到两个方式 app主动发起请求一般都是直接使用binder调用，比如常见的如下几个接口： interface IDisplayEventConnection { /* * stealReceiveChannel() returns a BitTube to receive events from. Only the receive file * descriptor of outChannel will be initialized, and this effectively \"steals\" the receive * channel from the remote end (such that the remote end can only use its send channel). */ void stealReceiveChannel(out BitTube outChannel); /* * setVsyncRate() sets the vsync event delivery rate. A value of 1 returns every vsync event. * A value of 2 returns every other event, etc. A value of 0 returns no event unless * requestNextVsync() has been called. */ void setVsyncRate(in int count); /* * requestNextVsync() schedules the next vsync event. It has no effect if the vsync rate is \u003e 0. */ oneway void requestNextVsync(); // Asynchronous /* * getLatestVsyncEventData() gets the latest vsync event data. */ ParcelableVsyncEventData getLatestVsyncEventData(); } SurfaceFlinger进程也需要与app进行通讯，比如把vsync来临这种通知调用： 这里为啥sf要是有socket呢？这里主要还是为了性能考虑，socket相比延时阻塞情况比binder好，vsync通知这种属于实时性较强的操作。 下面接着看看app层面FrameDisplayEventReceiver构造接下来干了啥 public FrameDisplayEventReceiver(Looper looper, int vsyncSource) { super(looper, vsyncSource, 0);//直接调用了父类的构造 } /** * Creates a display event receiver. * * @param looper The looper to use when invoking callbacks. * @param vsyncSource The source of the vsync tick. Must be on of the VSYNC_SOURCE_* values. * @param eventRegistration Which events to dispatch. Must be a bitfield consist of the * EVENT_REGISTRATION_*_FLAG values. */ public DisplayEventReceiver(Looper looper, int vsyncSource, int eventRegistration) { mMessageQueue = looper.getQueue(); mReceiverPtr = nativeInit(new WeakReference\u003cDisplayEventReceiver\u003e(this), mMessageQueue, vsyncSource, eventRegistration); } 这里调用了nativeInit，接下来代码就到了native层面了 具体堆栈如下： native层面的分析和堆栈： 接上面的nativeInit frameworks/base/core/jni/android_view_DisplayEventReceiver.cpp static jlong nativeInit(JNIEnv* env, jclass clazz, jobject receiverWeak, jobject messageQueueObj, jint vsyncSource, jint eventRegistration) { //省略部分 sp\u003cNativeDisplayEventReceiver\u003e receiver = new NativeDisplayEventReceiver(env, receiverWeak, messageQueue, vsyncSource, eventRegistration); status_t status = receiver-\u003einitialize(); //省略部分 return reinterpret_cast\u003cjlong\u003e(receiver.get()); } 构造 NativeDisplayEventReceiver类： NativeDisplayEventReceiver::NativeDisplayEventReceiver(JNIEnv* env, jobject receiverWeak, const sp\u003cMessageQueue\u003e\u0026 messageQueue, jint vsyncSource, jint eventRegistration) : DisplayEventDispatcher(messageQueue-\u003egetLooper(), static_cast\u003cISurfaceComposer::VsyncSource\u003e(vsyncSource), static_cast\u003cISurfaceComposer::EventRegistration\u003e(eventRegistration)), mReceiverWeakGlobal(env-\u003eNewGlobalRef(receiverWeak)), mMessageQueue(messageQueue) { } 注意这里的NativeDisplayEventReceiver继承DisplayEventDispatcher DisplayEventDispatcher::DisplayEventDispatcher( const sp\u003cLooper\u003e\u0026 looper, ISurfaceComposer::VsyncSource vsyncSource, ISurfaceComposer::EventRegistrationFlags eventRegistration) : mLooper(looper), mReceiver(vsyncSource, eventRegistration), mWaitingForVsync(false), mLastVsyncCount(0), mLastScheduleVsyncTime(0) { ALOGV(\"dispatcher %p ~ Initializing display event dispatcher.\", this); } 注意这里的DisplayEventDispatcher构造也会mReceiver也构造， mReceiver是DisplayEventReceiver 类型，构造方法如下： DisplayEventReceiver::DisplayEventReceiver( ISurfaceComposer::VsyncSource vsyncSource, ISurfaceComposer::EventRegistrationFlags eventRegistration) { sp\u003cISurfaceComposer\u003e sf(ComposerService::getComposerService()); if (sf != nullptr) { //会与sf进行跨进程通讯，让创建对应connection mEventConnection = sf-\u003ecreateDisplayEventConnection(vsyncSource, eventRegistration); if (","date":"2024-11-06","objectID":"/posts/vsync%E4%B9%8Bapp%E5%B1%82%E9%9D%A2%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90-vsynceventdata-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","WMS","blog"],"title":"Vsync之app层面深入分析  vsynceventdata-CSDN博客","uri":"/posts/vsync%E4%B9%8Bapp%E5%B1%82%E9%9D%A2%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90-vsynceventdata-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":["AMS","Android"],"content":"ActivityRecord、TaskRecord、ActivityStack、ActivityDisplay、ActivityStackSupervisor 的关系 ActivityManagerService Activity栈管理 ActivityRecord 记录Activity的信息，并通过成员变量task指向TaskRecord。 类型 名称 说明 ProcessRecord app 跑在哪个进程 TaskRecord task 跑在哪个task ActivityInfo info Activity信息 int mActivityType Activity类型 ActivityState state Activity状态 ApplicationInfo appInfo 跑在哪个app ComponentName realActivity 组件名 String packageName 包名 String processName 进程名 int launchMode 启动模式 int userId 该Activity运行在哪个用户Id TaskRecord 描述Activity的Affinity所属的栈。 类型 名称 说明 ActivityStack stack 当前所属的stack ArrayList mActivities 当前task的所有Activity列表 int taskId TaskRecord的Id String affinity root activity的affinity，即该Task中第一个Activity int mCallingUid 调用者的UserId String mCallingPackage 调用者的包名 ActivityStack 管理着TaskRecord，内部维护Activity所有状态、特殊状态的Activity和Activity相关的列表数据。 类型 名称 说明 ArrayList mTaskHistory 保存所有的Task列表 ArrayList mStacks 所有的stack列表 int mStackId ActivityStackvisor的mActivityContainers的key值Id int mDisplayId ActivityStackSupervisor的mActivityDisplays的key值Id ActivityRecord mPauseingActivity 正在暂停的Activity ActivityRecord mLastPausedActivity 上一个已暂停的Activity ActivityRecord mResumedActivity 已经Resumed的Activity ActivityRecord mLastStartedActivity 最近一次启动的Activity ActivityStackSupervisor 管理所有的ActivityStack。 类型 名称 说明 ActivityStack mHomeStack 桌面的stack ActivityStack mFocusedStack 当前聚焦的stack ActivityStack mLastFocusedStack 正在切换到聚焦的stack SparseArray mActivityDisplays displayId为key SparseArray mActivityContainers mStackId为key ActivityDisplay 表示一个屏幕，Android支持三种屏幕：主屏幕，外接屏幕（HDMI等），虚拟屏幕（投屏）一般地，对于没有分屏功能以及虚拟屏的情况下，ActivityStackSupervisor与ActivityDisplay都是系统唯一；ActivityDisplay主要有Home Stack和App Stack这两个栈。 记忆关系链 每个ActivityStack中可以有若干个TaskRecord对象；每个TaskRecord中可以有若干个ActivityRecord对象；每个ActivityRecord记录一个Activity信息。 正向关系链表： java 代码解读 复制代码ActivityStackSupervisor.mActivityDisplays -\u003e ActivityDisplay.mStack -\u003e ActivityStack.mTaskHistory -\u003e TaskRecord.mActivities -\u003e ActivityRecord 反向关系链 java 代码解读 复制代码ActivityRecord.task -\u003e TaskRecord.mStack -\u003e ActivityStack.mStackSupervisor -\u003e ActivityStackSupervisor ActivityStack.mDisplayId可以找到对应的ActivityDisplay，HOME_STACK_ID=0可以在ActivityStackSupervisor.mActivityDisplays找到桌面的ActivityStack。 引用： 作者：彭小铭 链接：https://juejin.cn/post/7267554771540049957 来源：稀土掘金 ","date":"2024-11-06","objectID":"/posts/ams--activityrecordtaskrecordactivitystackactivitydisplayactivitystacksupervisor/:0:0","tags":["AMS","blog","Framework"],"title":"AMS   -- ActivityRecord、TaskRecord、ActivityStack、ActivityDisplay、ActivityStackSupervisor","uri":"/posts/ams--activityrecordtaskrecordactivitystackactivitydisplayactivitystacksupervisor/"},{"categories":null,"content":"BufferQueueConsumer的acquireBuffer方法的主要作用是从BufferQueue中获取一个可用的图像缓冲区，并返回一个GraphicBuffer对象。它可以用于在应用程序中进行图像处理、渲染或显示等操作。 在调用acquireBuffer方法时，它会首先检查是否有可用的图像缓冲区。如果有可用的缓冲区，则会将其标记为“已使用”，并返回该缓冲区的GraphicBuffer对象。如果没有可用的缓冲区，则会等待直到有可用的缓冲区为止。 BufferQueueConsumer的acquireBuffer方法代码如下： //frameworks/native/libs/gui/BufferQueueConsumer.cpp status_t BufferQueueConsumer::acquireBuffer(BufferItem* outBuffer, nsecs_t expectedPresent, uint64_t maxFrameNumber) { ATRACE_CALL(); int numDroppedBuffers = 0; sp\u003cIProducerListener\u003e listener; { std::unique_lock\u003cstd::mutex\u003e lock(mCore-\u003emMutex); // Check that the consumer doesn't currently have the maximum number of // buffers acquired. We allow the max buffer count to be exceeded by one // buffer so that the consumer can successfully set up the newly acquired // buffer before releasing the old one. int numAcquiredBuffers = 0; for (int s : mCore-\u003emActiveBuffers) { if (mSlots[s].mBufferState.isAcquired()) { ++numAcquiredBuffers; } } const bool acquireNonDroppableBuffer = mCore-\u003emAllowExtraAcquire \u0026\u0026 numAcquiredBuffers == mCore-\u003emMaxAcquiredBufferCount + 1; if (numAcquiredBuffers \u003e= mCore-\u003emMaxAcquiredBufferCount + 1 \u0026\u0026 !acquireNonDroppableBuffer) { BQ_LOGE(\"acquireBuffer: max acquired buffer count reached: %d (max %d)\", numAcquiredBuffers, mCore-\u003emMaxAcquiredBufferCount); return INVALID_OPERATION; } bool sharedBufferAvailable = mCore-\u003emSharedBufferMode \u0026\u0026 mCore-\u003emAutoRefresh \u0026\u0026 mCore-\u003emSharedBufferSlot != BufferQueueCore::INVALID_BUFFER_SLOT; // In asynchronous mode the list is guaranteed to be one buffer deep, // while in synchronous mode we use the oldest buffer. if (mCore-\u003emQueue.empty() \u0026\u0026 !sharedBufferAvailable) { return NO_BUFFER_AVAILABLE; } BufferQueueCore::Fifo::iterator front(mCore-\u003emQueue.begin()); // If expectedPresent is specified, we may not want to return a buffer yet. // If it's specified and there's more than one buffer queued, we may want // to drop a buffer. // Skip this if we're in shared buffer mode and the queue is empty, // since in that case we'll just return the shared buffer. if (expectedPresent != 0 \u0026\u0026 !mCore-\u003emQueue.empty()) { // The 'expectedPresent' argument indicates when the buffer is expected // to be presented on-screen. If the buffer's desired present time is // earlier (less) than expectedPresent -- meaning it will be displayed // on time or possibly late if we show it as soon as possible -- we // acquire and return it. If we don't want to display it until after the // expectedPresent time, we return PRESENT_LATER without acquiring it. // // To be safe, we don't defer acquisition if expectedPresent is more // than one second in the future beyond the desired present time // (i.e., we'd be holding the buffer for a long time). // // NOTE: Code assumes monotonic time values from the system clock // are positive. // Start by checking to see if we can drop frames. We skip this check if // the timestamps are being auto-generated by Surface. If the app isn't // generating timestamps explicitly, it probably doesn't want frames to // be discarded based on them. while (mCore-\u003emQueue.size() \u003e 1 \u0026\u0026 !mCore-\u003emQueue[0].mIsAutoTimestamp) { const BufferItem\u0026 bufferItem(mCore-\u003emQueue[1]); // If dropping entry[0] would leave us with a buffer that the // consumer is not yet ready for, don't drop it. if (maxFrameNumber \u0026\u0026 bufferItem.mFrameNumber \u003e maxFrameNumber) { break; } // If entry[1] is timely, drop entry[0] (and repeat). We apply an // additional criterion here: we only drop the earlier buffer if our // desiredPresent falls within +/- 1 second of the expected present. // Otherwise, bogus desiredPresent times (e.g., 0 or a small // relative timestamp), which normally mean \"ignore the timestamp // and acquire immediately\", would cause us to drop frames. // // We may want to add an additional criterion: don't drop the // earlier buffer if entry[1]'s fence hasn't signaled yet. nsecs_t desiredPresent = bufferItem.mTimestamp; if (desiredPresent \u003c expectedPresent - MAX_REASONABLE_NSEC || desiredPres","date":"2024-11-06","objectID":"/posts/android13-bufferqueueconsumer-acquirebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueConsumer acquireBuffer流程分析-CSDN博客","uri":"/posts/android13-bufferqueueconsumer-acquirebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueConsumer的releaseBuffer方法用于释放图形缓冲区。 当应用程序使用图形缓冲区进行绘制或渲染操作时，需要从BufferQueueConsumer中获取可用的缓冲区。使用完毕后，可以通过调用releaseBuffer方法将缓冲区释放回给BufferQueueConsumer。 releaseBuffer方法的作用是将指定的缓冲区添加到可用缓冲区队列中，以便其他应用程序或系统可以继续使用该缓冲区进行绘制或渲染操作。释放缓冲区后，应用程序不再拥有该缓冲区的所有权。 BufferQueueConsumer的releaseBuffer方法代码如下： //frameworks/native/lib/gui/BufferQueueConsumer.cpp status_t BufferQueueConsumer::releaseBuffer(int slot, uint64_t frameNumber, const sp\u003cFence\u003e\u0026 releaseFence, EGLDisplay eglDisplay, EGLSyncKHR eglFence) { ATRACE_CALL(); ATRACE_BUFFER_INDEX(slot); if (slot \u003c 0 || slot \u003e= BufferQueueDefs::NUM_BUFFER_SLOTS || releaseFence == nullptr) { BQ_LOGE(\"releaseBuffer: slot %d out of range or fence %p NULL\", slot, releaseFence.get()); return BAD_VALUE; } sp\u003cIProducerListener\u003e listener; { // Autolock scope std::lock_guard\u003cstd::mutex\u003e lock(mCore-\u003emMutex); // If the frame number has changed because the buffer has been reallocated, // we can ignore this releaseBuffer for the old buffer. // Ignore this for the shared buffer where the frame number can easily // get out of sync due to the buffer being queued and acquired at the // same time. if (frameNumber != mSlots[slot].mFrameNumber \u0026\u0026 !mSlots[slot].mBufferState.isShared()) { return STALE_BUFFER_SLOT; } if (!mSlots[slot].mBufferState.isAcquired()) { BQ_LOGE(\"releaseBuffer: attempted to release buffer slot %d \" \"but its state was %s\", slot, mSlots[slot].mBufferState.string()); return BAD_VALUE; } mSlots[slot].mEglDisplay = eglDisplay; mSlots[slot].mEglFence = eglFence; mSlots[slot].mFence = releaseFence; mSlots[slot].mBufferState.release(); // After leaving shared buffer mode, the shared buffer will // still be around. Mark it as no longer shared if this // operation causes it to be free. if (!mCore-\u003emSharedBufferMode \u0026\u0026 mSlots[slot].mBufferState.isFree()) { mSlots[slot].mBufferState.mShared = false; } // Don't put the shared buffer on the free list. if (!mSlots[slot].mBufferState.isShared()) { mCore-\u003emActiveBuffers.erase(slot); mCore-\u003emFreeBuffers.push_back(slot); } if (mCore-\u003emBufferReleasedCbEnabled) { listener = mCore-\u003emConnectedProducerListener; } BQ_LOGV(\"releaseBuffer: releasing slot %d\", slot); mCore-\u003emDequeueCondition.notify_all(); VALIDATE_CONSISTENCY(); } // Autolock scope // Call back without lock held if (listener != nullptr) { listener-\u003eonBufferReleased(); } return NO_ERROR; } ","date":"2024-11-06","objectID":"/posts/android13-bufferqueueconsumer-releasebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueConsumer releaseBuffer流程分析-CSDN博客","uri":"/posts/android13-bufferqueueconsumer-releasebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueLayer是Android系统中的一个图层，用于管理图像缓冲区的队列。它是SurfaceFlinger系统服务的一部分，负责接收应用程序或系统组件提交的图像缓冲区，并将其显示在屏幕上。onFirstRef是BufferQueueLayer类的一个方法，它是在第一次引用BufferQueueLayer对象时被调用的。在这个方法中，可以进行一些初始化操作，例如创建和配置图像缓冲区队列。 在创建BufferQueueLayer同时会创建一套生产者-消费者模型架构，核心是如下几个类： BufferQueueLayer：创建了BufferQueue、MonitoredProducer、BufferLayerConsumer BufferQueue：buffer队列，创建BufferQueueCore，BufferQueueProducer BufferQueueProducer：生产者 BufferQueueConsumer：消费者 MonitoredProducer：生产者的封装 BufferLayerConsumer：消费者的封装 生产者提供图形数据，放入BufferQueue，消费者拿到图形数据进行合成，通常认为生产者为Surface，消费者为SurfaceFlinger，下面我们就分析一下生产者-消费者模型架构的搭建。 BufferQueue 我们以BufferQueueLayer的创建为入口分析： //frameworks/native/services/surfaceflinger/BufferQueueLayer.cpp void BufferQueueLayer::onFirstRef() { BufferLayer::onFirstRef(); sp\u003cIGraphicBufferProducer\u003e producer; sp\u003cIGraphicBufferConsumer\u003e consumer; //步骤1 BufferQueue::createBufferQueue(\u0026producer, \u0026consumer, true); //创建BufferQueue //步骤2 mProducer = new MonitoredProducer(producer, mFlinger, this); //创建一个生产者 { // Grab the SF state lock during this since it's the only safe way to access RenderEngine Mutex::Autolock lock(mFlinger-\u003emStateLock); //步骤3 mConsumer = new BufferLayerConsumer(consumer, mFlinger-\u003egetRenderEngine(), mTextureName, this); //创建一个消费者 { } //步骤4 mConsumer-\u003esetConsumerUsageBits(getEffectiveUsage(0)); //设置缓冲区的类型,会保存到BufferQueueCore中的mConsumerUsageBits变量中 //步骤5 mConsumer-\u003esetContentsChangedListener(this); //设置缓冲区内容改变的监听器 mConsumer-\u003esetName(mName); // BufferQueueCore::mMaxDequeuedBufferCount is default to 1 if (!mFlinger-\u003eisLayerTripleBufferingDisabled()) { mProducer-\u003esetMaxDequeuedBufferCount(2); } if (const auto display = mFlinger-\u003egetDefaultDisplayDevice()) { updateTransformHint(display); } if (mFlinger-\u003emLayerExt) { mLayerType = mFlinger-\u003emLayerExt-\u003egetLayerClass(mName.string()); } } 上面这个函数就是创建SurfaceFlinger生产者-消费者模型的核心代码，我们分步骤分析： BufferQueue createBufferQueue 步骤1：createBufferQueue，从名字看就能知道是创建BufferQueue，并且将生产者producer和消费者consumer的地址传了过去，显然这两个对象也会在createBufferQueue中创建。 //frameworks/native/libs/gui/BufferQueue.cpp void BufferQueue::createBufferQueue(sp\u003cIGraphicBufferProducer\u003e* outProducer, sp\u003cIGraphicBufferConsumer\u003e* outConsumer, bool consumerIsSurfaceFlinger) { sp\u003cBufferQueueCore\u003e core(new BufferQueueCore()); //创建BufferQueueCore sp\u003cIGraphicBufferProducer\u003e producer(new BufferQueueProducer(core, consumerIsSurfaceFlinger)); //创建BufferQueueProducer sp\u003cIGraphicBufferConsumer\u003e consumer(new BufferQueueConsumer(core)); //创建BufferQueueConsumer *outProducer = producer; *outConsumer = consumer; } 可以看到这个函数中并没有创建BufferQueue，而是创建的BufferQueueCore，可见BufferQueue的核心实现其实是依靠BufferQueueCore的，接着又创建了生产者的具体实现类BufferQueueProducer，消费者的具体实现类BufferQueueConsumer，并且这两个类都持有BufferQueueCore的引用，最后outProducer，outConsumer分别指向创建的生产者-消费者，下面分别进行分析： new BufferQueueCore 创建BufferQueueCore对象，BufferQueueCore的构造方法如下： //frameworks/native/libs/gui/BufferQueueCore.cpp class BufferQueueCore : public virtual RefBase { BufferQueueCore::BufferQueueCore() : mMutex(), mIsAbandoned(false), mConsumerControlledByApp(false), mConsumerName(getUniqueName()), mConsumerListener(), mConsumerUsageBits(0), mConsumerIsProtected(false), mConnectedApi(NO_CONNECTED_API), mLinkedToDeath(), mConnectedProducerListener(), mBufferReleasedCbEnabled(false), mSlots(), mQueue(), mFreeSlots(), mFreeBuffers(), mUnusedSlots(), mActiveBuffers(), mDequeueCondition(), mDequeueBufferCannotBlock(false), mQueueBufferCanDrop(false), mLegacyBufferDrop(true), mDefaultBufferFormat(PIXEL_FORMAT_RGBA_8888), mDefaultWidth(1), mDefaultHeight(1), mDefaultBufferDataSpace(HAL_DATASPACE_UNKNOWN), mMaxBufferCount(BufferQueueDefs::NUM_BUFFER_SLOTS), mMaxAcquiredBufferCount(1), mMaxDequeuedBufferCount(1), mBufferHasBeenQueued(false), mFrameCounter(0), mTransformHint(0), mIsAllocating(false), mIsAllocatingCondition(), mAllowAllocation(true), mBufferAge(0), mGenerationNumber(0), mAsyncMode(false), mSharedBufferMode(false), mAutoRefresh(false), mSharedBufferSlot(INVALID_BUFFER_SLOT), mSharedBufferCache(Rect::INVALID_RECT, 0, NATIVE_WINDOW_SCALING_MODE_FR","date":"2024-11-06","objectID":"/posts/android13-bufferqueuelayer-onfirstref%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","转载"],"title":"Android13 BufferQueueLayer onFirstRef流程分析-CSDN博客","uri":"/posts/android13-bufferqueuelayer-onfirstref%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueLayer的onFrameAvailable方法用于通知图像或视频帧已经可用并准备好显示，代码如下： //frameworks/native/services/surfaceflinger/BufferQueueLayer.cpp sp\u003cSurfaceFlinger\u003e mFlinger; sp\u003cBufferLayerConsumer\u003e mConsumer; void BufferQueueLayer::onFrameAvailable(const BufferItem\u0026 item) { const int32_t layerId = getSequence(); const uint64_t bufferId = item.mGraphicBuffer-\u003egetId(); mFlinger-\u003emFrameTracer-\u003etraceTimestamp(layerId, bufferId, item.mFrameNumber, systemTime(), FrameTracer::FrameEvent::QUEUE); mFlinger-\u003emFrameTracer-\u003etraceFence(layerId, bufferId, item.mFrameNumber, std::make_shared\u003cFenceTime\u003e(item.mFence), FrameTracer::FrameEvent::ACQUIRE_FENCE); ATRACE_CALL(); // Add this buffer from our internal queue tracker { // Autolock scope const nsecs_t presentTime = item.mIsAutoTimestamp ? 0 : item.mTimestamp; using LayerUpdateType = scheduler::LayerHistory::LayerUpdateType; mFlinger-\u003emScheduler-\u003erecordLayerHistory(this, presentTime, LayerUpdateType::Buffer); Mutex::Autolock lock(mQueueItemLock); // Reset the frame number tracker when we receive the first buffer after // a frame number reset if (item.mFrameNumber == 1) { mLastFrameNumberReceived = 0; } // Ensure that callbacks are handled in order while (item.mFrameNumber != mLastFrameNumberReceived + 1) { status_t result = mQueueItemCondition.waitRelative(mQueueItemLock, ms2ns(500)); if (result != NO_ERROR) { ALOGE(\"[%s] Timed out waiting on callback\", getDebugName()); break; } } auto surfaceFrame = createSurfaceFrameForBuffer(mFrameTimelineInfo, systemTime(), mName); mQueueItems.push_back({item, surfaceFrame}); mQueuedFrames++; // Wake up any pending callbacks mLastFrameNumberReceived = item.mFrameNumber; mQueueItemCondition.broadcast(); } mFlinger-\u003emInterceptor-\u003esaveBufferUpdate(layerId, item.mGraphicBuffer-\u003egetWidth(), item.mGraphicBuffer-\u003egetHeight(), item.mFrameNumber); mFlinger-\u003eonLayerUpdate(); mConsumer-\u003eonBufferAvailable(item); } 上面方法主要处理如下： 1、调用mFlinger(SurfaceFlinger)内mScheduler(Scheduler)的recordLayerHistory方法。 2、调用Layer的createSurfaceFrameForBuffer方法，创建Layer。 3、调用mFlinger(SurfaceFlinger)内mInterceptor(SurfaceInterceptor)的saveBufferUpdate方法。 4、调用mFlinger(SurfaceFlinger)的onLayerUpdate方法。 5、调用mConsumer(BufferLayerConsumer)的onBufferAvailable方法。 下面分别进行分析： Scheduler recordLayerHistory 调用mFlinger(SurfaceFlinger)内mScheduler(Scheduler)的recordLayerHistory方法： //frameworks/native/services/surfaceflinger/Scheduler/Scheduler.cpp LayerHistory mLayerHistory; void Scheduler::recordLayerHistory(Layer* layer, nsecs_t presentTime, LayerHistory::LayerUpdateType updateType) { { std::scoped_lock lock(mRefreshRateConfigsLock); if (!mRefreshRateConfigs-\u003ecanSwitch()) return; } mLayerHistory.record(layer, presentTime, systemTime(), updateType); } LayerHistory record 调用mLayerHistory(LayerHistory)的record方法： //frameworks/native/services/surfaceflinger/Scheduler/LayerHistory.cpp void LayerHistory::record(Layer* layer, nsecs_t presentTime, nsecs_t now, LayerUpdateType updateType) { std::lock_guard lock(mLock); auto id = layer-\u003egetSequence(); auto [found, layerPair] = findLayer(id); if (found == LayerStatus::NotFound) { // Offscreen layer ALOGV(\"%s: %s not registered\", __func__, layer-\u003egetName().c_str()); return; } const auto\u0026 info = layerPair-\u003esecond; const auto layerProps = LayerInfo::LayerProps{ .visible = layer-\u003eisVisible(), .bounds = layer-\u003egetBounds(), .transform = layer-\u003egetTransform(), .setFrameRateVote = layer-\u003egetFrameRateForLayerTree(), .frameRateSelectionPriority = layer-\u003egetFrameRateSelectionPriority(), }; info-\u003esetLastPresentTime(presentTime, now, updateType, mModeChangePending, layerProps); // Activate layer if inactive. if (found == LayerStatus::LayerInInactiveMap) { mActiveLayerInfos.insert( {id, std::make_pair(layerPair-\u003efirst, std::move(layerPair-\u003esecond))}); mInactiveLayerInfos.erase(id); } } Layer createSurfaceFrameForBuffer 调用Layer的createSurfaceFrameForBuffer方法，创建Layer： //frameworks/native/services/surfaceflinger/Layer.cpp sp\u003cSurfaceFlinger\u003e mFlinger; const std::unique_ptr\u003cframetimeline::FrameTimeline\u003e mFra","date":"2024-11-06","objectID":"/posts/android13-bufferqueuelayer-onframeavailable%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueLayer onFrameAvailable流程分析-CSDN博客","uri":"/posts/android13-bufferqueuelayer-onframeavailable%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueLayer的onLayerDisplayed方法在BufferQueueLayer被显示时调用，代码如下： //frameworks/native/services/surfaceflinger/BufferQueueLayer.cpp sp\u003cSurfaceFlinger\u003e mFlinger; const std::unique_ptr\u003cFrameTracer\u003e mFrameTracer; void BufferQueueLayer::onLayerDisplayed(ftl::SharedFuture\u003cFenceResult\u003e futureFenceResult) { const sp\u003cFence\u003e releaseFence = futureFenceResult.get().value_or(Fence::NO_FENCE); mConsumer-\u003esetReleaseFence(releaseFence); // Prevent tracing the same release multiple times. if (mPreviousFrameNumber != mPreviousReleasedFrameNumber) { mFlinger-\u003emFrameTracer-\u003etraceFence(getSequence(), mPreviousBufferId, mPreviousFrameNumber, std::make_shared\u003cFenceTime\u003e(releaseFence), FrameTracer::FrameEvent::RELEASE_FENCE); mPreviousReleasedFrameNumber = mPreviousFrameNumber; } } FrameTracer traceFence 调用FrameTracer的traceFence方法，用于分析和调试界面渲染的性能问题： //frameworks/native/services/surfaceflinger/FrameTracer/FrameTracer.cpp void FrameTracer::traceFence(int32_t layerId, uint64_t bufferID, uint64_t frameNumber, const std::shared_ptr\u003cFenceTime\u003e\u0026 fence, FrameEvent::BufferEventType type, nsecs_t startTime) { FrameTracerDataSource::Trace([this, layerId, bufferID, frameNumber, \u0026fence, type, startTime](FrameTracerDataSource::TraceContext ctx) { const nsecs_t signalTime = fence-\u003egetSignalTime(); if (signalTime != Fence::SIGNAL_TIME_INVALID) { std::lock_guard\u003cstd::mutex\u003e lock(mTraceMutex); if (mTraceTracker.find(layerId) == mTraceTracker.end()) { return; } // Handle any pending fences for this buffer. tracePendingFencesLocked(ctx, layerId, bufferID); if (signalTime != Fence::SIGNAL_TIME_PENDING) { traceSpanLocked(ctx, layerId, bufferID, frameNumber, type, startTime, signalTime); } else { mTraceTracker[layerId].pendingFences[bufferID].push_back( {.frameNumber = frameNumber, .type = type, .fence = fence, .startTime = startTime}); } } }); } ","date":"2024-11-06","objectID":"/posts/android13-bufferqueuelayer-onlayerdisplayed%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueLayer onLayerDisplayed流程分析-CSDN博客","uri":"/posts/android13-bufferqueuelayer-onlayerdisplayed%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueLayer的updateTexImage方法用于将当前图形缓冲区的内容更新到纹理中，代码如下： //frameworks/native/services/surfaceflinger/BufferQueueLayer.cpp status_t BufferQueueLayer::updateTexImage(bool\u0026 recomputeVisibleRegions, nsecs_t latchTime, nsecs_t expectedPresentTime) { // This boolean is used to make sure that SurfaceFlinger's shadow copy // of the buffer queue isn't modified when the buffer queue is returning // BufferItem's that weren't actually queued. This can happen in shared // buffer mode. bool queuedBuffer = false; const int32_t layerId = getSequence(); LayerRejecter r(mDrawingState, getDrawingState(), recomputeVisibleRegions, getProducerStickyTransform() != 0, mName, getTransformToDisplayInverse()); if (isRemovedFromCurrentState()) { expectedPresentTime = 0; } // updateTexImage() below might drop the some buffers at the head of the queue if there is a // buffer behind them which is timely to be presented. However this buffer may not be signaled // yet. The code below makes sure that this wouldn't happen by setting maxFrameNumber to the // last buffer that was signaled. uint64_t lastSignaledFrameNumber = mLastFrameNumberReceived; { Mutex::Autolock lock(mQueueItemLock); for (size_t i = 0; i \u003c mQueueItems.size(); i++) { bool fenceSignaled = mQueueItems[i].item.mFenceTime-\u003egetSignalTime() != Fence::SIGNAL_TIME_PENDING; if (!fenceSignaled) { break; } lastSignaledFrameNumber = mQueueItems[i].item.mFrameNumber; } } const uint64_t maxFrameNumberToAcquire = std::min(mLastFrameNumberReceived.load(), lastSignaledFrameNumber); bool autoRefresh; status_t updateResult = mConsumer-\u003eupdateTexImage(\u0026r, expectedPresentTime, \u0026autoRefresh, \u0026queuedBuffer, maxFrameNumberToAcquire); mDrawingState.autoRefresh = autoRefresh; if (updateResult == BufferQueue::PRESENT_LATER) { // Producer doesn't want buffer to be displayed yet. Signal a // layer update so we check again at the next opportunity. // Producer 不希望显示缓冲区。 发出图层更新的信号，以便我们在下次有机会时再次检查。 mFlinger-\u003eonLayerUpdate(); // (692) SurfaceFlinger onLayerUpdate流程分析 return BAD_VALUE; } else if (updateResult == BufferLayerConsumer::BUFFER_REJECTED) { // If the buffer has been rejected, remove it from the shadow queue // and return early if (queuedBuffer) { Mutex::Autolock lock(mQueueItemLock); if (mQueuedFrames \u003e 0) { mConsumer-\u003emergeSurfaceDamage(mQueueItems[0].item.mSurfaceDamage); mFlinger-\u003emTimeStats-\u003eremoveTimeRecord(layerId, mQueueItems[0].item.mFrameNumber); if (mQueueItems[0].surfaceFrame) { addSurfaceFrameDroppedForBuffer(mQueueItems[0].surfaceFrame); } mQueueItems.erase(mQueueItems.begin()); mQueuedFrames--; } } return BAD_VALUE; } else if (updateResult != NO_ERROR || mUpdateTexImageFailed) { // This can occur if something goes wrong when trying to create the // EGLImage for this buffer. If this happens, the buffer has already // been released, so we need to clean up the queue and bug out // early. if (queuedBuffer) { Mutex::Autolock lock(mQueueItemLock); for (auto\u0026 [item, surfaceFrame] : mQueueItems) { if (surfaceFrame) { addSurfaceFrameDroppedForBuffer(surfaceFrame); } } mQueueItems.clear(); mQueuedFrames = 0; mFlinger-\u003emTimeStats-\u003eonDestroy(layerId); mFlinger-\u003emFrameTracer-\u003eonDestroy(layerId); } // Once we have hit this state, the shadow queue may no longer // correctly reflect the incoming BufferQueue's contents, so even if // updateTexImage starts working, the only safe course of action is // to continue to ignore updates. mUpdateTexImageFailed = true; return BAD_VALUE; } bool more_frames_pending = false; if (queuedBuffer) { // Autolock scope auto currentFrameNumber = mConsumer-\u003egetFrameNumber(); Mutex::Autolock lock(mQueueItemLock); // Remove any stale buffers that have been dropped during // updateTexImage while (mQueuedFrames \u003e 0 \u0026\u0026 mQueueItems[0].item.mFrameNumber != currentFrameNumber) { mConsumer-\u003emergeSurfaceDamage(mQueueItems[0].item.mSurfaceDamage); mFlinger-\u003emTimeStats-\u003eremoveTimeRecord(layerId, mQueueItems[0].item.mFrameNumber); if (mQueueItems[0].surfaceFrame) { addSurfaceFrameDroppedForBuffer(mQu","date":"2024-11-06","objectID":"/posts/android13-bufferqueuelayer-updateteximage%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueLayer updateTexImage流程分析-CSDN博客","uri":"/posts/android13-bufferqueuelayer-updateteximage%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueProducer的dequeueBuffer方法是Android系统中用于从BufferQueue中获取可用的缓冲区的方法。BufferQueue是一个用于在不同线程之间传递图像数据的队列，它通常用于图像渲染和视频编解码等场景。 dequeueBuffer方法的作用是从BufferQueue中获取一个可用的缓冲区，并返回该缓冲区的索引。如果没有可用的缓冲区，则该方法会阻塞，直到有可用的缓冲区为止。 在调用dequeueBuffer方法之前，需要先通过BufferQueue的getBufferCount方法获取可用缓冲区的数量。然后，通过dequeueBuffer方法获取一个可用的缓冲区，并将其索引作为参数传递给其他相关的方法，如图像渲染或视频编解码等。 代码如下： //frameworks/native/libs/gui/BufferQueueProducer.cpp class BufferQueueProducer : public BnGraphicBufferProducer { status_t BufferQueueProducer::dequeueBuffer(int* outSlot, sp\u003candroid::Fence\u003e* outFence, uint32_t width, uint32_t height, PixelFormat format, uint64_t usage, uint64_t* outBufferAge, FrameEventHistoryDelta* outTimestamps) { ATRACE_CALL(); { // Autolock scope std::lock_guard\u003cstd::mutex\u003e lock(mCore-\u003emMutex); mConsumerName = mCore-\u003emConsumerName; if (mCore-\u003emIsAbandoned) { BQ_LOGE(\"dequeueBuffer: BufferQueue has been abandoned\"); return NO_INIT; } if (mCore-\u003emConnectedApi == BufferQueueCore::NO_CONNECTED_API) { BQ_LOGE(\"dequeueBuffer: BufferQueue has no connected producer\"); return NO_INIT; } } // Autolock scope BQ_LOGV(\"dequeueBuffer: w=%u h=%u format=%#x, usage=%#\" PRIx64, width, height, format, usage); if ((width \u0026\u0026 !height) || (!width \u0026\u0026 height)) { BQ_LOGE(\"dequeueBuffer: invalid size: w=%u h=%u\", width, height); return BAD_VALUE; } status_t returnFlags = NO_ERROR; EGLDisplay eglDisplay = EGL_NO_DISPLAY; EGLSyncKHR eglFence = EGL_NO_SYNC_KHR; bool attachedByConsumer = false; { // Autolock scope std::unique_lock\u003cstd::mutex\u003e lock(mCore-\u003emMutex); // If we don't have a free buffer, but we are currently allocating, we wait until allocation // is finished such that we don't allocate in parallel. if (mCore-\u003emFreeBuffers.empty() \u0026\u0026 mCore-\u003emIsAllocating) { mDequeueWaitingForAllocation = true; mCore-\u003ewaitWhileAllocatingLocked(lock); mDequeueWaitingForAllocation = false; mDequeueWaitingForAllocationCondition.notify_all(); } if (format == 0) { format = mCore-\u003emDefaultBufferFormat; } // Enable the usage bits the consumer requested usage |= mCore-\u003emConsumerUsageBits; const bool useDefaultSize = !width \u0026\u0026 !height; if (useDefaultSize) { width = mCore-\u003emDefaultWidth; height = mCore-\u003emDefaultHeight; if (mCore-\u003emAutoPrerotation \u0026\u0026 (mCore-\u003emTransformHintInUse \u0026 NATIVE_WINDOW_TRANSFORM_ROT_90)) { std::swap(width, height); } } int found = BufferItem::INVALID_BUFFER_SLOT; while (found == BufferItem::INVALID_BUFFER_SLOT) { status_t status = waitForFreeSlotThenRelock(FreeSlotCaller::Dequeue, lock, \u0026found); if (status != NO_ERROR) { return status; } // This should not happen if (found == BufferQueueCore::INVALID_BUFFER_SLOT) { BQ_LOGE(\"dequeueBuffer: no available buffer slots\"); return -EBUSY; } const sp\u003cGraphicBuffer\u003e\u0026 buffer(mSlots[found].mGraphicBuffer); // If we are not allowed to allocate new buffers, // waitForFreeSlotThenRelock must have returned a slot containing a // buffer. If this buffer would require reallocation to meet the // requested attributes, we free it and attempt to get another one. if (!mCore-\u003emAllowAllocation) { if (buffer-\u003eneedsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { //检查是否已分配了GraphicBuffer if (mCore-\u003emSharedBufferSlot == found) { BQ_LOGE(\"dequeueBuffer: cannot re-allocate a sharedbuffer\"); return BAD_VALUE; } mCore-\u003emFreeSlots.insert(found); mCore-\u003eclearBufferSlotLocked(found); found = BufferItem::INVALID_BUFFER_SLOT; continue; } } } const sp\u003cGraphicBuffer\u003e\u0026 buffer(mSlots[found].mGraphicBuffer); if (mCore-\u003emSharedBufferSlot == found \u0026\u0026 buffer-\u003eneedsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { BQ_LOGE(\"dequeueBuffer: cannot re-allocate a shared\" \"buffer\"); return BAD_VALUE; } if (mCore-\u003emSharedBufferSlot != found) { mCore-\u003emActiveBuffers.insert(found); } *outSlot = found; ATRACE_BUFFER_INDEX(found); attachedByConsumer = mSlots[found].mNeedsReallocation; mSlots[found].mNeedsReallocation = false; mSlots[found].mBufferState.dequeue(); if ((buffer == nullptr) || buffer-\u003eneedsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { mSlots","date":"2024-11-06","objectID":"/posts/android13-bufferqueueproducer-dequeuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueProducer dequeueBuffer流程分析-CSDN博客","uri":"/posts/android13-bufferqueueproducer-dequeuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"BufferQueueProducer的queueBuffer方法用于将图形缓冲区添加到队列中。当应用程序完成对图形缓冲区的绘制后，可以调用queueBuffer方法将其提交给SurfaceFlinger进行显示。 //frameworks/native/libs/gui/BufferQueueProducer.cpp class BufferQueueProducer : public BnGraphicBufferProducer { status_t BufferQueueProducer::queueBuffer(int slot, const QueueBufferInput \u0026input, QueueBufferOutput *output) { ATRACE_CALL(); ATRACE_BUFFER_INDEX(slot); int64_t requestedPresentTimestamp; bool isAutoTimestamp; android_dataspace dataSpace; Rect crop(Rect::EMPTY_RECT); int scalingMode; uint32_t transform; uint32_t stickyTransform; sp\u003cFence\u003e acquireFence; bool getFrameTimestamps = false; input.deflate(\u0026requestedPresentTimestamp, \u0026isAutoTimestamp, \u0026dataSpace, \u0026crop, \u0026scalingMode, \u0026transform, \u0026acquireFence, \u0026stickyTransform, \u0026getFrameTimestamps); const Region\u0026 surfaceDamage = input.getSurfaceDamage(); const HdrMetadata\u0026 hdrMetadata = input.getHdrMetadata(); if (acquireFence == nullptr) { BQ_LOGE(\"queueBuffer: fence is NULL\"); return BAD_VALUE; } auto acquireFenceTime = std::make_shared\u003cFenceTime\u003e(acquireFence); switch (scalingMode) { case NATIVE_WINDOW_SCALING_MODE_FREEZE: case NATIVE_WINDOW_SCALING_MODE_SCALE_TO_WINDOW: case NATIVE_WINDOW_SCALING_MODE_SCALE_CROP: case NATIVE_WINDOW_SCALING_MODE_NO_SCALE_CROP: break; default: BQ_LOGE(\"queueBuffer: unknown scaling mode %d\", scalingMode); return BAD_VALUE; } sp\u003cIConsumerListener\u003e frameAvailableListener; sp\u003cIConsumerListener\u003e frameReplacedListener; int callbackTicket = 0; uint64_t currentFrameNumber = 0; BufferItem item; { // Autolock scope std::lock_guard\u003cstd::mutex\u003e lock(mCore-\u003emMutex); if (mCore-\u003emIsAbandoned) { BQ_LOGE(\"queueBuffer: BufferQueue has been abandoned\"); return NO_INIT; } if (mCore-\u003emConnectedApi == BufferQueueCore::NO_CONNECTED_API) { BQ_LOGE(\"queueBuffer: BufferQueue has no connected producer\"); return NO_INIT; } if (slot \u003c 0 || slot \u003e= BufferQueueDefs::NUM_BUFFER_SLOTS) { BQ_LOGE(\"queueBuffer: slot index %d out of range [0, %d)\", slot, BufferQueueDefs::NUM_BUFFER_SLOTS); return BAD_VALUE; } else if (!mSlots[slot].mBufferState.isDequeued()) { BQ_LOGE(\"queueBuffer: slot %d is not owned by the producer \" \"(state = %s)\", slot, mSlots[slot].mBufferState.string()); return BAD_VALUE; } else if (!mSlots[slot].mRequestBufferCalled) { BQ_LOGE(\"queueBuffer: slot %d was queued without requesting \" \"a buffer\", slot); return BAD_VALUE; } // If shared buffer mode has just been enabled, cache the slot of the // first buffer that is queued and mark it as the shared buffer. if (mCore-\u003emSharedBufferMode \u0026\u0026 mCore-\u003emSharedBufferSlot == BufferQueueCore::INVALID_BUFFER_SLOT) { mCore-\u003emSharedBufferSlot = slot; mSlots[slot].mBufferState.mShared = true; } BQ_LOGV(\"queueBuffer: slot=%d/%\" PRIu64 \" time=%\" PRIu64 \" dataSpace=%d\" \" validHdrMetadataTypes=0x%x crop=[%d,%d,%d,%d] transform=%#x scale=%s\", slot, mCore-\u003emFrameCounter + 1, requestedPresentTimestamp, dataSpace, hdrMetadata.validTypes, crop.left, crop.top, crop.right, crop.bottom, transform, BufferItem::scalingModeName(static_cast\u003cuint32_t\u003e(scalingMode))); const sp\u003cGraphicBuffer\u003e\u0026 graphicBuffer(mSlots[slot].mGraphicBuffer); Rect bufferRect(graphicBuffer-\u003egetWidth(), graphicBuffer-\u003egetHeight()); Rect croppedRect(Rect::EMPTY_RECT); crop.intersect(bufferRect, \u0026croppedRect); if (croppedRect != crop) { BQ_LOGE(\"queueBuffer: crop rect is not contained within the \" \"buffer in slot %d\", slot); return BAD_VALUE; } // Override UNKNOWN dataspace with consumer default if (dataSpace == HAL_DATASPACE_UNKNOWN) { dataSpace = mCore-\u003emDefaultBufferDataSpace; } mSlots[slot].mFence = acquireFence; mSlots[slot].mBufferState.queue(); // Increment the frame counter and store a local version of it // for use outside the lock on mCore-\u003emMutex. ++mCore-\u003emFrameCounter; currentFrameNumber = mCore-\u003emFrameCounter; mSlots[slot].mFrameNumber = currentFrameNumber; item.mAcquireCalled = mSlots[slot].mAcquireCalled; item.mGraphicBuffer = mSlots[slot].mGraphicBuffer; item.mCrop = crop; item.mTransform = transform \u0026 ~static_cast\u003cuint32_t\u003e(NATIVE_WINDOW_T","date":"2024-11-06","objectID":"/posts/android13-bufferqueueproducer-queuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 BufferQueueProducer queueBuffer流程分析-CSDN博客","uri":"/posts/android13-bufferqueueproducer-queuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Choreographer的postCallback()方法用于将一个任务添加到Choreographer的任务队列中，以便在下一帧绘制之前执行，代码如下： //frameworks/base/core/java/android/view/Choreographer.java public final class Choreographer { public void postCallback(int callbackType, Runnable action, Object token) { postCallbackDelayed(callbackType, action, token, 0); } } 调用Choreographer的postCallbackDelayed方法： //frameworks/base/core/java/android/view/Choreographer.java public final class Choreographer { public void postCallbackDelayed(int callbackType, Runnable action, Object token, long delayMillis) { if (action == null) { throw new IllegalArgumentException(\"action must not be null\"); } if (callbackType \u003c 0 || callbackType \u003e CALLBACK_LAST) { throw new IllegalArgumentException(\"callbackType is invalid\"); } postCallbackDelayedInternal(callbackType, action, token, delayMillis); } } 调用Choreographer的postCallbackDelayedInternal方法： //frameworks/base/core/java/android/view/Choreographer.java public final class Choreographer { private void postCallbackDelayedInternal(int callbackType, Object action, Object token, long delayMillis) { if (DEBUG_FRAMES) { Log.d(TAG, \"PostCallback: type=\" + callbackType + \", action=\" + action + \", token=\" + token + \", delayMillis=\" + delayMillis); } synchronized (mLock) { //添加类型为callbackType的CallbackQueue（将要执行的回调封装而成） final long now = SystemClock.uptimeMillis(); final long dueTime = now + delayMillis; mCallbackQueues[callbackType].addCallbackLocked(dueTime, action, token); if (dueTime \u003c= now) { //立即执行 scheduleFrameLocked(now); } else { //异步回调延迟执行 Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_CALLBACK, action); msg.arg1 = callbackType; msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, dueTime); } } } } 调用Choreographer的scheduleFrameLocked方法： //frameworks/base/core/java/android/view/Choreographer.java public final class Choreographer { private void scheduleFrameLocked(long now) { if (!mFrameScheduled) { mFrameScheduled = true; if (USE_VSYNC) { if (DEBUG_FRAMES) { Log.d(TAG, \"Scheduling next frame on vsync.\"); } // If running on the Looper thread, then schedule the vsync immediately, // otherwise post a message to schedule the vsync from the UI thread // as soon as possible. //检测当前的Looper线程是不是主线程 if (isRunningOnLooperThreadLocked()) { //当运行在Looper线程，则立刻调度vsync scheduleVsyncLocked(); } else { //切换到主线程，调度vsync Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_VSYNC); msg.setAsynchronous(true); mHandler.sendMessageAtFrontOfQueue(msg); } } else { //如果没有VSYNC的同步，则发送消息刷新画面 final long nextFrameTime = Math.max( mLastFrameTimeNanos / TimeUtils.NANOS_PER_MS + sFrameDelay, now); if (DEBUG_FRAMES) { Log.d(TAG, \"Scheduling next frame in \" + (nextFrameTime - now) + \" ms.\"); } Message msg = mHandler.obtainMessage(MSG_DO_FRAME); msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, nextFrameTime); } } } } 调用Choreographer的scheduleVsyncLocked方法： //frameworks/base/core/java/android/view/Choreographer.java public final class Choreographer { private final FrameDisplayEventReceiver mDisplayEventReceiver; private void scheduleVsyncLocked() { try { Trace.traceBegin(Trace.TRACE_TAG_VIEW, \"Choreographer#scheduleVsyncLocked\"); mDisplayEventReceiver.scheduleVsync(); } finally { Trace.traceEnd(Trace.TRACE_TAG_VIEW); } } } DisplayEventReceiver scheduleVsync 调用mDisplayEventReceiver(FrameDisplayEventReceiver)的scheduleVsync方法，FrameDisplayEventReceiver继承DisplayEventReceiver，实际调用DisplayEventReceiver的scheduleVsync方法： //frameworks/base/core/java/android/view/DisplayEventReceiver.java public abstract class DisplayEventReceiver { public void scheduleVsync() { if (mReceiverPtr == 0) { Log.w(TAG, \"Attempted to schedule a vertical sync pulse but the display event \" + \"receiver has already been disposed.\"); } else { nativeScheduleVsync(mReceiverPtr); } } } nativeScheduleVsync 调用nativeScheduleVsync方法，nativeScheduleVsync是一个native方法，在android_view_DisplayEventReceiver.cpp中实现： //frameworks/base/core/jni/android_view_DisplayEventReceiver.cpp static void nativeScheduleVsync(JNIEnv* env, jclass clazz, ","date":"2024-11-06","objectID":"/posts/android13-choreographer-postcallback%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 Choreographer postCallback流程分析_choreographer.postcallback-CSDN博客","uri":"/posts/android13-choreographer-postcallback%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"EventThread的threadMain方法无限循环处理pendingEvents,对Vsync类型的Event分发到消费者，通过往消费者的FD写数据，通知APP有Vsync信号到来。pendingEvents中的消息处理完了，分发线程等待mCondition的通知，EventThread的threadMain方法代码如下： //frameworks/native/services/surfaceflinger/Scheduler/EventThread.cpp std::vector\u003cDisplayEventReceiver::Event\u003e mPendingEvents; void EventThread::threadMain(std::unique_lock\u003cstd::mutex\u003e\u0026 lock) { // consumers 表示即将消费事件的 connection 集合 DisplayEventConsumers consumers; // 状态值不等于 State::Quit 则一直循环遍历，死循环 while (mState != State::Quit) { std::optional\u003cDisplayEventReceiver::Event\u003e event; // Determine next event to dispatch. // 确定下一个要调度的 Event if (!mPendingEvents.empty()) { event = mPendingEvents.front(); // 获取头部 Event mPendingEvents.pop_front(); // 将头部 Event 弹出 switch (event-\u003eheader.type) { // 根据 Event 类型分别对应处理 case DisplayEventReceiver::DISPLAY_EVENT_HOTPLUG: //Event类型为DISPLAY_EVENT_HOTPLUG，即当显示设备（如显示器）被插入或拔出时产生 if (event-\u003ehotplug.connected \u0026\u0026 !mVSyncState) { mVSyncState.emplace(event-\u003eheader.displayId); } else if (!event-\u003ehotplug.connected \u0026\u0026 mVSyncState \u0026\u0026 mVSyncState-\u003edisplayId == event-\u003eheader.displayId) { mVSyncState.reset(); } break; case DisplayEventReceiver::DISPLAY_EVENT_VSYNC: //Event类型为DISPLAY_EVENT_VSYNC，即Vsync（ 垂直同步）事件 if (mInterceptVSyncsCallback) { mInterceptVSyncsCallback(event-\u003eheader.timestamp); } break; } } // 标志位：是否有 VSync 请求，默认 false bool vsyncRequested = false; // Find connections that should consume this event. // 循环遍历存储 EventThreadConnection 的 vector 容器 mDisplayEventConnections，查找要消费事件的连接 // begin()函数用于返回指向向量容器的第一个元素的迭代器 auto it = mDisplayEventConnections.begin(); while (it != mDisplayEventConnections.end()) { if (const auto connection = it-\u003epromote()) { // promote 下面引用有介绍 // 如果有一个 connection 的 vsyncRequest 不为 None 则 vsyncRequested 为 true vsyncRequested |= connection-\u003evsyncRequest != VSyncRequest::None; // event 不为空且 shouldConsumeEvent() 返回 true 则将 connection 加入到 consumers 等待消费 event // shouldConsumeEvent() 方法作用：对于 VSync 类型的事件，只要 VSyncRequest 的类型不是 None 就返回 true if (event \u0026\u0026 shouldConsumeEvent(*event, connection)) { consumers.push_back(connection); } ++it; } else { // 获取不到 connection 则从 mDisplayEventConnections 移除 it = mDisplayEventConnections.erase(it); } } // consumers 不为空即当前 Event 有 EventThreadConnection 来消费 if (!consumers.empty()) { dispatchEvent(*event, consumers); // 分发完清空 consumers.clear(); } State nextState; if (mVSyncState \u0026\u0026 vsyncRequested) { // 有 VSync 请求 // 调用 dispatchEvent() 方法遍历 consumers 为其每个 EventThreadConnection 分发事件 nextState = mVSyncState-\u003esynthetic ? State::SyntheticVSync : State::VSync; } else { ALOGW_IF(!mVSyncState, \"Ignoring VSYNC request while display is disconnected\"); // 显示器熄屏或没有连接、忽略 VSync 请求 nextState = State::Idle; } // mState 值默认为 State::Idle，与 nextState 不一致，则分情况讨论 if (mState != nextState) { if (mState == State::VSync) { // 当前状态为 State::VSync，则调用 mVSyncSource 的 setVSyncEnabled 并传入 false mVSyncSource-\u003esetVSyncEnabled(false); } else if (nextState == State::VSync) { // nextState 状态为 State::VSync，则调用 mVSyncSource 的 setVSyncEnabled 并传入 true mVSyncSource-\u003esetVSyncEnabled(true); } mState = nextState; } if (event) { // 还有事件则继续循环遍历 continue; } // Wait for event or client registration/request. // 没有事件且当前状态为：State::Idle，则线程继续等待事件或客户端注册/请求 if (mState == State::Idle) { mCondition.wait(lock); } else { // Generate a fake VSYNC after a long timeout in case the driver stalls. When the // display is off, keep feeding clients at 60 Hz. const std::chrono::nanoseconds timeout = mState == State::SyntheticVSync ? 16ms : 1000ms; if (mCondition.wait_for(lock, timeout) == std::cv_status::timeout) { if (mState == State::VSync) { ALOGW(\"Faking VSYNC due to driver stall for thread %s\", mThreadName); std::string debugInfo = \"VsyncSource debug info:\\n\"; mVSyncSource-\u003edump(debugInfo); // Log the debug info line-by-line to avoid logcat overflow auto pos = debugInfo.find('\\n'); while (pos != std::string::npos) { ALOGW(\"%s\", debugInfo.substr(0, pos).c_str()); debugInfo = debugInfo.substr(pos + 1); pos = debugInfo.find('\\n'); } } LOG_FATAL_IF(!mVSyncState","date":"2024-11-06","objectID":"/posts/android13-eventthread-threadmain%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 EventThread threadMain流程分析_eventthread::threadmain-CSDN博客","uri":"/posts/android13-eventthread-threadmain%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Surface::dequeueBuffer是Android系统中Surface类的一个方法，用于从Surface中获取一个可用的Buffer。它通常在图形渲染或视频播放等场景中使用。 Surface::dequeueBuffer的调用地方可以有多个，具体取决于应用程序的实现和使用场景。以下是一些可能的调用地方： 图形渲染引擎：在图形渲染引擎中，Surface::dequeueBuffer通常用于获取一个可用的绘制缓冲区，以便进行图形绘制操作。这样可以实现流畅的图形渲染效果。 视频播放器：在视频播放器中，Surface::dequeueBuffer可以用于获取一个可用的视频帧缓冲区，以便将视频数据解码并显示在屏幕上。这样可以实现流畅的视频播放效果。 图像处理应用：在图像处理应用中，Surface::dequeueBuffer可以用于获取一个可用的图像缓冲区，以便进行图像处理操作，如滤镜、特效等。这样可以实现实时的图像处理效果。 游戏引擎：在游戏引擎中，Surface::dequeueBuffer可以用于获取一个可用的游戏画面缓冲区，以便进行游戏画面的渲染和更新。这样可以实现流畅的游戏画面效果。 Surface的dequeueBuffer方法的作用是应用程序一端请求绘制图像时，向BufferQueue中申请一块可用的GraphicBuffer，有了这个buffer就可以绘制图像数据了，生产者在生成内容的时候，就会有这么一个过程； 生产者向 BufferQueue 中申请 slot（缓冲槽） 生产者拿到 slot，但是 slot 并没有关联对应的 GraphicBuffer（缓冲区） 生产者创建一个缓冲区，并将它与缓冲槽相关联。 下面从代码角度进行分析： //framework/native/libs/gui/Surface.cpp sp\u003cIGraphicBufferProducer\u003e mGraphicBufferProducer; class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { int Surface::dequeueBuffer(android_native_buffer_t** buffer, int* fenceFd) { ATRACE_CALL(); ALOGV(\"Surface::dequeueBuffer\"); IGraphicBufferProducer::DequeueBufferInput dqInput; { Mutex::Autolock lock(mMutex); if (mReportRemovedBuffers) { mRemovedBuffers.clear(); } getDequeueBufferInputLocked(\u0026dqInput); if (mSharedBufferMode \u0026\u0026 mAutoRefresh \u0026\u0026 mSharedBufferSlot != BufferItem::INVALID_BUFFER_SLOT) { sp\u003cGraphicBuffer\u003e\u0026 gbuf(mSlots[mSharedBufferSlot].buffer); if (gbuf != nullptr) { *buffer = gbuf.get(); *fenceFd = -1; return OK; } } } // Drop the lock so that we can still touch the Surface while blocking in IGBP::dequeueBuffer int buf = -1; sp\u003cFence\u003e fence; nsecs_t startTime = systemTime(); FrameEventHistoryDelta frameTimestamps; //这里尝试去dequeueBuffer,因为这时SurfaceFlinger对应Layer的slot还没有分配buffer,这时SurfaceFlinger会回复的flag会有BUFFER_NEEDS_REALLOCATIO status_t result = mGraphicBufferProducer-\u003edequeueBuffer(\u0026buf, \u0026fence, dqInput.width, dqInput.height, dqInput.format, dqInput.usage, \u0026mBufferAge, dqInput.getTimestamps ? \u0026frameTimestamps : nullptr); mLastDequeueDuration = systemTime() - startTime; if (result \u003c 0) { ALOGV(\"dequeueBuffer: IGraphicBufferProducer::dequeueBuffer\" \"(%d, %d, %d, %#\" PRIx64 \") failed: %d\", dqInput.width, dqInput.height, dqInput.format, dqInput.usage, result); return result; } if (buf \u003c 0 || buf \u003e= NUM_BUFFER_SLOTS) { ALOGE(\"dequeueBuffer: IGraphicBufferProducer returned invalid slot number %d\", buf); android_errorWriteLog(0x534e4554, \"36991414\"); // SafetyNet logging return FAILED_TRANSACTION; } Mutex::Autolock lock(mMutex); // Write this while holding the mutex mLastDequeueStartTime = startTime; sp\u003cGraphicBuffer\u003e\u0026 gbuf(mSlots[buf].buffer); // this should never happen ALOGE_IF(fence == nullptr, \"Surface::dequeueBuffer: received null Fence! buf=%d\", buf); if (CC_UNLIKELY(atrace_is_tag_enabled(ATRACE_TAG_GRAPHICS))) { static FenceMonitor hwcReleaseThread(\"HWC release\"); hwcReleaseThread.queueFence(fence); } if (result \u0026 IGraphicBufferProducer::RELEASE_ALL_BUFFERS) { freeAllBuffers(); } if (dqInput.getTimestamps) { mFrameEventHistory-\u003eapplyDelta(frameTimestamps); } if ((result \u0026 IGraphicBufferProducer::BUFFER_NEEDS_REALLOCATION) || gbuf == nullptr) { if (mReportRemovedBuffers \u0026\u0026 (gbuf != nullptr)) { mRemovedBuffers.push_back(gbuf); } //这里检查到dequeueBuffer返回的结果里带有BUFFER_NEEDS_REALLOCATION标志就会发出一次requestBuffer result = mGraphicBufferProducer-\u003erequestBuffer(buf, \u0026gbuf); if (result != NO_ERROR) { ALOGE(\"dequeueBuffer: IGraphicBufferProducer::requestBuffer failed: %d\", result); mGraphicBufferProducer-\u003ecancelBuffer(buf, fence); return result; } } if (fence-\u003eisValid()) { *fenceFd = fence-\u003edup(); if (*fenceFd == -1) { ALOGE(\"dequeueBuffer: error duping fence: %d\", errno); // dup() should never fail; something is badly wrong. Soldier on // and hope for the best; the worst that should happen is some // visible corruption that lasts until the next frame. } } else { *fenceFd = -1; } *buffer = gbuf.get(); if (mSharedBufferMode \u0026\u0026 mAutoRefresh) { mSharedBufferSlot = buf; mSharedBufferHasBeenQueued = false; } else if (mSharedBufferSlot == buf) { mSha","date":"2024-11-06","objectID":"/posts/android13-surface-dequeuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 Surface dequeueBuffer流程分析-CSDN博客","uri":"/posts/android13-surface-dequeuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Surface的lockCanvas用于获取Canvas对象，以便进行绘图操作，代码如下： //frameworks/base/core/java/android/view/Surface.java public class Surface implements Parcelable { public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { checkNotReleasedLocked(); if (mLockedObject != 0) { // Ideally, nativeLockCanvas() would throw in this situation and prevent the // double-lock, but that won't happen if mNativeObject was updated. We can't // abandon the old mLockedObject because it might still be in use, so instead // we just refuse to re-lock the Surface. throw new IllegalArgumentException(\"Surface was already locked\"); } mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } } 调用nativeLockCanvas方法，nativeLockCanvas是一个Native方法在android_view_Surface.cpp中实现： //frameworks/base/core/jni/android_view_Surface.cpp static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u003cSurface\u003e surface(reinterpret_cast\u003cSurface *\u003e(nativeObject)); if (!isSurfaceValid(surface)) { jniThrowException(env, IllegalArgumentException, NULL); return 0; } if (!ACanvas_isSupportedPixelFormat(ANativeWindow_getFormat(surface.get()))) { native_window_set_buffers_format(surface.get(), PIXEL_FORMAT_RGBA_8888); } Rect dirtyRect(Rect::EMPTY_RECT); Rect* dirtyRectPtr = NULL; if (dirtyRectObj) { dirtyRect.left = env-\u003eGetIntField(dirtyRectObj, gRectClassInfo.left); dirtyRect.top = env-\u003eGetIntField(dirtyRectObj, gRectClassInfo.top); dirtyRect.right = env-\u003eGetIntField(dirtyRectObj, gRectClassInfo.right); dirtyRect.bottom = env-\u003eGetIntField(dirtyRectObj, gRectClassInfo.bottom); dirtyRectPtr = \u0026dirtyRect; } ANativeWindow_Buffer buffer; status_t err = surface-\u003elock(\u0026buffer, dirtyRectPtr); if (err \u003c 0) { const char* const exception = (err == NO_MEMORY) ? OutOfResourcesException : IllegalArgumentException; jniThrowException(env, exception, NULL); return 0; } graphics::Canvas canvas(env, canvasObj); canvas.setBuffer(\u0026buffer, static_cast\u003cint32_t\u003e(surface-\u003egetBuffersDataSpace())); if (dirtyRectPtr) { canvas.clipRect({dirtyRect.left, dirtyRect.top, dirtyRect.right, dirtyRect.bottom}); } if (dirtyRectObj) { env-\u003eSetIntField(dirtyRectObj, gRectClassInfo.left, dirtyRect.left); env-\u003eSetIntField(dirtyRectObj, gRectClassInfo.top, dirtyRect.top); env-\u003eSetIntField(dirtyRectObj, gRectClassInfo.right, dirtyRect.right); env-\u003eSetIntField(dirtyRectObj, gRectClassInfo.bottom, dirtyRect.bottom); } // Create another reference to the surface and return it. This reference // should be passed to nativeUnlockCanvasAndPost in place of mNativeObject, // because the latter could be replaced while the surface is locked. sp\u003cSurface\u003e lockedSurface(surface); lockedSurface-\u003eincStrong(\u0026sRefBaseOwner); return (jlong) lockedSurface.get(); } 调用surface(Surface)的lock方法： //framework/native/libs/gui/Surface.cpp class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { status_t Surface::lock( ANativeWindow_Buffer* outBuffer, ARect* inOutDirtyBounds) { if (mLockedBuffer != nullptr) { ALOGE(\"Surface::lock failed, already locked\"); return INVALID_OPERATION; } if (!mConnectedToCpu) { int err = Surface::connect(NATIVE_WINDOW_API_CPU); if (err) { return err; } // we're intending to do software rendering from this point setUsage(GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN); } ANativeWindowBuffer* out; int fenceFd = -1; status_t err = dequeueBuffer(\u0026out, \u0026fenceFd); ALOGE_IF(err, \"dequeueBuffer failed (%s)\", strerror(-err)); if (err == NO_ERROR) { sp\u003cGraphicBuffer\u003e backBuffer(GraphicBuffer::getSelf(out)); const Rect bounds(backBuffer-\u003ewidth, backBuffer-\u003eheight); Region newDirtyRegion; if (inOutDirtyBounds) { newDirtyRegion.set(static_cast\u003cRect const\u0026\u003e(*inOutDirtyBounds)); newDirtyRegion.andSelf(bounds); } else { newDirtyRegion.set(bounds); } // figure out if we can copy the frontbuffer back const sp\u003cGraphicBuffer\u003e\u0026 frontBuffer(mPostedBuffer); const bool canC","date":"2024-11-06","objectID":"/posts/android13-surface-lockcanvas%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 Surface lockCanvas流程分析-CSDN博客","uri":"/posts/android13-surface-lockcanvas%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Surface::queueBuffer是Android系统中Surface类的一个成员函数，用于将图像数据放入Surface的缓冲区中。它的调用地方主要包括以下几个： 应用程序：应用程序可以通过Surface对象的queueBuffer函数将图像数据发送给SurfaceFlinger服务。这样，SurfaceFlinger就可以将图像数据进行合成和显示。 SurfaceFlinger服务：SurfaceFlinger是Android系统中负责显示合成的服务。它会定期地从各个应用程序的Surface中获取图像数据，并进行合成和渲染。在合成过程中，SurfaceFlinger会调用Surface的queueBuffer函数将合成后的图像数据放入Surface的缓冲区中。 Hardware Composer：在一些支持硬件加速的设备上，SurfaceFlinger会将合成后的图像数据交给Hardware Composer来进行最终的渲染和显示。在这个过程中，Hardware Composer也会调用Surface的queueBuffer函数将图像数据放入硬件缓冲区中。 当对GraphicBuffer的绘制操作完成之后就需要调用queueBuffer函数将这块buffer放入BufferQueue队列中并通过回调通知消费者使用这块buffer，queueBuffer方法代码如下： //framework/native/libs/gui/Surface.cpp sp\u003cIGraphicBufferProducer\u003e mGraphicBufferProducer; class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { int Surface::queueBuffer(android_native_buffer_t* buffer, int fenceFd) { ATRACE_CALL(); ALOGV(\"Surface::queueBuffer\"); Mutex::Autolock lock(mMutex); int i = getSlotFromBufferLocked(buffer); //找到buffer在mSlots中的下标 if (i \u003c 0) { if (fenceFd \u003e= 0) { close(fenceFd); } return i; } if (mSharedBufferSlot == i \u0026\u0026 mSharedBufferHasBeenQueued) { if (fenceFd \u003e= 0) { close(fenceFd); } return OK; } IGraphicBufferProducer::QueueBufferOutput output; IGraphicBufferProducer::QueueBufferInput input; getQueueBufferInputLocked(buffer, fenceFd, mTimestamp, \u0026input); applyGrallocMetadataLocked(buffer, input); sp\u003cFence\u003e fence = input.fence; nsecs_t now = systemTime(); status_t err = mGraphicBufferProducer-\u003equeueBuffer(i, input, \u0026output); mLastQueueDuration = systemTime() - now; if (err != OK) { ALOGE(\"queueBuffer: error queuing buffer, %d\", err); } onBufferQueuedLocked(i, fence, output); return err; } } BpGraphicBufferProducer queueBuffer 调用mGraphicBufferProducer(IGraphicBufferProducer)的queueBuffer方法，IGraphicBufferProducer是一个接口，由BpGraphicBufferProducer实现： //frameworks/native/libs/gui/IGraphicBufferProducer.cpp class BpGraphicBufferProducer : public BpInterface\u003cIGraphicBufferProducer\u003e { virtual status_t queueBuffer(int buf, const QueueBufferInput\u0026 input, QueueBufferOutput* output) { Parcel data, reply; data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor()); data.writeInt32(buf); data.write(input); status_t result = remote()-\u003etransact(QUEUE_BUFFER, data, \u0026reply); if (result != NO_ERROR) { return result; } result = reply.read(*output); if (result != NO_ERROR) { return result; } result = reply.readInt32(); return result; } } 发送QUEUE_BUFFER消息，发送的消息在BnGraphicBufferProducer的onTransact方法中处理： //frameworks/native/libs/gui/IGraphicBufferProducer.cpp status_t BnGraphicBufferProducer::onTransact( uint32_t code, const Parcel\u0026 data, Parcel* reply, uint32_t flags) { switch(code) { case QUEUE_BUFFER: { CHECK_INTERFACE(IGraphicBufferProducer, data, reply); int buf = data.readInt32(); QueueBufferInput input(data); QueueBufferOutput output; status_t result = queueBuffer(buf, input, \u0026output); reply-\u003ewrite(output); reply-\u003ewriteInt32(result); return NO_ERROR; } } } BufferQueueProducer queueBuffer 调用BnGraphicBufferProducer的queueBuffer方法，BnGraphicBufferProducer继承于BufferQueueProducer，调用BufferQueueProducer的queueBuffer方法，将图形缓冲区添加到队列中。当应用程序完成对图形缓冲区的绘制后，可以调用queueBuffer方法将其提交给SurfaceFlinger进行显示。 Android13 BufferQueueProducer queueBuffer流程分析-CSDN博客 ","date":"2024-11-06","objectID":"/posts/android13-surface-queuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","转载"],"title":"Android13 Surface queueBuffer流程分析_surface::queuebuffer-CSDN博客","uri":"/posts/android13-surface-queuebuffer%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Surface的unlockCanvasAndPost用于解锁并提交Surface上的画布内容，代码如下： //frameworks/base/core/java/android/view/Surface.java public class Surface implements Parcelable { public void unlockCanvasAndPost(Canvas canvas) { synchronized (mLock) { checkNotReleasedLocked(); if (mHwuiContext != null) { mHwuiContext.unlockAndPost(canvas); } else { unlockSwCanvasAndPost(canvas); } } } } 调用Surface的unlockSwCanvasAndPost方法： //frameworks/base/core/java/android/view/Surface.java public class Surface implements Parcelable { private void unlockSwCanvasAndPost(Canvas canvas) { if (canvas != mCanvas) { throw new IllegalArgumentException(\"canvas object must be the same instance that \" + \"was previously returned by lockCanvas\"); } if (mNativeObject != mLockedObject) { Log.w(TAG, \"WARNING: Surface's mNativeObject (0x\" + Long.toHexString(mNativeObject) + \") != mLockedObject (0x\" + Long.toHexString(mLockedObject) +\")\"); } if (mLockedObject == 0) { throw new IllegalStateException(\"Surface was not locked\"); } try { nativeUnlockCanvasAndPost(mLockedObject, canvas); } finally { nativeRelease(mLockedObject); mLockedObject = 0; } } } 调用nativeUnlockCanvasAndPost方法，nativeLockCanvas是一个Native方法在android_view_Surface.cpp中实现： //frameworks/base/core/jni/android_view_Surface.cpp static void nativeUnlockCanvasAndPost(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj) { sp\u003cSurface\u003e surface(reinterpret_cast\u003cSurface *\u003e(nativeObject)); if (!isSurfaceValid(surface)) { return; } // detach the canvas from the surface graphics::Canvas canvas(env, canvasObj); canvas.setBuffer(nullptr, ADATASPACE_UNKNOWN); // unlock surface status_t err = surface-\u003eunlockAndPost(); if (err \u003c 0) { jniThrowException(env, IllegalArgumentException, NULL); } } 调用surface(Surface)的unlockAndPost方法： //framework/native/libs/gui/Surface.cpp class Surface : public ANativeObjectBase\u003cANativeWindow, Surface, RefBase\u003e { status_t Surface::unlockAndPost() { if (mLockedBuffer == nullptr) { ALOGE(\"Surface::unlockAndPost failed, no locked buffer\"); return INVALID_OPERATION; } int fd = -1; status_t err = mLockedBuffer-\u003eunlockAsync(\u0026fd); ALOGE_IF(err, \"failed unlocking buffer (%p)\", mLockedBuffer-\u003ehandle); err = queueBuffer(mLockedBuffer.get(), fd); ALOGE_IF(err, \"queueBuffer (handle=%p) failed (%s)\", mLockedBuffer-\u003ehandle, strerror(-err)); mPostedBuffer = mLockedBuffer; mLockedBuffer = nullptr; return err; } } Surface queueBuffer 调用Surface的queueBuffer方法，将图像数据放入Surface的缓冲区中： Android13 Surface queueBuffer流程分析-CSDN博客 ","date":"2024-11-06","objectID":"/posts/android13-surface-unlockcanvasandpost%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 Surface unlockCanvasAndPost流程分析-CSDN博客","uri":"/posts/android13-surface-unlockcanvasandpost%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"SurfaceFlinger的commit方法用于将应用程序的绘制结果提交到屏幕上显示。 主要就是处理app端发起的一系列transaction的事务请求，需要对这些请求进行识别是否当前帧处理，处理过程就是把事务中的属性取出，然后更新到Layer中，偶尔buffer更新的还需要进行相关的latchbuffer操作，SurfaceFlinger的commit代码如下： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp bool SurfaceFlinger::commit(nsecs_t frameTime, int64_t vsyncId, nsecs_t expectedVsyncTime) //这里frameTime代表当前时间，expectedVsyncTime代表硬件vsync时间，即屏幕先的vsync时间 FTL_FAKE_GUARD(kMainThreadContext) { // we set this once at the beginning of commit to ensure consistency throughout the whole frame mPowerHintSessionData.sessionEnabled = mPowerAdvisor-\u003eusePowerHintSession(); if (mPowerHintSessionData.sessionEnabled) { mPowerHintSessionData.commitStart = systemTime(); } // calculate the expected present time once and use the cached // value throughout this frame to make sure all layers are // seeing this same value. if (expectedVsyncTime \u003e= frameTime) { mExpectedPresentTime = expectedVsyncTime; } else { const DisplayStatInfo stats = mScheduler-\u003egetDisplayStatInfo(frameTime); mExpectedPresentTime = calculateExpectedPresentTime(stats); } const nsecs_t lastScheduledPresentTime = mScheduledPresentTime; mScheduledPresentTime = expectedVsyncTime; if (mPowerHintSessionData.sessionEnabled) { mPowerAdvisor-\u003esetTargetWorkDuration(mExpectedPresentTime - mPowerHintSessionData.commitStart); } const auto vsyncIn = [\u0026] { if (!ATRACE_ENABLED()) return 0.f; return (mExpectedPresentTime - systemTime()) / 1e6f; }(); ATRACE_FORMAT(\"%s %\" PRId64 \" vsyncIn %.2fms%s\", __func__, vsyncId, vsyncIn, mExpectedPresentTime == expectedVsyncTime ? \"\" : \" (adjusted)\"); // When Backpressure propagation is enabled we want to give a small grace period // for the present fence to fire instead of just giving up on this frame to handle cases // where present fence is just about to get signaled. const int graceTimeForPresentFenceMs = (mPropagateBackpressureClientComposition || !mHadClientComposition) ? 1 : 0; // Pending frames may trigger backpressure propagation. const TracedOrdinal\u003cbool\u003e framePending = {\"PrevFramePending\", previousFramePending(graceTimeForPresentFenceMs)}; // Frame missed counts for metrics tracking. // A frame is missed if the prior frame is still pending. If no longer pending, // then we still count the frame as missed if the predicted present time // was further in the past than when the fence actually fired. // Add some slop to correct for drift. This should generally be // smaller than a typical frame duration, but should not be so small // that it reports reasonable drift as a missed frame. const DisplayStatInfo stats = mScheduler-\u003egetDisplayStatInfo(systemTime()); const nsecs_t frameMissedSlop = stats.vsyncPeriod / 2; const nsecs_t previousPresentTime = previousFramePresentTime(); const TracedOrdinal\u003cbool\u003e frameMissed = {\"PrevFrameMissed\", framePending || (previousPresentTime \u003e= 0 \u0026\u0026 (lastScheduledPresentTime \u003c previousPresentTime - frameMissedSlop))}; const TracedOrdinal\u003cbool\u003e hwcFrameMissed = {\"PrevHwcFrameMissed\", mHadDeviceComposition \u0026\u0026 frameMissed}; const TracedOrdinal\u003cbool\u003e gpuFrameMissed = {\"PrevGpuFrameMissed\", mHadClientComposition \u0026\u0026 frameMissed}; if (frameMissed) { mFrameMissedCount++; mTimeStats-\u003eincrementMissedFrames(); } if (hwcFrameMissed) { mHwcFrameMissedCount++; } if (gpuFrameMissed) { mGpuFrameMissedCount++; } // If we are in the middle of a mode change and the fence hasn't // fired yet just wait for the next commit. // 如果我们正处于模式更改的过程中，并且围栏尚未触发，请等待下一次提交。 if (mSetActiveModePending) { if (framePending) { mScheduler-\u003escheduleFrame(); return false; } // We received the present fence from the HWC, so we assume it successfully updated // the mode, hence we update SF. mSetActiveModePending = false; { Mutex::Autolock lock(mStateLock); updateInternalStateWithChangedMode(); } } if (framePending) { if ((hwcFrameMissed \u0026\u0026 !gpuFrameMissed) || mPropagateBackpressureClientComposition) { scheduleCommit(FrameHint::kNone); return false; } } if (mTracingEnabledChanged) { mLayerTracingEnabled = mLayerTracing.isEn","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger-commit%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger commit(提交)流程分析_surfaceflinger::commit-CSDN博客","uri":"/posts/android13-surfaceflinger-commit%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"SurfaceFlinger的composite方法，用于将多个窗口的图像进行合成，主要负责对相关要进行上帧的layer进行，识别排序好，然后合成，有hwc合成的会构建对应OutputLayer传递hwc，GPU合成则直接合成，再传递到hwc中，它主要完成以下几个步骤： 从队列中获取所有待合成的缓冲区。 将这些缓冲区按照一定的顺序进行合成，生成最终的图像。 将合成后的图像提交给HWC进行显示。 SurfaceFlinger的composite方法代码如下： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp std::unique_ptr\u003ccompositionengine::CompositionEngine\u003e mCompositionEngine; void SurfaceFlinger::composite(nsecs_t frameTime, int64_t vsyncId) FTL_FAKE_GUARD(kMainThreadContext) { ATRACE_FORMAT(\"%s %\" PRId64, __func__, vsyncId); if (mPowerHintSessionData.sessionEnabled) { mPowerHintSessionData.compositeStart = systemTime(); } compositionengine::CompositionRefreshArgs refreshArgs; const auto\u0026 displays = FTL_FAKE_GUARD(mStateLock, mDisplays); refreshArgs.outputs.reserve(displays.size()); for (const auto\u0026 [_, display] : displays) { refreshArgs.outputs.push_back(display-\u003egetCompositionDisplay()); } mDrawingState.traverseInZOrder([\u0026refreshArgs](Layer* layer) { if (auto layerFE = layer-\u003egetCompositionEngineLayerFE()) refreshArgs.layers.push_back(layerFE); }); refreshArgs.layersWithQueuedFrames.reserve(mLayersWithQueuedFrames.size()); for (auto layer : mLayersWithQueuedFrames) { if (auto layerFE = layer-\u003egetCompositionEngineLayerFE()) refreshArgs.layersWithQueuedFrames.push_back(layerFE); } refreshArgs.outputColorSetting = useColorManagement ? mDisplayColorSetting : compositionengine::OutputColorSetting::kUnmanaged; refreshArgs.colorSpaceAgnosticDataspace = mColorSpaceAgnosticDataspace; refreshArgs.forceOutputColorMode = mForceColorMode; refreshArgs.updatingOutputGeometryThisFrame = mVisibleRegionsDirty; refreshArgs.updatingGeometryThisFrame = mGeometryDirty.exchange(false) || mVisibleRegionsDirty; refreshArgs.blursAreExpensive = mBlursAreExpensive; refreshArgs.internalDisplayRotationFlags = DisplayDevice::getPrimaryDisplayRotationFlags(); if (CC_UNLIKELY(mDrawingState.colorMatrixChanged)) { refreshArgs.colorTransformMatrix = mDrawingState.colorMatrix; mDrawingState.colorMatrixChanged = false; } refreshArgs.devOptForceClientComposition = mDebugDisableHWC; if (mDebugFlashDelay != 0) { refreshArgs.devOptForceClientComposition = true; refreshArgs.devOptFlashDirtyRegionsDelay = std::chrono::milliseconds(mDebugFlashDelay); } const auto expectedPresentTime = mExpectedPresentTime.load(); const auto prevVsyncTime = mScheduler-\u003egetPreviousVsyncFrom(expectedPresentTime); const auto hwcMinWorkDuration = mVsyncConfiguration-\u003egetCurrentConfigs().hwcMinWorkDuration; refreshArgs.earliestPresentTime = prevVsyncTime - hwcMinWorkDuration; refreshArgs.previousPresentFence = mPreviousPresentFences[0].fenceTime; refreshArgs.scheduledFrameTime = mScheduler-\u003egetScheduledFrameTime(); refreshArgs.expectedPresentTime = expectedPresentTime; // Store the present time just before calling to the composition engine so we could notify // the scheduler. const auto presentTime = systemTime(); mCompositionEngine-\u003epresent(refreshArgs); if (mPowerHintSessionData.sessionEnabled) { mPowerHintSessionData.presentEnd = systemTime(); } mTimeStats-\u003erecordFrameDuration(frameTime, systemTime()); if (mScheduler-\u003eonPostComposition(presentTime)) { scheduleComposite(FrameHint::kNone); } postFrame(); postComposition(); const bool prevFrameHadClientComposition = mHadClientComposition; mHadClientComposition = mHadDeviceComposition = mReusedClientComposition = false; TimeStats::ClientCompositionRecord clientCompositionRecord; for (const auto\u0026 [_, display] : displays) { const auto\u0026 state = display-\u003egetCompositionDisplay()-\u003egetState(); mHadClientComposition |= state.usesClientComposition \u0026\u0026 !state.reusedClientComposition; mHadDeviceComposition |= state.usesDeviceComposition; mReusedClientComposition |= state.reusedClientComposition; clientCompositionRecord.predicted |= (state.strategyPrediction != CompositionStrategyPredictionState::DISABLED); clientCompositionRecord.predictionSucceeded |= (state.strategyPrediction == CompositionStrategyPredictionState::SUCCESS); } clientCompositionRecord.hadClientComp","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger-composite%E5%90%88%E6%88%90%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger composite(合成)流程分析-CSDN博客","uri":"/posts/android13-surfaceflinger-composite%E5%90%88%E6%88%90%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"onComposerHalHotplug是一个Android系统中的一个事件回调函数，用于处理Composer HAL（Hardware Abstraction Layer）的热插拔事件。Composer HAL是Android系统中负责处理图形渲染和显示的硬件抽象层，它与硬件驱动程序和图形服务之间进行通信。 当发生Composer HAL的热插拔事件时，系统会调用onComposerHalHotplug函数来通知相关的应用程序。这个函数可以在应用程序中实现，以便在热插拔事件发生时执行相应的操作。 SurfaceFlinger的onComposerHalHotplug方法代码如下： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp void SurfaceFlinger::onComposerHalHotplug(hal::HWDisplayId hwcDisplayId, hal::Connection connection) { const bool connected = connection == hal::Connection::CONNECTED; ALOGI(\"%s HAL display %\" PRIu64, connected ? \"Connecting\" : \"Disconnecting\", hwcDisplayId); // Only lock if we're not on the main thread. This function is normally // called on a hwbinder thread, but for the primary display it's called on // the main thread with the state lock already held, so don't attempt to // acquire it here. ConditionalLock lock(mStateLock, std::this_thread::get_id() != mMainThreadId); mPendingHotplugEvents.emplace_back(HotplugEvent{hwcDisplayId, connection}); if (std::this_thread::get_id() == mMainThreadId) { // Process all pending hot plug events immediately if we are on the main thread. // 如果我们在主线程上，请立即处理所有待处理的热插拔事件。 processDisplayHotplugEventsLocked(); } setTransactionFlags(eDisplayTransactionNeeded); } SurfaceFlinger processDisplayHotplugEventsLocked 调用SurfaceFlinger的processDisplayHotplugEventsLocked方法，处理所有待处理的热插拔事件： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp void SurfaceFlinger::processDisplayHotplugEventsLocked() { for (const auto\u0026 event : mPendingHotplugEvents) { std::optional\u003cDisplayIdentificationInfo\u003e info = getHwComposer().onHotplug(event.hwcDisplayId, event.connection); if (!info) { continue; } const auto displayId = info-\u003eid; const auto token = mPhysicalDisplayTokens.get(displayId); if (event.connection == hal::Connection::CONNECTED) { auto [supportedModes, activeMode] = loadDisplayModes(displayId); if (!token) { ALOGV(\"Creating display %s\", to_string(displayId).c_str()); DisplayDeviceState state; state.physical = {.id = displayId, .type = getHwComposer().getDisplayConnectionType(displayId), .hwcDisplayId = event.hwcDisplayId, .deviceProductInfo = std::move(info-\u003edeviceProductInfo), .supportedModes = std::move(supportedModes), .activeMode = std::move(activeMode)}; state.isSecure = true; // All physical displays are currently considered secure. state.displayName = std::move(info-\u003ename); sp\u003cIBinder\u003e token = new BBinder(); mCurrentState.displays.add(token, state); mPhysicalDisplayTokens.try_emplace(displayId, std::move(token)); mInterceptor-\u003esaveDisplayCreation(state); } else { ALOGV(\"Recreating display %s\", to_string(displayId).c_str()); auto\u0026 state = mCurrentState.displays.editValueFor(token-\u003eget()); state.sequenceId = DisplayDeviceState{}.sequenceId; // Generate new sequenceId. state.physical-\u003esupportedModes = std::move(supportedModes); state.physical-\u003eactiveMode = std::move(activeMode); if (getHwComposer().updatesDeviceProductInfoOnHotplugReconnect()) { state.physical-\u003edeviceProductInfo = std::move(info-\u003edeviceProductInfo); } } } else { ALOGV(\"Removing display %s\", to_string(displayId).c_str()); if (const ssize_t index = mCurrentState.displays.indexOfKey(token-\u003eget()); index \u003e= 0) { const DisplayDeviceState\u0026 state = mCurrentState.displays.valueAt(index); mInterceptor-\u003esaveDisplayDeletion(state.sequenceId); mCurrentState.displays.removeItemsAt(index); } mPhysicalDisplayTokens.erase(displayId); } processDisplayChangesLocked(); } mPendingHotplugEvents.clear(); } 调用processDisplayChangesLocked方法： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp void SurfaceFlinger::processDisplayChangesLocked() { // here we take advantage of Vector's copy-on-write semantics to // improve performance by skipping the transaction entirely when // know that the lists are identical const KeyedVector\u003cwp\u003cIBinder\u003e, DisplayDeviceState\u003e\u0026 curr(mCurrentState.displays); const KeyedVector\u003cwp\u003cIBinder\u003e, DisplayDeviceState\u003e\u0026 draw(mDrawingState.displays); if (!curr.isIdenticalTo(dr","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger-oncomposerhalhotplug%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger onComposerHalHotplug流程分析-CSDN博客","uri":"/posts/android13-surfaceflinger-oncomposerhalhotplug%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"onComposerHalRefresh方法是SurfaceFlinger中的一个函数。该方法的作用是在Composer HAL刷新时被调用，用于更新显示内容。onComposerHalRefresh方法会在SurfaceFlinger接收到Composer HAL刷新事件时被调用。Composer HAL是硬件抽象层的一部分，负责与硬件显示设备进行通信。当Composer HAL完成一次刷新操作后，会通知SurfaceFlinger进行相应的处理。 在onComposerHalRefresh方法中，SurfaceFlinger会执行一系列操作，包括更新屏幕上的图像内容、处理显示层的合成和混合等。通过这些操作，SurfaceFlinger能够将应用程序的图像内容正确地显示在屏幕上。 SurfaceFlinger的onComposerHalRefresh方法代码如下： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp void SurfaceFlinger::onComposerHalRefresh(hal::HWDisplayId) { Mutex::Autolock lock(mStateLock); scheduleComposite(FrameHint::kNone); } SurfaceFlinger scheduleComposite 调用SurfaceFlinger的scheduleComposite方法： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp void SurfaceFlinger::scheduleComposite(FrameHint hint) { mMustComposite = true; scheduleCommit(hint); } 调用scheduleCommit方法： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp std::unique_ptr\u003cscheduler::Scheduler\u003e mScheduler; void SurfaceFlinger::scheduleCommit(FrameHint hint) { if (hint == FrameHint::kActive) { mScheduler-\u003eresetIdleTimer(); } mPowerAdvisor-\u003enotifyDisplayUpdateImminent(); mScheduler-\u003escheduleFrame(); } MessageQueue scheduleFrame 调用Scheduler的scheduleFrame方法，Scheduler继承MessageQueue，调用MessageQueue的scheduleFrame方法： //frameworks/native/services/surfaceflinger/Scheduler/MessageQueue.cpp void MessageQueue::scheduleFrame() { ATRACE_CALL(); { std::lock_guard lock(mInjector.mutex); if (CC_UNLIKELY(mInjector.connection)) { ALOGD(\"%s while injecting VSYNC\", __FUNCTION__); //请求下一个 VSync 信号 mInjector.connection-\u003erequestNextVsync(); return; } } std::lock_guard lock(mVsync.mutex); mVsync.scheduledFrameTime = mVsync.registration-\u003eschedule({.workDuration = mVsync.workDuration.get().count(), .readyDuration = 0, .earliestVsync = mVsync.lastCallbackTime.count()}); } 调用了VSyncCallbackRegistration的schedule方法： //frameworks/native/services/surfaceflinger/Scheduler/VSyncCallbackRegistration.cpp std::reference_wrapper\u003cVSyncDispatch\u003e mDispatch; ScheduleResult VSyncCallbackRegistration::schedule(VSyncDispatch::ScheduleTiming scheduleTiming) { if (!mValidToken) { return std::nullopt; } return mDispatch.get().schedule(mToken, scheduleTiming); } VSyncDispatchTimerQueue schedule 调用mDispatch(VSyncDispatch)的schedule方法，实际调用的是VSyncDispatchTimerQueue的schedule方法： //frameworks/native/services/surfaceflinger/Scheduler/VSyncDispatchTimerQueue.cpp ScheduleResult VSyncDispatchTimerQueueEntry::schedule(VSyncDispatch::ScheduleTiming timing, VSyncTracker\u0026 tracker, nsecs_t now) { auto nextVsyncTime = tracker.nextAnticipatedVSyncTimeFrom( std::max(timing.earliestVsync, now + timing.workDuration + timing.readyDuration)); auto nextWakeupTime = nextVsyncTime - timing.workDuration - timing.readyDuration; bool const wouldSkipAVsyncTarget = mArmedInfo \u0026\u0026 (nextVsyncTime \u003e (mArmedInfo-\u003emActualVsyncTime + mMinVsyncDistance)); bool const wouldSkipAWakeup = mArmedInfo \u0026\u0026 ((nextWakeupTime \u003e (mArmedInfo-\u003emActualWakeupTime + mMinVsyncDistance))); if (wouldSkipAVsyncTarget \u0026\u0026 wouldSkipAWakeup) { return getExpectedCallbackTime(nextVsyncTime, timing); } bool const alreadyDispatchedForVsync = mLastDispatchTime \u0026\u0026 ((*mLastDispatchTime + mMinVsyncDistance) \u003e= nextVsyncTime \u0026\u0026 (*mLastDispatchTime - mMinVsyncDistance) \u003c= nextVsyncTime); if (alreadyDispatchedForVsync) { nextVsyncTime = tracker.nextAnticipatedVSyncTimeFrom(*mLastDispatchTime + mMinVsyncDistance); nextWakeupTime = nextVsyncTime - timing.workDuration - timing.readyDuration; } // 如果计时器线程即将运行，通过回调计时器重新计算应用此工作更新，以避免取消即将触发的回调。 auto const nextReadyTime = nextVsyncTime - timing.readyDuration; mScheduleTiming = timing; mArmedInfo = {nextWakeupTime, nextVsyncTime, nextReadyTime}; return getExpectedCallbackTime(nextVsyncTime, timing); } ","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger-oncomposerhalrefresh%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger onComposerHalRefresh流程分析_android 13 surfaceflinge变化-CSDN博客","uri":"/posts/android13-surfaceflinger-oncomposerhalrefresh%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"onComposerHalVsync是一个Android系统中的一个回调函数，用于在垂直同步（Vsync）事件发生时通知应用程序。Vsync是指显示器刷新的时间点，它通常以固定的频率发生，比如60Hz。应用程序可以通过注册onComposerHalVsync回调函数来获取Vsync事件的通知。 当Vsync事件发生时，系统会调用注册了onComposerHalVsync回调函数的应用程序，并传递一个时间戳参数，表示Vsync事件发生的时间点。应用程序可以利用这个时间戳来进行一些与显示相关的操作，比如更新UI界面或者进行动画效果的计算。 onComposerHalVsync函数通常是在底层硬件抽象层（HAL）中实现的，它与具体的硬件设备相关。应用程序可以通过调用系统提供的API来注册和取消onComposerHalVsync回调函数。 SurfaceFlinger的onComposerHalVsync方法代码如下： //frameworks/native/services/surfaceflinger/Surfaceflinger.cpp void SurfaceFlinger::onComposerHalVsync(hal::HWDisplayId hwcDisplayId, int64_t timestamp, std::optional\u003chal::VsyncPeriodNanos\u003e vsyncPeriod) { const std::string tracePeriod = [vsyncPeriod]() { if (ATRACE_ENABLED() \u0026\u0026 vsyncPeriod) { std::stringstream ss; ss \u003c\u003c \"(\" \u003c\u003c *vsyncPeriod \u003c\u003c \")\"; return ss.str(); } return std::string(); }(); ATRACE_FORMAT(\"onComposerHalVsync%s\", tracePeriod.c_str()); Mutex::Autolock lock(mStateLock); const auto displayId = getHwComposer().toPhysicalDisplayId(hwcDisplayId); if (displayId) { const auto token = getPhysicalDisplayTokenLocked(*displayId); const auto display = getDisplayDeviceLocked(token); display-\u003eonVsync(timestamp); } if (!getHwComposer().onVsync(hwcDisplayId, timestamp)) { return; } const bool isActiveDisplay = displayId \u0026\u0026 getPhysicalDisplayTokenLocked(*displayId) == mActiveDisplayToken; if (!isActiveDisplay) { // For now, we don't do anything with non active display vsyncs. return; } bool periodFlushed = false; mScheduler-\u003eaddResyncSample(timestamp, vsyncPeriod, \u0026periodFlushed); if (periodFlushed) { modulateVsync(\u0026VsyncModulator::onRefreshRateChangeCompleted); } } 调用modulateVsync方法： //frameworks/native/services/surfaceflinger/SurfaceFlinger.h class SurfaceFlinger : public BnSurfaceComposer, public PriorityDumper, private IBinder::DeathRecipient, private HWC2::ComposerCallback, private ICompositor, private scheduler::ISchedulerCallback { class BufferCountTracker { void modulateVsync(Handler handler, Args... args) { if (const auto config = (*mVsyncModulator.*handler)(args...)) { const auto vsyncPeriod = mScheduler-\u003egetVsyncPeriodFromRefreshRateConfigs(); setVsyncConfig(*config, vsyncPeriod); } } } 调用setVsyncConfig方法： //frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp std::unique_ptr\u003cscheduler::Scheduler\u003e mScheduler; void SurfaceFlinger::setVsyncConfig(const VsyncModulator::VsyncConfig\u0026 config, nsecs_t vsyncPeriod) { mScheduler-\u003esetDuration(mAppConnectionHandle, /*workDuration=*/config.appWorkDuration, /*readyDuration=*/config.sfWorkDuration); mScheduler-\u003esetDuration(mSfConnectionHandle, /*workDuration=*/std::chrono::nanoseconds(vsyncPeriod), /*readyDuration=*/config.sfWorkDuration); mScheduler-\u003esetDuration(config.sfWorkDuration); } Scheduler setDuration 调用Scheduler的setDuration方法： //frameworks/native/services/surfaceflinger/Scheduler/Scheduler.cpp void Scheduler::setDuration(ConnectionHandle handle, std::chrono::nanoseconds workDuration, std::chrono::nanoseconds readyDuration) { android::EventThread* thread; { std::lock_guard\u003cstd::mutex\u003e lock(mConnectionsLock); RETURN_IF_INVALID_HANDLE(handle); thread = mConnections[handle].thread.get(); } thread-\u003esetDuration(workDuration, readyDuration); } EventThread setDuration 调用EventThread的setDuration方法： //frameworks/native/services/surfaceflinger/Scheduler/EventThread.cpp const std::unique_ptr\u003cVSyncSource\u003e mVSyncSource GUARDED_BY(mMutex); void EventThread::setDuration(std::chrono::nanoseconds workDuration, std::chrono::nanoseconds readyDuration) { std::lock_guard\u003cstd::mutex\u003e lock(mMutex); mVSyncSource-\u003esetDuration(workDuration, readyDuration); } 调用mVSyncSource(VSyncSource)的setDuration方法，DispSyncSource继承VSyncSource，调用DispSyncSource的setDuration方法： //frameworks/native/services/surfaceflinger/Scheduler/DispSyncSource.cpp class DispSyncSource final : public VSyncSource { void DispSyncSource::setDuration(std::chrono::nanoseconds workDuration, std::chrono::nanoseconds readyDuration) { std::lock_guard lock(mVsyncMutex); mWorkDuration = workDuration; mReadyDuration = readyDuration;","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger-oncomposerhalvsync%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger onComposerHalVsync流程分析-CSDN博客","uri":"/posts/android13-surfaceflinger-oncomposerhalvsync%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"SurfaceFlinger的onLayerUpdate方法用于在图形层更新时进行相应的处理，代码如下： void SurfaceFlinger::onLayerUpdate() { scheduleCommit(FrameHint::kActive); } 调用SurfaceFlinger的scheduleCommit方法： //frameworks/native/service/surfaceflinger/SurfaeFlinger.cpp std::unique_ptr\u003cscheduler::Scheduler\u003e mScheduler; void SurfaceFlinger::scheduleCommit(FrameHint hint) { if (hint == FrameHint::kActive) { mScheduler-\u003eresetIdleTimer(); } mPowerAdvisor-\u003enotifyDisplayUpdateImminent(); mScheduler-\u003escheduleFrame(); } 调用mScheduler(Scheduler)的scheduleFrame方法，Scheduler继承于MessageQueue，调用MessageQueue的scheduleFrame方法： //frameworks/native/services/surfaceflinger/Scheduler/MessageQueue.cpp Vsync mVsync; std::unique_ptr\u003cscheduler::VSyncCallbackRegistration\u003e registration; void MessageQueue::scheduleFrame() { ATRACE_CALL(); { std::lock_guard lock(mInjector.mutex); if (CC_UNLIKELY(mInjector.connection)) { ALOGD(\"%s while injecting VSYNC\", __FUNCTION__); mInjector.connection-\u003erequestNextVsync(); return; } } std::lock_guard lock(mVsync.mutex); mVsync.scheduledFrameTime = mVsync.registration-\u003eschedule({.workDuration = mVsync.workDuration.get().count(), .readyDuration = 0, .earliestVsync = mVsync.lastCallbackTime.count()}); } 调用mVsync(Vsync)成员变量registration的schedule方法，而mVsync.registration在MessageQueue的initVsync中注册： //frameworks/native/services/surfaceflinger/Scheduler/MessageQueue.cpp void MessageQueue::initVsync(scheduler::VSyncDispatch\u0026 dispatch, frametimeline::TokenManager\u0026 tokenManager, std::chrono::nanoseconds workDuration) { setDuration(workDuration); mVsync.tokenManager = \u0026tokenManager; mVsync.registration = std::make_unique\u003c scheduler::VSyncCallbackRegistration\u003e(dispatch, std::bind(\u0026MessageQueue::vsyncCallback, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3), \"sf\"); } 因此会调用到MessageQueue的vsyncCallback方法： //frameworks/native/services/surfaceflinger/Scheduler/MessageQueue.cpp void MessageQueue::vsyncCallback(nsecs_t vsyncTime, nsecs_t targetWakeupTime, nsecs_t readyTime) { ATRACE_CALL(); // Trace VSYNC-sf mVsync.value = (mVsync.value + 1) % 2; { std::lock_guard lock(mVsync.mutex); mVsync.lastCallbackTime = std::chrono::nanoseconds(vsyncTime); mVsync.scheduledFrameTime.reset(); } const auto vsyncId = mVsync.tokenManager-\u003egenerateTokenForPredictions( {targetWakeupTime, readyTime, vsyncTime}); mHandler-\u003edispatchFrame(vsyncId, vsyncTime); } 调用Handler的dispatchFrame方法： //frameworks/native/services/surfaceflinger/Scheduler/MessageQueue.cpp void MessageQueue::Handler::dispatchFrame(int64_t vsyncId, nsecs_t expectedVsyncTime) { if (!mFramePending.exchange(true)) { mVsyncId = vsyncId; mExpectedVsyncTime = expectedVsyncTime; mQueue.mLooper-\u003esendMessage(this, Message()); } } 发送Message，消息在Handler的handleMessage方法中处理： //frameworks/native/services/surfaceflinger/Scheduler/MessageQueue.cpp ICompositor\u0026 mCompositor; void MessageQueue::Handler::handleMessage(const Message\u0026) { mFramePending.store(false); const nsecs_t frameTime = systemTime(); auto\u0026 compositor = mQueue.mCompositor; if (!compositor.commit(frameTime, mVsyncId, mExpectedVsyncTime)) { return; } compositor.composite(frameTime, mVsyncId); compositor.sample(); } 上面方法主要处理如下： 1、调用mCompositor(ICompositor)的commit方法。 2、调用mCompositor(ICompositor)的composite方法。 下面分别进行分析： SurfaceFlinger commit 调用mCompositor(ICompositor)的commit方法，ICompositor是一个接口，由SurfaceFlinger实现，SurfaceFlinger的commit方法用于将应用程序的绘制结果提交到屏幕上显示： Android13 SurfaceFlinger commit(提交)流程分析-CSDN博客 SurfaceFlinger composite 调用mCompositor(ICompositor)的commit方法，ICompositor是一个接口，由SurfaceFlinger实现，SurfaceFlinger的composite用于将多个窗口的图像进行合成： Android13 SurfaceFlinger composite(合成)流程分析-CSDN博客 ","date":"2024-11-06","objectID":"/posts/android13-surfaceflinger-onlayerupdate%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android13 SurfaceFlinger onLayerUpdate流程分析-CSDN博客","uri":"/posts/android13-surfaceflinger-onlayerupdate%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Android1****4 - WindowManagerService之客户端Activity****布局 一**、主要角色** WMS作为一个服务端，有多种客户端与其交互的场景。我们以常见的Activity为例： Activity：在ActivityThread构建一个Activity后，会调用其attach方法，在attach中构建了一个PhoneWindow。 PhoneWindow：一个Activity对应一个PhoneWindow。而每个PhoneWindow持有一个WindowManagerImpl对象。 WindowManagerImpl：是服务端WMS在客户端的代理。而WindowManagerImpl中持有WindowManagerGlobal。 WindowManagerGlobal：是进程内的单例。WindowManagerGlobal不仅持有WMS服务端的WindowManagerService、WindowSession的引用，并且集合了所有的ViewRootImpl、DecorView等 ViewRootImpl：每个Activity对应一个ViewRootImp对象。ViewRootImp是作为客户端与WMS的桥梁。从客户端到服务端的角度，ViewRootImp中持有的WindowSession对象是服务端Session的引用，一个Session对应一个客户端进程。从服务端到客户端的角度，ViewRootImp中有一个子类W，是binder通信的服务端，W对象的引用被WMS持有，用来服务端向客户端通信。另外，ViewRootImp中持有DecorView对象。从逻辑上，ViewRootImpl是View树的根，但其本身并不是一个View，只是实现了ViewParent接口。DecorView是ViewRootImp的子类（见setView()方法中的view.assignParent(this)） ） DecorView：每个Activity对应一个DecorView。DecorView是真正的顶层View，是最外层的view。其inflate PhoneWidow传过来的layout后，将其addView作为自己的第0个类。DecorView维护了一个窗口的基本结构，包括主内容区域、titlebar区域等。 二**、**窗口的构建过程 窗口的结构大致如下： 其过程参考上图，在PhoneWindow的初始化过程中，调用了generateLayout(DecorView decor)方法，其中对一个window的整体画面进行了初始化。 protected ViewGroup generateLayout(DecorView decor) { // Apply data from current theme. // Style来自于Theme xml文件 TypedArray a = getWindowStyle(); mIsFloating = a.getBoolean(R.styleable.Window_windowIsFloating, false); int flagsToUpdate = (FLAG_LAYOUT_IN_SCREEN|FLAG_LAYOUT_INSET_DECOR) \u0026 (~getForcedWindowFlags()); if (mIsFloating) { setLayout(WRAP_CONTENT, WRAP_CONTENT); setFlags(0, flagsToUpdate); } else { setFlags(FLAG_LAYOUT_IN_SCREEN|FLAG_LAYOUT_INSET_DECOR, flagsToUpdate); getAttributes().setFitInsetsSides(0); getAttributes().setFitInsetsTypes(0); } if (a.getBoolean(R.styleable.Window_windowNoTitle, false)) { requestFeature(FEATURE_NO_TITLE); } else if (a.getBoolean(R.styleable.Window_windowActionBar, false)) { // Don't allow an action bar if there is no title. requestFeature(FEATURE_ACTION_BAR); } if (a.getBoolean(R.styleable.Window_windowActionBarOverlay, false)) { requestFeature(FEATURE_ACTION_BAR_OVERLAY); } if (a.getBoolean(R.styleable.Window_windowActionModeOverlay, false)) { requestFeature(FEATURE_ACTION_MODE_OVERLAY); } if (a.getBoolean(R.styleable.Window_windowFullscreen, false)) { setFlags(FLAG_FULLSCREEN, FLAG_FULLSCREEN \u0026 (~getForcedWindowFlags())); } if (a.getBoolean(R.styleable.Window_windowTranslucentStatus, false)) { setFlags(FLAG_TRANSLUCENT_STATUS, FLAG_TRANSLUCENT_STATUS \u0026 (~getForcedWindowFlags())); } if (a.getBoolean(R.styleable.Window_windowTranslucentNavigation, false)) { setFlags(FLAG_TRANSLUCENT_NAVIGATION, FLAG_TRANSLUCENT_NAVIGATION \u0026 (~getForcedWindowFlags())); } if (a.getBoolean(R.styleable.Window_windowShowWallpaper, false)) { setFlags(FLAG_SHOW_WALLPAPER, FLAG_SHOW_WALLPAPER\u0026(~getForcedWindowFlags())); } if (a.getBoolean(R.styleable.Window_windowEnableSplitTouch, getContext().getApplicationInfo().targetSdkVersion \u003e= android.os.Build.VERSION_CODES.HONEYCOMB)) { setFlags(FLAG_SPLIT_TOUCH, FLAG_SPLIT_TOUCH\u0026(~getForcedWindowFlags())); } a.getValue(R.styleable.Window_windowMinWidthMajor, mMinWidthMajor); a.getValue(R.styleable.Window_windowMinWidthMinor, mMinWidthMinor); if (DEBUG) Log.d(TAG, \"Min width minor: \" + mMinWidthMinor.coerceToString() + \", major: \" + mMinWidthMajor.coerceToString()); if (a.hasValue(R.styleable.Window_windowFixedWidthMajor)) { if (mFixedWidthMajor == null) mFixedWidthMajor = new TypedValue(); a.getValue(R.styleable.Window_windowFixedWidthMajor, mFixedWidthMajor); } if (a.hasValue(R.styleable.Window_windowFixedWidthMinor)) { if (mFixedWidthMinor == null) mFixedWidthMinor = new TypedValue(); a.getValue(R.styleable.Window_windowFixedWidthMinor, mFixedWidthMinor); } if (a.hasValue(R.styleable.Window_windowFixedHeightMajor)) { if (mFixedHeightMajor == null) mFixedHeightMajor = new TypedValue(); a.getValue(R.styleable.Window_windowFixedHeightMajor, mFixedHeightMajor); } if (a.hasValue(R.styleable.Window_windowFixedHeightMinor)) { if (mFixedHeightMinor == null) mFixedHeightMinor = new TypedValue(); ","date":"2024-11-06","objectID":"/posts/android14-windowmanagerservice%E4%B9%8B%E5%AE%A2%E6%88%B7%E7%AB%AFactivity%E5%B8%83%E5%B1%80-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Android14 - WindowManagerService之客户端Activity布局-CSDN博客","uri":"/posts/android14-windowmanagerservice%E4%B9%8B%E5%AE%A2%E6%88%B7%E7%AB%AFactivity%E5%B8%83%E5%B1%80-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"[TOC] 背景 某轮测试发现，我们的设备运行一个第三方的App时，卡顿感非常明显： 界面加载很慢，菊花转半天 滑屏极度不跟手，目测观感帧率低于15 对比机（竞品）也会稍微一点卡，但是好很多，基本不会有很大感觉的卡顿 可以初步判定我们的设备存在性能问题，亟需优化，拉平到竞品水准。 最后发现，这个问题实际上是应用自身奇怪的实现（getResources()的重载），加上Binder过度调用（沉重的Binder耗时）导致的。 本文做记录和分享。 其中对比机配置、Android版本均与本机不同，不做变量参考。 观测 由于这个可爱的App是第三方的App（应用市场下载的），我们没有源码，只能从系统端去干涉。先抓一份trace。 1. trace体现UI绘制操作严重耗时 trace一抓一看，显然App主线程已经陷入困境。可以看到： CPU使用率并不高 主线程几乎完全在执行Traversal工作（mersure和layout） measure和layout极度耗时，显然达不到合理的帧率要求（甚至连PPT帧率都赶不上） 可以看到，这份trace表明App的整个measure和layout工作存在整体性的不合理耗时。但并不能准确提示细节，也不能看出问题部分。可以肯定，耗时工作位于App层（不是指耗时原因也来自App）。 2. 排查measure和layout慢的原因：可疑的多次binder 上面可以确认绘制缓慢造成耗时。但是一来App不是自己的，二来这么复杂的调用，通过分析调用、跟代码来定位慢方法、慢路径显然足够低效。 定位到Traversal，统计一下Traversal各部分的耗时占比，可以大致定位出耗时部分可能是什么业务的： 可以看到，traversal意外地包含了数量巨大的binder调用，它占据总耗时的80%+，使得应用层绘图超出生命线10倍以上： 这次doFrame-\u003etravesal耗时接近200ms，属于\"无法使用的垃圾\"级别，不是性能问题而是故障 binder调用（binder transaction）次数很多，在几毫秒的时间里（预期的一次应用层绘图时间）进行了194次IPC binder耗时占比很高：83%左右 还有一个ioctl调用次数也很多、很耗时；由于binder驱动调用talkWithDriver()需要使用ioctl，因此这里初步判断ioctl是binder IPC的伴生，无碍 生命线：对于60Hz的屏幕，生命线为16ms左右。但是16ms为图形栈全链路的极限时间，留给应用层的时间更低 可以确认，过多的binder调用导致了这个恼火的性能问题。 3. binder：在哪、谁为、为何频繁调用 通常应用（和应用集成的库），出于一定的目的，会通过IBinder、AIDL、封装组件（如startService）、直接调用驱动节点（talkWithDriver）等方式来进行一次Binder IPC。 性能问题中，与Binder IPC相关的，最常见的主要如下： 频繁调用Binder 关键、敏感、紧张的位置调用Binder Binder对端响应太慢，对端繁忙 Binder传递的数据太大 Binder客户端线程数超限（发起请求的线程满） Binder服务端线程数超限（处理请求的线程满） 对于Binder传递数据太大、线程数导致的性能问题，由于应用不是自己的（不好干涉、不关注），且对比机卡顿不那么明显（可以粗略排除），因此不太值得去看。（另外我们是在滑屏的时候卡的，主线程UIHandler也做不到并发发出Binder IPC） 这里还是展示一下怎么分析。下列命令可以提供一些关于binder状态、traction状态、传递数据大小等内容： cat /sys/kernel/debug/binder/failed_transaction_log cat /sys/kernel/debug/binder/transaction_log cat /sys/kernel/debug/binder/transactions 同样的，我们不好关注应用为何调用binder（因为没有App的代码，最近也忙的不想逆向它；但实际上最后我们知道了为何调用），也很显然是在哪调用的（在App UI线程 performTraversal时调用的），因此先来看看这群IPC的对端是谁。 trace一看，binder调用确实很多（画蓝紫色线部分都是binder；本是细线，溢满则刚）： 上图binder调用很多，其实很多是同一种类，各IPC都最终归属于一类Binder。分类看，数量巨大、占比最高的两类binder（称为第一部分binder和第二部分binder）是值得探讨的主要耗时部分。 首先，分析第一部分binder的对端。跟踪发现第一部分binder“飞”往SurafceFlinger，耗时较短，次数合理，评估正常，不再跟进，不贴图展示。 第二部分binder，从次数、耗时来看，确实可疑。它从App进程“飞”往System_server（Framework服务层）： 4. binder：频繁调用的具体定位 性能分析的其中一个关键方向是找到慢方法、慢路径。上面一步已经体现了，慢是因为App在敏感且关键的位置调用了Binder，这个binder的对端是Framework。 从系统侧分析这个binder的性能，难以像App那样轻松定位——因为App里面有多少个调用、系统里面暴露了多少个binder，在哪里触发的，都不好搞。 因此直接来粗暴的方法，把所有binder调用抓堆栈下来。 多次复现、多次抓取，阅读堆栈、总结分类，可以抓到蛛丝马迹。由于最长的堆栈高达33万行（包含合理的正常的binder和造成性能问题的binder），且抓了好几份，这里只能将问题的关键点做个展示输出。 ls 20230209.fk.trace binder.20230209.2.fk.trace.log binder.20230209.4.fk.trace.log binder.20230209.fk.trace.log binder.20230210.1.fk.trace.log 20230209.ok.trace binder.20230209.3.fk.trace.log binder.20230209.5.fk.trace.log binder.20230209.ok.trace.log fk表示fuck，即不正常情况下的binder堆栈；ok表示正常。 其中性能故障对应的堆栈如下（几类有性能问题的binder调用；仅截取关键位置）： 第一个堆栈放全一些，可以看出，在正常的traversal过程中，View体系正常调用getResources()，binder发生在getResources()内部：它调用了IWindowManager.getInitialDisplayDensity()，通过binder“飞”到system_server： Count: 15 Trace: java.lang.Throwable at android.os.BinderProxy.transact(BinderProxy.java:547) at android.view.IWindowManager$Stub$Proxy.getInitialDisplayDensity(IWindowManager.java:3025) at java.lang.reflect.Method.invoke(Native Method) at refactor.common.base.FActivity.e5(FActivity.java:7) at refactor.common.base.FActivity.getResources(FActivity.java:7) at androidx.appcompat.widget.ContentFrameLayout.onMeasure(ContentFrameLayout.java:1) at android.view.View.measure(View.java:25597) at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:7114) at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1632) at android.widget.LinearLayout.measureVertical(LinearLayout.java:922) at android.widget.LinearLayout.onMeasure(LinearLayout.java:801) at android.view.View.measure(View.java:25597) at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:7114) at android.widget.FrameLayout.onMeasure(FrameLayout.java:331) at android.view.View.measure(View.java:25597) at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:7114) at android.widget.LinearLayout.measure","date":"2024-11-06","objectID":"/posts/android%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96getresources%E4%B8%8Ebinder%E4%BA%A4%E7%81%AB%E5%AF%BC%E8%87%B4%E7%9A%84%E7%95%8C%E9%9D%A2%E5%8D%A1%E9%A1%BF%E4%BC%98%E5%8C%96/:0:0","tags":["clippings","转载","blog","卡顿","Trace","Perfetto"],"title":"Android性能优化：getResources()与Binder交火导致的界面卡顿优化","uri":"/posts/android%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96getresources%E4%B8%8Ebinder%E4%BA%A4%E7%81%AB%E5%AF%BC%E8%87%B4%E7%9A%84%E7%95%8C%E9%9D%A2%E5%8D%A1%E9%A1%BF%E4%BC%98%E5%8C%96/"},{"categories":null,"content":"本文适用于Android 12中增加系统服务。 目录 1.总体步骤 2、详细步骤 2.1 创建AIDL文件 2.2 报错修改 2.2.1 AIDL文件自动生成的Java文件报错 2.2.2 AIDL文件Observer/Callback/Listener命名报错修改 2.2.3 注册方法报错 2.2.4 避免使用枚举类enum 2.2.5 Callback如何让APP访问到 3. Context中定义service name 4. 编写SystemService 5. 在SystemServer类中注册新增的系统服务 6. 编写系统Manager类 7. 注册系统Manager类 8. 应用调用 1.总体步骤 2、详细步骤 2.1 创建AIDL文件 **在framework/base/core/java/android/app下创建AIDL文件，**如果业务比较复杂，可以创建模块文件夹。代码示例如下： framework/base/core/java/android/app/devicemanager/IDeviceManager.aidl package android.app.devicemanager;import android.app.devicemanager.DeviceEntity;import android.app.devicemanager.IDeviceObserver;interface IDeviceManager {int bindDivice(int deviceId); DeviceEntity getDeviceEntity(int deviceId);void registerDeviceObserver(in IDeviceObserver observer);void unregisterDeviceObserver(in IDeviceObserver observer);} framework/base/core/java/android/app/devicemanager/IDiviceObserver.aidl package android.app.devicemanager;import android.app.devicemanager.DeviceEntity;oneway interface IDiviceObserver{void onBindChanged(int state, int deviceId);void onStateChanged(int state, int deviceId);} framework/base/core/java/android/app/devicemanager/DeviceEntity.aidl package android.app.devicemanager;parcelable DeviceEntity; 2.2 报错修改 上述写法会报非常多的错，请参考Android 12 API规范：请参考 https://www.cnblogs.com/wanghongzhu/p/14729469.html 。 针对上述代码所犯的错误，也就是大家在Android 12版本中使用make -j32 framework-minus-apex编译framework层的报错修改。 2.2.1 AIDL文件自动生成的Java文件报错 这是因为AIDL自动生成的Java文件不满足Android 12 framework API的规范：framework层不能直接暴露原生AIDL文件。 修改的方式是在aidl文件上添加@hide，如下所示，这样就可以解决所有AIDL自动生成的文件。（这是扒遍国内全网都没在找到，在Google中才找到的根本解决办法） package android.app.devicemanager;import android.app.devicemanager.DeviceEntity;import android.app.devicemanager.IDeviceObserver;interface IDeviceManager {int bindDivice(int deviceId); DeviceEntity getDeviceEntity(int deviceId);void registerDeviceObserver(in IDeviceObserver observer);void unregisterDeviceObserver(in IDeviceObserver observer);} out/srcjars/android/app/devicemanager/IDiviceObserver.java:60: error: Methods calling system APIs should rethrow `RemoteException` as `RuntimeException` (but do not list it in the throws clause) [RethrowRemoteException] out/srcjars/android/app/devicemanager/IDiviceObserver.java:70: error: Missing nullability on method `asBinder` return [MissingNullability] out/srcjars/android/app/devicemanager/IDiviceObserver.java:75: error: Raw AIDL interfaces must not be exposed: Stub extends Binder [RawAidl] 2.2.2 AIDL文件Observer/Callback/Listener命名报错修改 Observer命名报错，Android Lint 工具对callback和listener有严格的校验，不建议使用Observer作为回调，要用callback或者listener。 当只有一个回调方法且永远不会有其他回调方法时使用Listener，且注册监听和解注册监听的方法必须是add/remove开头，否则Android Lint编译不过。 当有多个回调方法时，或者有关联的常量时，应该使用Callback。Callback类可以是一个interface或者abstract class。添加callback和去掉callback应该使用register和unregister开头的方法。 callback中的方法应该以on-开头。 请中招的小伙伴自行修改。 2.2.3 注册方法报错 Registration methods should have overload that accepts delivery Executor: `registerDeviceCallback` [ExecutorRegistration] 是不是一脸懵，看不明白啥意思，以前很早的framework层的manager，没啥参考价值，推荐参考新的manager和API规范，因为现有的注册回调的方法必须是两个参数，其中一个必须为Executor，如下所示。 public void registerFooCallback( @NonNull @CallbackExecutor Executor executor,@NonNull FooCallback callback)public void unregisterFooCallback(@NonNull FooCallback callback) {} 2.2.4 避免使用枚举类enum 在Framework层使用enum会报错：Enums are discouraged in Android APIs [Enum]，因此一般都用@intDef代替，使用新的注解表示。 2.2.5 Callback如何让APP访问到 前边2.2.1 AIDL文件自动生成的Java文件报错，为了解决需要添加@hide，但是添加该注解后，Apps就访问不到该callback，如何实现Binder通信呢？ 解决办法： 创建一个public abstract class DeviceCallback，对apps暴露该类，让Apps添加注册的时候创建该类的实例。 然后再framework层manager中实现DeviceManager类与IDeviceCallback.aidl的一一映射关系。 这样做的好处： 即能避免暴露原生的AIDL文件，而且Apps不用实现ICallback.aidl中所有的方法。 //创建暴露给Apps的抽象类 package android.app.devicemanager;public abstract class DiviceCallback {void onBindChanged(int state, int deviceId);void onStateChanged(int state, int deviceId);} //Manager中对应的映射关系 package android.app.devicemanager;import android.app.devicemanager.IDeiceCallback;import android.app.devicemanager.DevoceCallback;import java.ut","date":"2024-11-06","objectID":"/posts/framework%E5%B1%82%E6%B7%BB%E5%8A%A0systemservice%E5%92%8Cmanager%E7%9A%84%E8%B6%85%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4_framework%E6%B7%BB%E5%8A%A0%E6%96%B0service-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","转载","blog"],"title":"Framework层添加SystemService和Manager的超详细步骤_framework添加新service-CSDN博客","uri":"/posts/framework%E5%B1%82%E6%B7%BB%E5%8A%A0systemservice%E5%92%8Cmanager%E7%9A%84%E8%B6%85%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4_framework%E6%B7%BB%E5%8A%A0%E6%96%B0service-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"SurfaceComposerClient创建 SurfaceComposerClient对象是在哪里创建的呢?是在SurfaceSession构造时候创建 frameworks/base/core/jni/android_view_SurfaceSession.cpp static jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); client-\u003eincStrong((void*)nativeCreate); return reinterpret_cast\u003cjlong\u003e(client); } 这里的SurfaceSession是在哪里创建的呢？这里直接上堆栈 实际是在ViewRootImpl构造期间就创建 SurfaceComposerClient的mClient初始化 这里的mClient是谁呢？类型是 sp mClient; 看得出是一个接口 看下SurfaceComposerClient构造时候会与sf进行跨进程createConnection创建链接，返回的对象就是Client对象。 void SurfaceComposerClient::onFirstRef() { sp\u003cISurfaceComposer\u003e sf(ComposerService::getComposerService()); if (sf != nullptr \u0026\u0026 mStatus == NO_INIT) { sp\u003cISurfaceComposerClient\u003e conn; conn = sf-\u003ecreateConnection(); if (conn != nullptr) { mClient = conn; mStatus = NO_ERROR; } } } 这里又出现了ComposerService::getComposerService() frameworks/native/libs/gui/SurfaceComposerClient.cpp sp\u003cISurfaceComposer\u003e ComposerService::getComposerService() { ComposerService\u0026 instance = ComposerService::getInstance(); if (instance.mComposerService == nullptr) { if (ComposerService::getInstance().connectLocked()) { WindowInfosListenerReporter::getInstance()-\u003ereconnect(instance.mComposerService); } } return instance.mComposerService; } //connectLocked实现 bool ComposerService::connectLocked() { const String16 name(\"SurfaceFlinger\"); //就是获取sf的bp代理，赋值给mComposerService mComposerService = waitForService\u003cISurfaceComposer\u003e(name); return true; } 所以上面onFirstRef中sf-\u003ecreateConnection()调用到sf了，sf代码如下 frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp sp\u003cISurfaceComposerClient\u003e SurfaceFlinger::createConnection() { const sp\u003cClient\u003e client = new Client(this); return client-\u003einitCheck() == NO_ERROR ? client : nullptr; } sf端就是简单创建了一个Client对象，这里来看看 其实Client本质是一个Binder对象的BpBinder即跨进程的代理，远端的BnBinder在SurfaceFlinger的Client.cpp 思考为啥有了sf代理，还需要Client： 哈哈，其实这里主要是为了帮助sf进行解耦一部分工作 SurfaceControl，Layer创建 frameworks/base/core/jni/android_view_SurfaceControl.cpp static jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jobject metadataParcel) { sp\u003cSurfaceComposerClient\u003e client; status_t err = client-\u003ecreateSurfaceChecked(String8(name.c_str()), w, h, format, \u0026surface, flags, parentHandle, std::move(metadata)); surface-\u003eincStrong((void *)nativeCreate); return reinterpret_cast\u003cjlong\u003e(surface.get()); } 主要调用到了SurfaceComposerClient的createSurfaceChecked。 下面看看 SurfaceComposerClient::createSurfaceChecked方法 status_t SurfaceComposerClient::createSurfaceChecked(const String8\u0026 name, uint32_t w, uint32_t h, PixelFormat format, sp\u003cSurfaceControl\u003e* outSurface, uint32_t flags, const sp\u003cIBinder\u003e\u0026 parentHandle, LayerMetadata metadata, uint32_t* outTransformHint) { err = mClient-\u003ecreateSurface(name, w, h, format, flags, parentHandle, std::move(metadata), \u0026handle, \u0026gbp, \u0026id, \u0026transformHint); } if (err == NO_ERROR) { *outSurface = new SurfaceControl(this, handle, gbp, id, w, h, format, transformHint, flags); } return err; } 最后会调用到Client的createSurface frameworks/native/services/surfaceflinger/Client.cpp status_t Client::createSurface(const String8\u0026 name, uint32_t /* w */, uint32_t /* h */, PixelFormat /* format */, uint32_t flags, const sp\u003cIBinder\u003e\u0026 parentHandle, LayerMetadata metadata, sp\u003cIBinder\u003e* outHandle, sp\u003cIGraphicBufferProducer\u003e* /* gbp */, int32_t* outLayerId, uint32_t* outTransformHint) { // We rely on createLayer to check permissions. LayerCreationArgs args(mFlinger.get(), this, name.c_str(), flags, std::move(metadata)); return mFlinger-\u003ecreateLayer(args, outHandle, parentHandle, outLayerId, nullptr, outTransformHint); } 接下来就是跨进程到了Sf端 status_t SurfaceFlinger::createLayer(LayerCreationArgs\u0026 args, sp\u003cIBinder\u003e* outHandle, const sp\u003cIBinder\u003e\u0026 parentHandle, int32_t* outLayerId, const sp\u003cLayer\u003e\u0026 parentLayer, uint32_t* outTransformHint) { sp\u003cLayer\u003e layer; //根据不同的flags创建不同的Layer，常见情况：有buffer数据的一般是createBufferStateLayer，没有buffer的就是createContainerLayer switch (args.flags \u0026 ISurfaceC","date":"2024-11-06","objectID":"/posts/surfacecontrol%E5%8F%8Asurfaceflinger%E4%B8%AD%E7%9A%84layer%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","转载"],"title":"SurfaceControl及SurfaceFlinger中的Layer创建过程深入剖析-CSDN博客","uri":"/posts/surfacecontrol%E5%8F%8Asurfaceflinger%E4%B8%AD%E7%9A%84layer%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"背景 前面已经讲解清楚了SurfaceControl整个创建过程，一般SurfaceControl都是一个静态图层的代表，但往往只有静态一个图层是没有意义的，即只是创建了一个图层其实啥也看不到，更多需要是SurfaceControl对应的Transaction,这个事务才是真正可以让SurfaceControl可以显示的关键所在，Transaction才是相当于一个个的动作让SurfaceControl静态东西可以动起来，接下来将详细分析一下Transaction。 常见Transaction使用案例 private final Transaction mTransaction = new Transaction();//构建或者获取一个事物 mTransaction.setLayerStack(mSurfaceControl, mDisplayLayerStack); //开始用事物对象，对一个个SurfaceControl进行设置属性 mTransaction.setWindowCrop(mSurfaceControl, mDisplayWidth, mDisplayHeight);//开始用事物对象，对一个个SurfaceControl进行设置属性 mTransaction.apply();//针对事物进行apply操作 上面可以看出，Transaction是一个独立的事物对象，专门用于操作一个个SurfaceControl的属性，但并不是属于SurfaceControl对象的成员，即Transaction完全可以实现一对多个SurfaceControl情况。 Transaction的构造 frameworks/base/core/java/android/view/SurfaceControl.java public Transaction() { this(nativeCreateTransaction()); } 来看看nativeCreateTransaction方法 frameworks/base/core/jni/android_view_SurfaceControl.cpp static jlong nativeCreateTransaction(JNIEnv* env, jclass clazz) { return reinterpret_cast\u003cjlong\u003e(new SurfaceComposerClient::Transaction); } 就是简单的构造了一个SurfaceComposerClient::Transaction对象 frameworks/native/libs/gui/SurfaceComposerClient.cpp SurfaceComposerClient::Transaction::Transaction() { mId = generateId(); } 可以看到如果默认的构造的Transaction其实啥也没有干，就是生成了个Id然后赋值给了mId成员变量。 Transaction相关介绍 主要成员 layer_state_t结构体 用来代表Layer图层的的相关信息，SurfaceControl与sf的Layer共用这个layer_state_t结构体，layer_state_t包括layer所有属性 主要成员如下： 可以看到常见的主要属性：坐标，长宽，变换矩阵，变化值what，flags，mask等，一般是一个图层就有一个layer_state_t结构体。 ComposerStates结构体 struct ComposerState { layer_state_t state; status_t write(Parcel\u0026 output) const; status_t read(const Parcel\u0026 input); }; 可以看出就是layer_state_t进行了一个包装而已 mComposerStates 定义如下： std::unordered_map\u003csp, ComposerState, IBinderHash\u003e mComposerStates; 可以看出来其实就是一个装载ComposerState的map容器，map的key是每个SurfaceControl的handle,具体可以看一下这个mComposerStates的容器添加方法： layer_state_t* SurfaceComposerClient::Transaction::getLayerState(const sp\u003cSurfaceControl\u003e\u0026 sc) { auto handle = sc-\u003egetLayerStateHandle();//获取SurfaceControl的handle， //判断是否mComposerStates容器是否存在这个sc的相关信息，如果没有则进入添加 if (mComposerStates.count(handle) == 0) { // we don't have it, add an initialized layer_state to our list ComposerState s;//初始化一个ComposerState s.state.surface = handle; s.state.layerId = sc-\u003egetLayerId(); mComposerStates[handle] = s;//把初始化的ComposerState放到map集合mComposerStates中 } //如果存在，则直接通过handle从mComposerStates获取state返回 return \u0026(mComposerStates[handle].state); } 上面其实可以得出如下结论： 1、每个Transaction都有自己的一个mComposerStates集合 2、mComposerStates集合会放入Transaction中会操作的SurfaceControl对应的layer_state_t 补充一下 sc-\u003egetLayerStateHandle方法： sp\u003cIBinder\u003e SurfaceControl::getLayerStateHandle() const { return mHandle; } 这个mHandle其实就是sf端创建一个Handle sp\u003cIBinder\u003e Layer::getHandle() { Mutex::Autolock _l(mLock); if (mGetHandleCalled) { ALOGE(\"Get handle called twice\" ); return nullptr; } mGetHandleCalled = true; return new Handle(mFlinger, this); } 即mHandle是sf端代表Layer的BpBinder对象。 主要方法 一些属性常见设置方法 //可以看到一般属性操作方法第一参数是SurfaceControl，后面属性需要参数 SurfaceComposerClient::Transaction\u0026 SurfaceComposerClient::Transaction::setPosition( const sp\u003cSurfaceControl\u003e\u0026 sc, float x, float y) { layer_state_t* s = getLayerState(sc); //获取sc对应的layer_state_t s-\u003ewhat |= layer_state_t::ePositionChanged;//改变what，即标记layer_state_t哪个属性是有变化的，方便sf进行识别获取 s-\u003ex = x; //接下来才是改变具体的值 s-\u003ey = y; registerSurfaceControlForCallback(sc); return *this; } 上面就是一个经典的Transaction改变属性的方法，常规就是以下几步： 1、通过传递来的sc，获取sc的layer_state_t 2、标记layer_state_t的what属性，主要为了明显表达出哪个属性变化了 3、进行具体属性改变 其他的属性方法套路都和上面基本一样 merge方法 主要目的是把多个Transaction的内容合并到一个，即把other的这个Transaction内容都拷贝到当前Transaction SurfaceComposerClient::Transaction\u0026 SurfaceComposerClient::Transaction::merge(Transaction\u0026\u0026 other) { for (auto const\u0026 [handle, composerState] : other.mComposerStates) { if (mComposerStates.count(handle) == 0) { mComposerStates[handle] = composerState; } else { if (composerState.state.what \u0026 layer_state_t::eBufferChanged) { releaseBufferIfOverwriting(mComposerStates[handle].state); } mComposerStates[handle].state.merge(composerState.state);","date":"2024-11-06","objectID":"/posts/surfacecontrol%E4%B9%8Btransaction%E4%BA%8B%E7%89%A9%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-android-framework%E5%AE%9E%E6%88%98%E5%BC%80%E5%8F%91-csdn%E5%8D%9A%E5%AE%A2/:0:0","tags":["clippings","blog","Framework"],"title":"SurfaceControl之Transaction事物深入剖析-android framework实战开发-CSDN博客","uri":"/posts/surfacecontrol%E4%B9%8Btransaction%E4%BA%8B%E7%89%A9%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90-android-framework%E5%AE%9E%E6%88%98%E5%BC%80%E5%8F%91-csdn%E5%8D%9A%E5%AE%A2/"},{"categories":["hello"],"content":"Welcome to Hugo FixIt! This is your very first post. ","date":"2022-09-29","objectID":"/posts/hello-world/:0:0","tags":["FixIt"],"title":"Hello World","uri":"/posts/hello-world/"}]